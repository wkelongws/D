{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#datapath = '/home/microway/Shuo/CarND/CarND-BehaviorCloning-Project/data-given/'\n",
    "data = pd.read_csv('/Users/Shuo/study/Project-predictive_study/Old_experiments/data_2016_1t_dir1.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(data,datafolder='/Users/Shuo/Desktop/Data_2016/'):\n",
    "    X_train = np.zeros((len(data),13,288,9))\n",
    "    y_train = np.zeros((len(data),15,288,1))\n",
    "    for i in range(len(data)):\n",
    "        with open(datafolder+'CSVs_old/'+data['X'][i], 'r') as f:\n",
    "            X = list(csv.reader(f, delimiter=\",\"))\n",
    "            X = np.asarray(X)\n",
    "            channels = np.unique(X[:,0])\n",
    "            for channel in channels:\n",
    "                index=X[:,0] == channel\n",
    "                X_train[i,:,:,int(channel)] = X[index,1:]\n",
    "        with open(datafolder+'Traffic_CSVs/'+data['y'][i], 'r') as f:\n",
    "            y = list(csv.reader(f, delimiter=\",\"))\n",
    "            y = np.asarray(y)\n",
    "            index=y[:,0] == '0'\n",
    "            y_train[i,:,:,0] = y[index,1:]\n",
    "    return X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(346, 13, 288, 9)\n",
      "(346, 15, 288, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train = load_data(data)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization(X_train):\n",
    "    table = pd.read_csv('/Users/Shuo/study/Project-predictive_study/stats_weather.csv',delimiter=',')\n",
    "    for i in range(X_train.shape[-1]):\n",
    "        mean = table['mean'][i]\n",
    "        std = table['std'][i]\n",
    "        X_train[:,:,:,i] = (X_train[:,:,:,i]-mean)/std\n",
    "    return X_train\n",
    "    \n",
    "X_train = normalization(X_train)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape, Dense, Convolution2D, Deconvolution2D, Flatten, Input, Dropout, MaxPooling2D, Activation\n",
    "from keras.models import model_from_json\n",
    "from keras.activations import relu, softmax, linear\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Structure 1\n",
    "# Epoch 10/10 311/311 [==============================] - 9s - loss: 1364.2763 - val_loss: 1280.2520\n",
    "model = Sequential()\n",
    "# 13*288*9\n",
    "model.add(Convolution2D(16, 3, 5,input_shape=(13, 288, 9),border_mode='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# 11*284*16\n",
    "model.add(Convolution2D(32, 3, 5,border_mode='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# 9*280*24\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(1024))\n",
    "model.add(Dense(60480))\n",
    "model.add(Reshape((9,280,24)))\n",
    "model.add(Deconvolution2D(16, 3, 5, output_shape=(None, 11, 284,16),border_mode='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# 11*284*16 \n",
    "model.add(Deconvolution2D(1, 5, 5, output_shape=(None, 15, 288, 1),border_mode='valid'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Structure 2\n",
    "acti = 'relu'\n",
    "\n",
    "model = Sequential()\n",
    "# 13*288*9\n",
    "model.add(Convolution2D(16, 3, 5,input_shape=(13, 288, 9),border_mode='valid',subsample=(1, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(acti))\n",
    "#model.add(Dropout(0.5))\n",
    "# 11*284*16\n",
    "model.add(Convolution2D(24, 3, 5,border_mode='valid',subsample=(1, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(acti))\n",
    "#model.add(Dropout(0.5))\n",
    "# 9*280*24\n",
    "model.add(Convolution2D(32, 3, 5,border_mode='valid',subsample=(1, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(acti))\n",
    "#model.add(Dropout(0.5))\n",
    "# 7*276*32\n",
    "model.add(Convolution2D(48, 3, 5,border_mode='valid',subsample=(1, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(acti))\n",
    "#model.add(Dropout(0.5))\n",
    "# 5*272*48\n",
    "#dummy_input = np.ones((32, 13, 288, 9))\n",
    "#preds = model.predict(dummy_input)\n",
    "#print(preds.shape)\n",
    "model.add(Deconvolution2D(32, 3, 5, output_shape=(None, 7, 276, 32),border_mode='valid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(acti))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Deconvolution2D(24, 3, 5, output_shape=(None, 9, 280, 24),border_mode='valid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(acti))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Deconvolution2D(16, 3, 5, output_shape=(None, 11, 284, 16),border_mode='valid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(acti))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Deconvolution2D(1, 5, 5, output_shape=(None, 15, 288, 1),border_mode='valid'))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "ada = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mse', optimizer=ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Structure 3\n",
    "model = Sequential()\n",
    "# 13*288*9\n",
    "model.add(Convolution2D(16, 3, 5,input_shape=(13, 288, 9),border_mode='valid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# 11*284*16\n",
    "model.add(Convolution2D(32, 3, 5,border_mode='valid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# 9*280*24\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1024))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(60480))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Reshape((9,280,24)))\n",
    "model.add(Deconvolution2D(16, 3, 5, output_shape=(None, 11, 284,16),border_mode='valid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# 11*284*16 \n",
    "model.add(Deconvolution2D(1, 5, 5, output_shape=(None, 15, 288, 1),border_mode='valid'))\n",
    "model.add(Activation('linear'))\n",
    "ada = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mse', optimizer=ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 311 samples, validate on 35 samples\n",
      "Epoch 1/500\n",
      "311/311 [==============================] - 13s - loss: 4767.1451 - val_loss: 4878.4194\n",
      "Epoch 2/500\n",
      "311/311 [==============================] - 11s - loss: 4725.9295 - val_loss: 4877.8618\n",
      "Epoch 3/500\n",
      "311/311 [==============================] - 11s - loss: 4721.9985 - val_loss: 4877.5308\n",
      "Epoch 4/500\n",
      "311/311 [==============================] - 11s - loss: 4716.2944 - val_loss: 4876.6289\n",
      "Epoch 5/500\n",
      "311/311 [==============================] - 11s - loss: 4707.9053 - val_loss: 4875.0444\n",
      "Epoch 6/500\n",
      "311/311 [==============================] - 11s - loss: 4695.9351 - val_loss: 4872.3110\n",
      "Epoch 7/500\n",
      "311/311 [==============================] - 11s - loss: 4679.5247 - val_loss: 4867.9453\n",
      "Epoch 8/500\n",
      "311/311 [==============================] - 12s - loss: 4658.4830 - val_loss: 4862.0332\n",
      "Epoch 9/500\n",
      "311/311 [==============================] - 12s - loss: 4632.6289 - val_loss: 4852.6001\n",
      "Epoch 10/500\n",
      "311/311 [==============================] - 12s - loss: 4603.1482 - val_loss: 4839.8091\n",
      "Epoch 11/500\n",
      "311/311 [==============================] - 11s - loss: 4569.7218 - val_loss: 4823.1079\n",
      "Epoch 12/500\n",
      "311/311 [==============================] - 12s - loss: 4532.9693 - val_loss: 4797.4297\n",
      "Epoch 13/500\n",
      "311/311 [==============================] - 11s - loss: 4492.3653 - val_loss: 4760.4731\n",
      "Epoch 14/500\n",
      "311/311 [==============================] - 12s - loss: 4447.8235 - val_loss: 4717.5469\n",
      "Epoch 15/500\n",
      "311/311 [==============================] - 11s - loss: 4398.5427 - val_loss: 4675.2222\n",
      "Epoch 16/500\n",
      "311/311 [==============================] - 11s - loss: 4344.1035 - val_loss: 4645.6582\n",
      "Epoch 17/500\n",
      "311/311 [==============================] - 11s - loss: 4284.0881 - val_loss: 4619.2437\n",
      "Epoch 18/500\n",
      "311/311 [==============================] - 11s - loss: 4217.9920 - val_loss: 4558.4204\n",
      "Epoch 19/500\n",
      "311/311 [==============================] - 12s - loss: 4147.3529 - val_loss: 4453.0063\n",
      "Epoch 20/500\n",
      "311/311 [==============================] - 11s - loss: 4071.8153 - val_loss: 4309.8257\n",
      "Epoch 21/500\n",
      "311/311 [==============================] - 11s - loss: 3994.3784 - val_loss: 4120.5107\n",
      "Epoch 22/500\n",
      "311/311 [==============================] - 11s - loss: 3914.3564 - val_loss: 3969.7161\n",
      "Epoch 23/500\n",
      "311/311 [==============================] - 12s - loss: 3832.1761 - val_loss: 3818.9741\n",
      "Epoch 24/500\n",
      "311/311 [==============================] - 11s - loss: 3749.1770 - val_loss: 3506.6082\n",
      "Epoch 25/500\n",
      "311/311 [==============================] - 11s - loss: 3664.5507 - val_loss: 3203.2458\n",
      "Epoch 26/500\n",
      "311/311 [==============================] - 11s - loss: 3578.2240 - val_loss: 2630.0906\n",
      "Epoch 27/500\n",
      "311/311 [==============================] - 11s - loss: 3491.5311 - val_loss: 2105.2646\n",
      "Epoch 28/500\n",
      "311/311 [==============================] - 11s - loss: 3405.6386 - val_loss: 1790.6770\n",
      "Epoch 29/500\n",
      "311/311 [==============================] - 12s - loss: 3319.8921 - val_loss: 1670.1991\n",
      "Epoch 30/500\n",
      "311/311 [==============================] - 13s - loss: 3234.7010 - val_loss: 1590.0560\n",
      "Epoch 31/500\n",
      "311/311 [==============================] - 12s - loss: 3151.1613 - val_loss: 1489.2905\n",
      "Epoch 32/500\n",
      "311/311 [==============================] - 12s - loss: 3067.9426 - val_loss: 1429.0309\n",
      "Epoch 33/500\n",
      "311/311 [==============================] - 12s - loss: 2986.8556 - val_loss: 1400.1442\n",
      "Epoch 34/500\n",
      "311/311 [==============================] - 12s - loss: 2906.6350 - val_loss: 1413.6550\n",
      "Epoch 35/500\n",
      "311/311 [==============================] - 12s - loss: 2827.8622 - val_loss: 1410.6624\n",
      "Epoch 36/500\n",
      "311/311 [==============================] - 12s - loss: 2751.5586 - val_loss: 1380.8666\n",
      "Epoch 37/500\n",
      "311/311 [==============================] - 12s - loss: 2675.9633 - val_loss: 1332.0092\n",
      "Epoch 38/500\n",
      "311/311 [==============================] - 12s - loss: 2602.4850 - val_loss: 1337.5472\n",
      "Epoch 39/500\n",
      "311/311 [==============================] - 11s - loss: 2531.1021 - val_loss: 1361.4902\n",
      "Epoch 40/500\n",
      "311/311 [==============================] - 13s - loss: 2461.2567 - val_loss: 1384.0291\n",
      "Epoch 41/500\n",
      "311/311 [==============================] - 12s - loss: 2393.8695 - val_loss: 1374.3035\n",
      "Epoch 42/500\n",
      "311/311 [==============================] - 11s - loss: 2327.6711 - val_loss: 1359.0431\n",
      "Epoch 43/500\n",
      "311/311 [==============================] - 11s - loss: 2263.8272 - val_loss: 1428.4088\n",
      "Epoch 44/500\n",
      "311/311 [==============================] - 12s - loss: 2200.9965 - val_loss: 1747.3436\n",
      "Epoch 45/500\n",
      "311/311 [==============================] - 12s - loss: 2141.0879 - val_loss: 1617.0940\n",
      "Epoch 46/500\n",
      "311/311 [==============================] - 12s - loss: 2082.0110 - val_loss: 1698.2921\n",
      "Epoch 47/500\n",
      "311/311 [==============================] - 12s - loss: 2024.8268 - val_loss: 1469.7108\n",
      "Epoch 48/500\n",
      "311/311 [==============================] - 12s - loss: 1969.4406 - val_loss: 1406.2646\n",
      "Epoch 49/500\n",
      "311/311 [==============================] - 11s - loss: 1915.6933 - val_loss: 1536.8776\n",
      "Epoch 50/500\n",
      "311/311 [==============================] - 11s - loss: 1863.7940 - val_loss: 1632.4054\n",
      "Epoch 51/500\n",
      "311/311 [==============================] - 11s - loss: 1813.0071 - val_loss: 2147.1431\n",
      "Epoch 52/500\n",
      "311/311 [==============================] - 11s - loss: 1764.7289 - val_loss: 3177.8943\n",
      "Epoch 53/500\n",
      "311/311 [==============================] - 11s - loss: 1717.1154 - val_loss: 6932.0962\n",
      "Epoch 54/500\n",
      "311/311 [==============================] - 11s - loss: 1671.5034 - val_loss: 12412.5020\n",
      "Epoch 55/500\n",
      "311/311 [==============================] - 11s - loss: 1627.0481 - val_loss: 24602.2363\n",
      "Epoch 56/500\n",
      "311/311 [==============================] - 12s - loss: 1584.5153 - val_loss: 54221.5195\n",
      "Epoch 57/500\n",
      "311/311 [==============================] - 12s - loss: 1543.0402 - val_loss: 175124.7500\n",
      "Epoch 58/500\n",
      "311/311 [==============================] - 12s - loss: 1502.9515 - val_loss: 437832.1562\n",
      "Epoch 59/500\n",
      "311/311 [==============================] - 12s - loss: 1464.7601 - val_loss: 573432.9375\n",
      "Epoch 60/500\n",
      "311/311 [==============================] - 11s - loss: 1427.3959 - val_loss: 911414.0000\n",
      "Epoch 61/500\n",
      "311/311 [==============================] - 11s - loss: 1391.1905 - val_loss: 1186238.7500\n",
      "Epoch 62/500\n",
      "311/311 [==============================] - 12s - loss: 1356.5738 - val_loss: 1308052.5000\n",
      "Epoch 63/500\n",
      "311/311 [==============================] - 13s - loss: 1323.0007 - val_loss: 1367459.8750\n",
      "Epoch 64/500\n",
      "311/311 [==============================] - 13s - loss: 1291.1991 - val_loss: 1644499.3750\n",
      "Epoch 65/500\n",
      "311/311 [==============================] - 12s - loss: 1259.8541 - val_loss: 2013461.2500\n",
      "Epoch 66/500\n",
      "311/311 [==============================] - 12s - loss: 1230.3869 - val_loss: 2620933.0000\n",
      "Epoch 67/500\n",
      "311/311 [==============================] - 11s - loss: 1201.4807 - val_loss: 3655198.2500\n",
      "Epoch 68/500\n",
      "311/311 [==============================] - 12s - loss: 1173.7578 - val_loss: 4563971.5000\n",
      "Epoch 69/500\n",
      "311/311 [==============================] - 12s - loss: 1147.3030 - val_loss: 5839794.5000\n",
      "Epoch 70/500\n",
      "311/311 [==============================] - 12s - loss: 1121.3735 - val_loss: 8523184.0000\n",
      "Epoch 71/500\n",
      "311/311 [==============================] - 12s - loss: 1096.7519 - val_loss: 10844974.0000\n",
      "Epoch 72/500\n",
      "311/311 [==============================] - 12s - loss: 1072.3130 - val_loss: 13455300.0000\n",
      "Epoch 73/500\n",
      "311/311 [==============================] - 11s - loss: 1049.5965 - val_loss: 19785516.0000\n",
      "Epoch 74/500\n",
      "311/311 [==============================] - 12s - loss: 1027.2225 - val_loss: 31127348.0000\n",
      "Epoch 75/500\n",
      "311/311 [==============================] - 12s - loss: 1005.7398 - val_loss: 37109484.0000\n",
      "Epoch 76/500\n",
      "311/311 [==============================] - 12s - loss: 985.2752 - val_loss: 45968612.0000\n",
      "Epoch 77/500\n",
      "311/311 [==============================] - 11s - loss: 965.3021 - val_loss: 56982184.0000\n",
      "Epoch 78/500\n",
      "311/311 [==============================] - 12s - loss: 946.1164 - val_loss: 71012152.0000\n",
      "Epoch 79/500\n",
      "311/311 [==============================] - 12s - loss: 927.8791 - val_loss: 88175288.0000\n",
      "Epoch 80/500\n",
      "311/311 [==============================] - 12s - loss: 909.9261 - val_loss: 108592736.0000\n",
      "Epoch 81/500\n",
      "311/311 [==============================] - 12s - loss: 892.6441 - val_loss: 134254192.0000\n",
      "Epoch 82/500\n",
      "311/311 [==============================] - 11s - loss: 876.1979 - val_loss: 164155312.0000\n",
      "Epoch 83/500\n",
      "311/311 [==============================] - 11s - loss: 860.3325 - val_loss: 201976864.0000\n",
      "Epoch 84/500\n",
      "311/311 [==============================] - 12s - loss: 844.7668 - val_loss: 247040384.0000\n",
      "Epoch 85/500\n",
      "311/311 [==============================] - 12s - loss: 830.0688 - val_loss: 297507488.0000\n",
      "Epoch 86/500\n",
      "311/311 [==============================] - 12s - loss: 815.7846 - val_loss: 357205920.0000\n",
      "Epoch 87/500\n",
      "311/311 [==============================] - 12s - loss: 802.0260 - val_loss: 424874880.0000\n",
      "Epoch 88/500\n",
      "311/311 [==============================] - 12s - loss: 788.6130 - val_loss: 507848832.0000\n",
      "Epoch 89/500\n",
      "311/311 [==============================] - 12s - loss: 775.8259 - val_loss: 616786048.0000\n",
      "Epoch 90/500\n",
      "311/311 [==============================] - 11s - loss: 763.3309 - val_loss: 751356672.0000\n",
      "Epoch 91/500\n",
      "311/311 [==============================] - 12s - loss: 751.2083 - val_loss: 918549312.0000\n",
      "Epoch 92/500\n",
      "311/311 [==============================] - 12s - loss: 739.4621 - val_loss: 1093977984.0000\n",
      "Epoch 93/500\n",
      "311/311 [==============================] - 12s - loss: 728.0870 - val_loss: 1280213376.0000\n",
      "Epoch 94/500\n",
      "311/311 [==============================] - 12s - loss: 717.2000 - val_loss: 1534948096.0000\n",
      "Epoch 95/500\n",
      "311/311 [==============================] - 11s - loss: 706.4773 - val_loss: 1816733952.0000\n",
      "Epoch 96/500\n",
      "311/311 [==============================] - 12s - loss: 695.8521 - val_loss: 2161809664.0000\n",
      "Epoch 97/500\n",
      "311/311 [==============================] - 12s - loss: 685.8469 - val_loss: 2617935360.0000\n",
      "Epoch 98/500\n",
      "311/311 [==============================] - 12s - loss: 675.9976 - val_loss: 3150833664.0000\n",
      "Epoch 99/500\n",
      "311/311 [==============================] - 12s - loss: 666.5321 - val_loss: 3756429824.0000\n",
      "Epoch 100/500\n",
      "311/311 [==============================] - 12s - loss: 657.2813 - val_loss: 4451661824.0000\n",
      "Epoch 101/500\n",
      "311/311 [==============================] - 12s - loss: 648.3281 - val_loss: 5238684160.0000\n",
      "Epoch 102/500\n",
      "311/311 [==============================] - 12s - loss: 639.6607 - val_loss: 6051735040.0000\n",
      "Epoch 103/500\n",
      "311/311 [==============================] - 12s - loss: 631.3196 - val_loss: 6984163328.0000\n",
      "Epoch 104/500\n",
      "311/311 [==============================] - 12s - loss: 623.2122 - val_loss: 7997095936.0000\n",
      "Epoch 105/500\n",
      "311/311 [==============================] - 12s - loss: 615.0068 - val_loss: 9166361600.0000\n",
      "Epoch 106/500\n",
      "311/311 [==============================] - 12s - loss: 607.3569 - val_loss: 10606893056.0000\n",
      "Epoch 107/500\n",
      "311/311 [==============================] - 12s - loss: 599.7126 - val_loss: 12102086656.0000\n",
      "Epoch 108/500\n",
      "311/311 [==============================] - 12s - loss: 592.4036 - val_loss: 14003497984.0000\n",
      "Epoch 109/500\n",
      "311/311 [==============================] - 12s - loss: 585.2562 - val_loss: 16251965440.0000\n",
      "Epoch 110/500\n",
      "311/311 [==============================] - 12s - loss: 578.2744 - val_loss: 18793379840.0000\n",
      "Epoch 111/500\n",
      "311/311 [==============================] - 12s - loss: 571.4470 - val_loss: 21626140672.0000\n",
      "Epoch 112/500\n",
      "311/311 [==============================] - 13s - loss: 564.8010 - val_loss: 24987766784.0000\n",
      "Epoch 113/500\n",
      "311/311 [==============================] - 14s - loss: 558.4190 - val_loss: 29536294912.0000\n",
      "Epoch 114/500\n",
      "311/311 [==============================] - 12s - loss: 551.9759 - val_loss: 33098622976.0000\n",
      "Epoch 115/500\n",
      "311/311 [==============================] - 12s - loss: 545.7389 - val_loss: 36723200000.0000\n",
      "Epoch 116/500\n",
      "311/311 [==============================] - 12s - loss: 539.5721 - val_loss: 43444547584.0000\n",
      "Epoch 117/500\n",
      "311/311 [==============================] - 12s - loss: 533.5898 - val_loss: 51049914368.0000\n",
      "Epoch 118/500\n",
      "311/311 [==============================] - 13s - loss: 527.6825 - val_loss: 58483765248.0000\n",
      "Epoch 119/500\n",
      "311/311 [==============================] - 12s - loss: 522.2104 - val_loss: 66784247808.0000\n",
      "Epoch 120/500\n",
      "311/311 [==============================] - 13s - loss: 516.3378 - val_loss: 76839755776.0000\n",
      "Epoch 121/500\n",
      "311/311 [==============================] - 14s - loss: 511.0163 - val_loss: 88196734976.0000\n",
      "Epoch 122/500\n",
      "311/311 [==============================] - 12s - loss: 505.6484 - val_loss: 101208449024.0000\n",
      "Epoch 123/500\n",
      "311/311 [==============================] - 14s - loss: 500.4529 - val_loss: 116956061696.0000\n",
      "Epoch 124/500\n",
      "311/311 [==============================] - 12s - loss: 495.4325 - val_loss: 135383252992.0000\n",
      "Epoch 125/500\n",
      "311/311 [==============================] - 12s - loss: 490.3453 - val_loss: 156154200064.0000\n",
      "Epoch 126/500\n",
      "311/311 [==============================] - 12s - loss: 485.6193 - val_loss: 180345815040.0000\n",
      "Epoch 127/500\n",
      "311/311 [==============================] - 13s - loss: 480.7981 - val_loss: 208783917056.0000\n",
      "Epoch 128/500\n",
      "311/311 [==============================] - 12s - loss: 476.0506 - val_loss: 241618206720.0000\n",
      "Epoch 129/500\n",
      "311/311 [==============================] - 12s - loss: 471.5859 - val_loss: 279801856000.0000\n",
      "Epoch 130/500\n",
      "311/311 [==============================] - 12s - loss: 467.1568 - val_loss: 323025469440.0000\n",
      "Epoch 131/500\n",
      "311/311 [==============================] - 12s - loss: 462.5478 - val_loss: 372152729600.0000\n",
      "Epoch 132/500\n",
      "311/311 [==============================] - 12s - loss: 458.0176 - val_loss: 429469892608.0000\n",
      "Epoch 133/500\n",
      "311/311 [==============================] - 12s - loss: 453.6492 - val_loss: 498732105728.0000\n",
      "Epoch 134/500\n",
      "311/311 [==============================] - 13s - loss: 449.1613 - val_loss: 575867650048.0000\n",
      "Epoch 135/500\n",
      "311/311 [==============================] - 13s - loss: 444.7291 - val_loss: 660439367680.0000\n",
      "Epoch 136/500\n",
      "311/311 [==============================] - 12s - loss: 440.0686 - val_loss: 761165840384.0000\n",
      "Epoch 137/500\n",
      "311/311 [==============================] - 12s - loss: 435.5269 - val_loss: 880542089216.0000\n",
      "Epoch 138/500\n",
      "311/311 [==============================] - 12s - loss: 430.8834 - val_loss: 1013551661056.0000\n",
      "Epoch 139/500\n",
      "311/311 [==============================] - 13s - loss: 426.3809 - val_loss: 1169558470656.0000\n",
      "Epoch 140/500\n",
      "311/311 [==============================] - 12s - loss: 422.1114 - val_loss: 1345649508352.0000\n",
      "Epoch 141/500\n",
      "311/311 [==============================] - 12s - loss: 418.0129 - val_loss: 1538885419008.0000\n",
      "Epoch 142/500\n",
      "311/311 [==============================] - 12s - loss: 414.0128 - val_loss: 1754659815424.0000\n",
      "Epoch 143/500\n",
      "311/311 [==============================] - 13s - loss: 410.2967 - val_loss: 1994423926784.0000\n",
      "Epoch 144/500\n",
      "311/311 [==============================] - 12s - loss: 406.6800 - val_loss: 2264477990912.0000\n",
      "Epoch 145/500\n",
      "311/311 [==============================] - 12s - loss: 403.3659 - val_loss: 2127151366144.0000\n",
      "Epoch 146/500\n",
      "311/311 [==============================] - 13s - loss: 400.0582 - val_loss: 1786909163520.0000\n",
      "Epoch 147/500\n",
      "311/311 [==============================] - 12s - loss: 397.1061 - val_loss: 1675781472256.0000\n",
      "Epoch 148/500\n",
      "311/311 [==============================] - 12s - loss: 394.0475 - val_loss: 1801490006016.0000\n",
      "Epoch 149/500\n",
      "311/311 [==============================] - 12s - loss: 391.3922 - val_loss: 1416253538304.0000\n",
      "Epoch 150/500\n",
      "311/311 [==============================] - 12s - loss: 388.7025 - val_loss: 1268003110912.0000\n",
      "Epoch 151/500\n",
      "311/311 [==============================] - 12s - loss: 386.3123 - val_loss: 748974243840.0000\n",
      "Epoch 152/500\n",
      "311/311 [==============================] - 12s - loss: 383.7367 - val_loss: 861715693568.0000\n",
      "Epoch 153/500\n",
      "311/311 [==============================] - 12s - loss: 381.4640 - val_loss: 2574016577536.0000\n",
      "Epoch 154/500\n",
      "311/311 [==============================] - 12s - loss: 379.1682 - val_loss: 3920094298112.0000\n",
      "Epoch 155/500\n",
      "311/311 [==============================] - 12s - loss: 376.9824 - val_loss: 4319577112576.0000\n",
      "Epoch 156/500\n",
      "311/311 [==============================] - 12s - loss: 374.9517 - val_loss: 4923925725184.0000\n",
      "Epoch 157/500\n",
      "311/311 [==============================] - 12s - loss: 372.9374 - val_loss: 4468643987456.0000\n",
      "Epoch 158/500\n",
      "311/311 [==============================] - 12s - loss: 370.9627 - val_loss: 3405141245952.0000\n",
      "Epoch 159/500\n",
      "311/311 [==============================] - 12s - loss: 369.0640 - val_loss: 3572068515840.0000\n",
      "Epoch 160/500\n",
      "311/311 [==============================] - 12s - loss: 367.2138 - val_loss: 3692421971968.0000\n",
      "Epoch 161/500\n",
      "311/311 [==============================] - 12s - loss: 365.3799 - val_loss: 3431957790720.0000\n",
      "Epoch 162/500\n",
      "311/311 [==============================] - 12s - loss: 363.7054 - val_loss: 3755895160832.0000\n",
      "Epoch 163/500\n",
      "311/311 [==============================] - 12s - loss: 362.0562 - val_loss: 3317604810752.0000\n",
      "Epoch 164/500\n",
      "311/311 [==============================] - 12s - loss: 360.4321 - val_loss: 3869851779072.0000\n",
      "Epoch 165/500\n",
      "311/311 [==============================] - 12s - loss: 358.8968 - val_loss: 2792228388864.0000\n",
      "Epoch 166/500\n",
      "311/311 [==============================] - 12s - loss: 357.4320 - val_loss: 2258480660480.0000\n",
      "Epoch 167/500\n",
      "311/311 [==============================] - 12s - loss: 355.8680 - val_loss: 3287676616704.0000\n",
      "Epoch 168/500\n",
      "311/311 [==============================] - 12s - loss: 354.5370 - val_loss: 4978950799360.0000\n",
      "Epoch 169/500\n",
      "311/311 [==============================] - 13s - loss: 353.0577 - val_loss: 10838965485568.0000\n",
      "Epoch 170/500\n",
      "311/311 [==============================] - 12s - loss: 351.8241 - val_loss: 17971669893120.0000\n",
      "Epoch 171/500\n",
      "311/311 [==============================] - 15s - loss: 350.4604 - val_loss: 17561066405888.0000\n",
      "Epoch 172/500\n",
      "311/311 [==============================] - 12s - loss: 349.3660 - val_loss: 26972478504960.0000\n",
      "Epoch 173/500\n",
      "311/311 [==============================] - 12s - loss: 348.1300 - val_loss: 33302274637824.0000\n",
      "Epoch 174/500\n",
      "311/311 [==============================] - 12s - loss: 346.7187 - val_loss: 30645533278208.0000\n",
      "Epoch 175/500\n",
      "311/311 [==============================] - 12s - loss: 345.5684 - val_loss: 17522133827584.0000\n",
      "Epoch 176/500\n",
      "311/311 [==============================] - 12s - loss: 344.5678 - val_loss: 5709486358528.0000\n",
      "Epoch 177/500\n",
      "311/311 [==============================] - 12s - loss: 343.5104 - val_loss: 4888857149440.0000\n",
      "Epoch 178/500\n",
      "311/311 [==============================] - 13s - loss: 342.3577 - val_loss: 6239322374144.0000\n",
      "Epoch 179/500\n",
      "311/311 [==============================] - 14s - loss: 341.2632 - val_loss: 10735119761408.0000\n",
      "Epoch 180/500\n",
      "311/311 [==============================] - 13s - loss: 340.2276 - val_loss: 11245108330496.0000\n",
      "Epoch 181/500\n",
      "311/311 [==============================] - 12s - loss: 339.1975 - val_loss: 10174458757120.0000\n",
      "Epoch 182/500\n",
      "311/311 [==============================] - 12s - loss: 338.1857 - val_loss: 22540089032704.0000\n",
      "Epoch 183/500\n",
      "311/311 [==============================] - 12s - loss: 337.2478 - val_loss: 45243730755584.0000\n",
      "Epoch 184/500\n",
      "311/311 [==============================] - 13s - loss: 336.3254 - val_loss: 74902308651008.0000\n",
      "Epoch 185/500\n",
      "311/311 [==============================] - 12s - loss: 335.4186 - val_loss: 107102139842560.0000\n",
      "Epoch 186/500\n",
      "311/311 [==============================] - 12s - loss: 334.5202 - val_loss: 140072288518144.0000\n",
      "Epoch 187/500\n",
      "311/311 [==============================] - 12s - loss: 333.6648 - val_loss: 196973760086016.0000\n",
      "Epoch 188/500\n",
      "311/311 [==============================] - 12s - loss: 332.8821 - val_loss: 277305301663744.0000\n",
      "Epoch 189/500\n",
      "311/311 [==============================] - 12s - loss: 332.3239 - val_loss: 388933347180544.0000\n",
      "Epoch 190/500\n",
      "311/311 [==============================] - 12s - loss: 331.5096 - val_loss: 450595521560576.0000\n",
      "Epoch 191/500\n",
      "311/311 [==============================] - 12s - loss: 330.6490 - val_loss: 506877846749184.0000\n",
      "Epoch 192/500\n",
      "311/311 [==============================] - 12s - loss: 329.7681 - val_loss: 565165888110592.0000\n",
      "Epoch 193/500\n",
      "311/311 [==============================] - 12s - loss: 329.0499 - val_loss: 627142937280512.0000\n",
      "Epoch 194/500\n",
      "311/311 [==============================] - 12s - loss: 328.3440 - val_loss: 678476520620032.0000\n",
      "Epoch 195/500\n",
      "311/311 [==============================] - 12s - loss: 327.8063 - val_loss: 734554297991168.0000\n",
      "Epoch 196/500\n",
      "311/311 [==============================] - 12s - loss: 327.1929 - val_loss: 866311613710336.0000\n",
      "Epoch 197/500\n",
      "311/311 [==============================] - 12s - loss: 326.4929 - val_loss: 1190086850904064.0000\n",
      "Epoch 198/500\n",
      "311/311 [==============================] - 12s - loss: 325.9410 - val_loss: 1566543150317568.0000\n",
      "Epoch 199/500\n",
      "311/311 [==============================] - 12s - loss: 325.2659 - val_loss: 2032095325061120.0000\n",
      "Epoch 200/500\n",
      "311/311 [==============================] - 12s - loss: 324.6627 - val_loss: 2522599649181696.0000\n",
      "Epoch 201/500\n",
      "311/311 [==============================] - 12s - loss: 324.1457 - val_loss: 3017135605415936.0000\n",
      "Epoch 202/500\n",
      "311/311 [==============================] - 13s - loss: 323.5849 - val_loss: 3456758794158080.0000\n",
      "Epoch 203/500\n",
      "311/311 [==============================] - 13s - loss: 322.9913 - val_loss: 4124100612063232.0000\n",
      "Epoch 204/500\n",
      "311/311 [==============================] - 13s - loss: 322.4484 - val_loss: 4803609535447040.0000\n",
      "Epoch 205/500\n",
      "311/311 [==============================] - 12s - loss: 322.0726 - val_loss: 5490871411671040.0000\n",
      "Epoch 206/500\n",
      "311/311 [==============================] - 12s - loss: 321.4434 - val_loss: 6050057363128320.0000\n",
      "Epoch 207/500\n",
      "311/311 [==============================] - 12s - loss: 320.9517 - val_loss: 6620206755479552.0000\n",
      "Epoch 208/500\n",
      "311/311 [==============================] - 12s - loss: 320.4804 - val_loss: 7198442497507328.0000\n",
      "Epoch 209/500\n",
      "311/311 [==============================] - 12s - loss: 320.1464 - val_loss: 7362410390224896.0000\n",
      "Epoch 210/500\n",
      "311/311 [==============================] - 12s - loss: 319.7236 - val_loss: 6739173054611456.0000\n",
      "Epoch 211/500\n",
      "311/311 [==============================] - 12s - loss: 319.2951 - val_loss: 6490233528909824.0000\n",
      "Epoch 212/500\n",
      "311/311 [==============================] - 12s - loss: 318.7899 - val_loss: 6195013583110144.0000\n",
      "Epoch 213/500\n",
      "311/311 [==============================] - 12s - loss: 318.4670 - val_loss: 7576116151713792.0000\n",
      "Epoch 214/500\n",
      "311/311 [==============================] - 12s - loss: 318.0454 - val_loss: 14227448535187456.0000\n",
      "Epoch 215/500\n",
      "311/311 [==============================] - 12s - loss: 317.6927 - val_loss: 23451002472497152.0000\n",
      "Epoch 216/500\n",
      "311/311 [==============================] - 12s - loss: 317.2952 - val_loss: 42904421184569344.0000\n",
      "Epoch 217/500\n",
      "311/311 [==============================] - 12s - loss: 316.9293 - val_loss: 64658250150182912.0000\n",
      "Epoch 218/500\n",
      "311/311 [==============================] - 13s - loss: 316.6128 - val_loss: 88397401978568704.0000\n",
      "Epoch 219/500\n",
      "311/311 [==============================] - 12s - loss: 316.1263 - val_loss: 113215406642036736.0000\n",
      "Epoch 220/500\n",
      "311/311 [==============================] - 12s - loss: 316.0507 - val_loss: 132177713023680512.0000\n",
      "Epoch 221/500\n",
      "311/311 [==============================] - 13s - loss: 315.5463 - val_loss: 160478944754139136.0000\n",
      "Epoch 222/500\n",
      "311/311 [==============================] - 12s - loss: 315.1614 - val_loss: 208401708806569984.0000\n",
      "Epoch 223/500\n",
      "311/311 [==============================] - 12s - loss: 315.0551 - val_loss: 269722898216779776.0000\n",
      "Epoch 224/500\n",
      "311/311 [==============================] - 12s - loss: 314.8408 - val_loss: 303131507487145984.0000\n",
      "Epoch 225/500\n",
      "311/311 [==============================] - 12s - loss: 314.4466 - val_loss: 327075434766270464.0000\n",
      "Epoch 226/500\n",
      "311/311 [==============================] - 12s - loss: 314.0114 - val_loss: 354395618656911360.0000\n",
      "Epoch 227/500\n",
      "311/311 [==============================] - 12s - loss: 313.6369 - val_loss: 389530925039353856.0000\n",
      "Epoch 228/500\n",
      "311/311 [==============================] - 12s - loss: 313.4071 - val_loss: 445776957754310656.0000\n",
      "Epoch 229/500\n",
      "311/311 [==============================] - 12s - loss: 313.2808 - val_loss: 501025527264444416.0000\n",
      "Epoch 230/500\n",
      "311/311 [==============================] - 12s - loss: 312.9596 - val_loss: 480564990261067776.0000\n",
      "Epoch 231/500\n",
      "311/311 [==============================] - 12s - loss: 312.5920 - val_loss: 488903926964289536.0000\n",
      "Epoch 232/500\n",
      "311/311 [==============================] - 12s - loss: 312.3361 - val_loss: 472491482536738816.0000\n",
      "Epoch 233/500\n",
      "311/311 [==============================] - 12s - loss: 311.9895 - val_loss: 446077639824769024.0000\n",
      "Epoch 234/500\n",
      "311/311 [==============================] - 12s - loss: 311.7459 - val_loss: 479878242170306560.0000\n",
      "Epoch 235/500\n",
      "311/311 [==============================] - 12s - loss: 311.5024 - val_loss: 535045791417368576.0000\n",
      "Epoch 236/500\n",
      "311/311 [==============================] - 12s - loss: 311.1814 - val_loss: 559183198383243264.0000\n",
      "Epoch 237/500\n",
      "311/311 [==============================] - 12s - loss: 310.9948 - val_loss: 560099022849703936.0000\n",
      "Epoch 238/500\n",
      "311/311 [==============================] - 12s - loss: 310.8205 - val_loss: 544654698410409984.0000\n",
      "Epoch 239/500\n",
      "311/311 [==============================] - 12s - loss: 310.6083 - val_loss: 502302816178536448.0000\n",
      "Epoch 240/500\n",
      "311/311 [==============================] - 12s - loss: 310.3686 - val_loss: 488485597149659136.0000\n",
      "Epoch 241/500\n",
      "311/311 [==============================] - 12s - loss: 310.4722 - val_loss: 464301151701958656.0000\n",
      "Epoch 242/500\n",
      "311/311 [==============================] - 12s - loss: 310.1559 - val_loss: 445854954360406016.0000\n",
      "Epoch 243/500\n",
      "311/311 [==============================] - 12s - loss: 309.7940 - val_loss: 461032922107871232.0000\n",
      "Epoch 244/500\n",
      "311/311 [==============================] - 12s - loss: 309.6167 - val_loss: 487272767104745472.0000\n",
      "Epoch 245/500\n",
      "311/311 [==============================] - 12s - loss: 309.4689 - val_loss: 517843519683952640.0000\n",
      "Epoch 246/500\n",
      "311/311 [==============================] - 12s - loss: 309.3544 - val_loss: 617510263012196352.0000\n",
      "Epoch 247/500\n",
      "311/311 [==============================] - 12s - loss: 309.0984 - val_loss: 756739908608983040.0000\n",
      "Epoch 248/500\n",
      "311/311 [==============================] - 12s - loss: 308.9237 - val_loss: 880471662934360064.0000\n",
      "Epoch 249/500\n",
      "311/311 [==============================] - 12s - loss: 308.7610 - val_loss: 1067612733869916160.0000\n",
      "Epoch 250/500\n",
      "311/311 [==============================] - 12s - loss: 308.7587 - val_loss: 1027858516578140160.0000\n",
      "Epoch 251/500\n",
      "311/311 [==============================] - 12s - loss: 308.4537 - val_loss: 1028743692157976576.0000\n",
      "Epoch 252/500\n",
      "311/311 [==============================] - 12s - loss: 308.4906 - val_loss: 1007377982207033344.0000\n",
      "Epoch 253/500\n",
      "311/311 [==============================] - 12s - loss: 308.3394 - val_loss: 1026891015065174016.0000\n",
      "Epoch 254/500\n",
      "311/311 [==============================] - 12s - loss: 308.0778 - val_loss: 1138309544829517824.0000\n",
      "Epoch 255/500\n",
      "311/311 [==============================] - 12s - loss: 307.9002 - val_loss: 1353626632018984960.0000\n",
      "Epoch 256/500\n",
      "311/311 [==============================] - 12s - loss: 307.8242 - val_loss: 1572523866507444224.0000\n",
      "Epoch 257/500\n",
      "311/311 [==============================] - 12s - loss: 307.8623 - val_loss: 1650252054326673408.0000\n",
      "Epoch 258/500\n",
      "311/311 [==============================] - 12s - loss: 307.6862 - val_loss: 1837598390339239936.0000\n",
      "Epoch 259/500\n",
      "311/311 [==============================] - 12s - loss: 307.6584 - val_loss: 2030592367827877888.0000\n",
      "Epoch 260/500\n",
      "311/311 [==============================] - 12s - loss: 307.4482 - val_loss: 2113914321053417472.0000\n",
      "Epoch 261/500\n",
      "311/311 [==============================] - 12s - loss: 307.3274 - val_loss: 2266096488503312384.0000\n",
      "Epoch 262/500\n",
      "311/311 [==============================] - 12s - loss: 307.1160 - val_loss: 2393197009017241600.0000\n",
      "Epoch 263/500\n",
      "311/311 [==============================] - 12s - loss: 307.2260 - val_loss: 2468451707990835200.0000\n",
      "Epoch 264/500\n",
      "311/311 [==============================] - 12s - loss: 306.9950 - val_loss: 2597928548010295296.0000\n",
      "Epoch 265/500\n",
      "311/311 [==============================] - 12s - loss: 306.7583 - val_loss: 2877602249796747264.0000\n",
      "Epoch 266/500\n",
      "311/311 [==============================] - 12s - loss: 306.5672 - val_loss: 3362190559262277632.0000\n",
      "Epoch 267/500\n",
      "311/311 [==============================] - 12s - loss: 306.6612 - val_loss: 3880827170427240448.0000\n",
      "Epoch 268/500\n",
      "311/311 [==============================] - 12s - loss: 306.6583 - val_loss: 4427665155333029888.0000\n",
      "Epoch 269/500\n",
      "311/311 [==============================] - 12s - loss: 306.5219 - val_loss: 4780682604884000768.0000\n",
      "Epoch 270/500\n",
      "311/311 [==============================] - 12s - loss: 306.3513 - val_loss: 5109454723530883072.0000\n",
      "Epoch 271/500\n",
      "311/311 [==============================] - 12s - loss: 306.1996 - val_loss: 5674354660824055808.0000\n",
      "Epoch 272/500\n",
      "311/311 [==============================] - 12s - loss: 306.1481 - val_loss: 6379424738472624128.0000\n",
      "Epoch 273/500\n",
      "311/311 [==============================] - 12s - loss: 306.0787 - val_loss: 6612383214851850240.0000\n",
      "Epoch 274/500\n",
      "311/311 [==============================] - 12s - loss: 305.8949 - val_loss: 6606121496131665920.0000\n",
      "Epoch 275/500\n",
      "311/311 [==============================] - 12s - loss: 305.8541 - val_loss: 6965226391809818624.0000\n",
      "Epoch 276/500\n",
      "311/311 [==============================] - 12s - loss: 305.7749 - val_loss: 7560045140006404096.0000\n",
      "Epoch 277/500\n",
      "311/311 [==============================] - 12s - loss: 305.6593 - val_loss: 7776484003934109696.0000\n",
      "Epoch 278/500\n",
      "311/311 [==============================] - 12s - loss: 305.7356 - val_loss: 7539226986846093312.0000\n",
      "Epoch 279/500\n",
      "311/311 [==============================] - 12s - loss: 305.5338 - val_loss: 7275614676040286208.0000\n",
      "Epoch 280/500\n",
      "311/311 [==============================] - 12s - loss: 305.6011 - val_loss: 7078770208831176704.0000\n",
      "Epoch 281/500\n",
      "311/311 [==============================] - 12s - loss: 305.6410 - val_loss: 7040537440754335744.0000\n",
      "Epoch 282/500\n",
      "311/311 [==============================] - 12s - loss: 305.3249 - val_loss: 6869633751379345408.0000\n",
      "Epoch 283/500\n",
      "311/311 [==============================] - 12s - loss: 305.2496 - val_loss: 6478533617088724992.0000\n",
      "Epoch 284/500\n",
      "311/311 [==============================] - 12s - loss: 305.4544 - val_loss: 5896391138448769024.0000\n",
      "Epoch 285/500\n",
      "311/311 [==============================] - 12s - loss: 305.2893 - val_loss: 5465764660651229184.0000\n",
      "Epoch 286/500\n",
      "311/311 [==============================] - 12s - loss: 305.3173 - val_loss: 4995817997776977920.0000\n",
      "Epoch 287/500\n",
      "311/311 [==============================] - 12s - loss: 305.0754 - val_loss: 4963628695362207744.0000\n",
      "Epoch 288/500\n",
      "311/311 [==============================] - 12s - loss: 304.9358 - val_loss: 5309351984774512640.0000\n",
      "Epoch 289/500\n",
      "311/311 [==============================] - 12s - loss: 304.8536 - val_loss: 5952129780907245568.0000\n",
      "Epoch 290/500\n",
      "311/311 [==============================] - 12s - loss: 304.7901 - val_loss: 6266917760916258816.0000\n",
      "Epoch 291/500\n",
      "311/311 [==============================] - 12s - loss: 304.7224 - val_loss: 6155195834662125568.0000\n",
      "Epoch 292/500\n",
      "311/311 [==============================] - 12s - loss: 304.6393 - val_loss: 5945498626280128512.0000\n",
      "Epoch 293/500\n",
      "311/311 [==============================] - 12s - loss: 304.5110 - val_loss: 5533090506399023104.0000\n",
      "Epoch 294/500\n",
      "311/311 [==============================] - 12s - loss: 304.5005 - val_loss: 4743940224818610176.0000\n",
      "Epoch 295/500\n",
      "311/311 [==============================] - 13s - loss: 304.4316 - val_loss: 4170045457776508928.0000\n",
      "Epoch 296/500\n",
      "311/311 [==============================] - 13s - loss: 304.6077 - val_loss: 4173596880334225408.0000\n",
      "Epoch 297/500\n",
      "311/311 [==============================] - 12s - loss: 304.3326 - val_loss: 4195027736349114368.0000\n",
      "Epoch 298/500\n",
      "311/311 [==============================] - 12s - loss: 304.2282 - val_loss: 4409104849300357120.0000\n",
      "Epoch 299/500\n",
      "311/311 [==============================] - 12s - loss: 304.1543 - val_loss: 4215562490387365888.0000\n",
      "Epoch 300/500\n",
      "311/311 [==============================] - 12s - loss: 304.1611 - val_loss: 3935407477385854976.0000\n",
      "Epoch 301/500\n",
      "311/311 [==============================] - 12s - loss: 304.1177 - val_loss: 3807267918383677440.0000\n",
      "Epoch 302/500\n",
      "311/311 [==============================] - 12s - loss: 304.0772 - val_loss: 3721592048202022912.0000\n",
      "Epoch 303/500\n",
      "311/311 [==============================] - 12s - loss: 303.9242 - val_loss: 3499326047525011456.0000\n",
      "Epoch 304/500\n",
      "311/311 [==============================] - 12s - loss: 303.9326 - val_loss: 3636493971380764672.0000\n",
      "Epoch 305/500\n",
      "311/311 [==============================] - 12s - loss: 303.8343 - val_loss: 3928502819241328640.0000\n",
      "Epoch 306/500\n",
      "311/311 [==============================] - 12s - loss: 303.8732 - val_loss: 4108852413010542592.0000\n",
      "Epoch 307/500\n",
      "311/311 [==============================] - 12s - loss: 303.8512 - val_loss: 4232231086664450048.0000\n",
      "Epoch 308/500\n",
      "311/311 [==============================] - 12s - loss: 303.6778 - val_loss: 4268029261119488000.0000\n",
      "Epoch 309/500\n",
      "311/311 [==============================] - 12s - loss: 303.8022 - val_loss: 4423958426757890048.0000\n",
      "Epoch 310/500\n",
      "311/311 [==============================] - 12s - loss: 303.8397 - val_loss: 4519308899752345600.0000\n",
      "Epoch 311/500\n",
      "311/311 [==============================] - 13s - loss: 303.8369 - val_loss: 4911668524612583424.0000\n",
      "Epoch 312/500\n",
      "311/311 [==============================] - 12s - loss: 303.6823 - val_loss: 5051273515991302144.0000\n",
      "Epoch 313/500\n",
      "311/311 [==============================] - 12s - loss: 303.6474 - val_loss: 4877417637895733248.0000\n",
      "Epoch 314/500\n",
      "311/311 [==============================] - 12s - loss: 303.4636 - val_loss: 5392216128846036992.0000\n",
      "Epoch 315/500\n",
      "311/311 [==============================] - 13s - loss: 303.3352 - val_loss: 5816052022830432256.0000\n",
      "Epoch 316/500\n",
      "311/311 [==============================] - 12s - loss: 303.3474 - val_loss: 6750987650649292800.0000\n",
      "Epoch 317/500\n",
      "311/311 [==============================] - 12s - loss: 303.3488 - val_loss: 7655565762425257984.0000\n",
      "Epoch 318/500\n",
      "311/311 [==============================] - 12s - loss: 303.3752 - val_loss: 7728316598544498688.0000\n",
      "Epoch 319/500\n",
      "311/311 [==============================] - 12s - loss: 303.3393 - val_loss: 7601358739664273408.0000\n",
      "Epoch 320/500\n",
      "311/311 [==============================] - 13s - loss: 303.1812 - val_loss: 7515562747837284352.0000\n",
      "Epoch 321/500\n",
      "311/311 [==============================] - 12s - loss: 303.0396 - val_loss: 7759697210157039616.0000\n",
      "Epoch 322/500\n",
      "311/311 [==============================] - 12s - loss: 302.9450 - val_loss: 8261893648585588736.0000\n",
      "Epoch 323/500\n",
      "311/311 [==============================] - 12s - loss: 303.0546 - val_loss: 8723344934867828736.0000\n",
      "Epoch 324/500\n",
      "311/311 [==============================] - 12s - loss: 303.0454 - val_loss: 9414915758506377216.0000\n",
      "Epoch 325/500\n",
      "311/311 [==============================] - 12s - loss: 302.8613 - val_loss: 10439629809268031488.0000\n",
      "Epoch 326/500\n",
      "311/311 [==============================] - 12s - loss: 302.9002 - val_loss: 10739120283999797248.0000\n",
      "Epoch 327/500\n",
      "311/311 [==============================] - 12s - loss: 302.8798 - val_loss: 10928419902419107840.0000\n",
      "Epoch 328/500\n",
      "311/311 [==============================] - 12s - loss: 302.7155 - val_loss: 10822884378338656256.0000\n",
      "Epoch 329/500\n",
      "311/311 [==============================] - 12s - loss: 302.6376 - val_loss: 10572214418903400448.0000\n",
      "Epoch 330/500\n",
      "311/311 [==============================] - 12s - loss: 302.5905 - val_loss: 9821393112667258880.0000\n",
      "Epoch 331/500\n",
      "311/311 [==============================] - 12s - loss: 302.6480 - val_loss: 9341368326212812800.0000\n",
      "Epoch 332/500\n",
      "311/311 [==============================] - 12s - loss: 302.6364 - val_loss: 8642024505121701888.0000\n",
      "Epoch 333/500\n",
      "311/311 [==============================] - 12s - loss: 302.6521 - val_loss: 8106198404045996032.0000\n",
      "Epoch 334/500\n",
      "311/311 [==============================] - 12s - loss: 302.4455 - val_loss: 7849157874239406080.0000\n",
      "Epoch 335/500\n",
      "311/311 [==============================] - 12s - loss: 302.4843 - val_loss: 6844152569405636608.0000\n",
      "Epoch 336/500\n",
      "311/311 [==============================] - 12s - loss: 302.4814 - val_loss: 5978517510218055680.0000\n",
      "Epoch 337/500\n",
      "311/311 [==============================] - 12s - loss: 302.5649 - val_loss: 5326432348156198912.0000\n",
      "Epoch 338/500\n",
      "311/311 [==============================] - 12s - loss: 302.3680 - val_loss: 4868254307989848064.0000\n",
      "Epoch 339/500\n",
      "311/311 [==============================] - 12s - loss: 302.4417 - val_loss: 4679917312000655360.0000\n",
      "Epoch 340/500\n",
      "311/311 [==============================] - 12s - loss: 302.2981 - val_loss: 4972006973965860864.0000\n",
      "Epoch 341/500\n",
      "311/311 [==============================] - 12s - loss: 302.2564 - val_loss: 5159928354559754240.0000\n",
      "Epoch 342/500\n",
      "311/311 [==============================] - 12s - loss: 302.3144 - val_loss: 5353823931583168512.0000\n",
      "Epoch 343/500\n",
      "311/311 [==============================] - 12s - loss: 302.3010 - val_loss: 5405935834937425920.0000\n",
      "Epoch 344/500\n",
      "311/311 [==============================] - 12s - loss: 302.0701 - val_loss: 5267881154953871360.0000\n",
      "Epoch 345/500\n",
      "311/311 [==============================] - 12s - loss: 302.0991 - val_loss: 5354637020431908864.0000\n",
      "Epoch 346/500\n",
      "311/311 [==============================] - 12s - loss: 302.2178 - val_loss: 5433699053294583808.0000\n",
      "Epoch 347/500\n",
      "311/311 [==============================] - 14s - loss: 302.0659 - val_loss: 5310895699099910144.0000\n",
      "Epoch 348/500\n",
      "311/311 [==============================] - 12s - loss: 302.0930 - val_loss: 5031965542051741696.0000\n",
      "Epoch 349/500\n",
      "311/311 [==============================] - 12s - loss: 301.8671 - val_loss: 4934064476958752768.0000\n",
      "Epoch 350/500\n",
      "311/311 [==============================] - 12s - loss: 301.9236 - val_loss: 4968125148163997696.0000\n",
      "Epoch 351/500\n",
      "311/311 [==============================] - 13s - loss: 301.8337 - val_loss: 5283471680079921152.0000\n",
      "Epoch 352/500\n",
      "311/311 [==============================] - 12s - loss: 301.9078 - val_loss: 5528706753539080192.0000\n",
      "Epoch 353/500\n",
      "311/311 [==============================] - 13s - loss: 301.7461 - val_loss: 6047128685058719744.0000\n",
      "Epoch 354/500\n",
      "311/311 [==============================] - 13s - loss: 301.7761 - val_loss: 6607849928410529792.0000\n",
      "Epoch 355/500\n",
      "311/311 [==============================] - 13s - loss: 301.9196 - val_loss: 6867621095344701440.0000\n",
      "Epoch 356/500\n",
      "311/311 [==============================] - 12s - loss: 301.9055 - val_loss: 6815384947176505344.0000\n",
      "Epoch 357/500\n",
      "311/311 [==============================] - 13s - loss: 301.6336 - val_loss: 6883871877203230720.0000\n",
      "Epoch 358/500\n",
      "311/311 [==============================] - 13s - loss: 301.5496 - val_loss: 7456263336972255232.0000\n",
      "Epoch 359/500\n",
      "311/311 [==============================] - 12s - loss: 301.5502 - val_loss: 7810051544174297088.0000\n",
      "Epoch 360/500\n",
      "311/311 [==============================] - 12s - loss: 301.7581 - val_loss: 7588393298549538816.0000\n",
      "Epoch 361/500\n",
      "311/311 [==============================] - 13s - loss: 301.5363 - val_loss: 7621304980103757824.0000\n",
      "Epoch 362/500\n",
      "311/311 [==============================] - 12s - loss: 301.4082 - val_loss: 7241529265823416320.0000\n",
      "Epoch 363/500\n",
      "311/311 [==============================] - 12s - loss: 301.3960 - val_loss: 6564463199578488832.0000\n",
      "Epoch 364/500\n",
      "311/311 [==============================] - 12s - loss: 301.4561 - val_loss: 5439475887386918912.0000\n",
      "Epoch 365/500\n",
      "311/311 [==============================] - 12s - loss: 301.3789 - val_loss: 4464369602247262208.0000\n",
      "Epoch 366/500\n",
      "311/311 [==============================] - 12s - loss: 301.3586 - val_loss: 3486395515904458752.0000\n",
      "Epoch 367/500\n",
      "311/311 [==============================] - 12s - loss: 301.7275 - val_loss: 2683280886895476736.0000\n",
      "Epoch 368/500\n",
      "311/311 [==============================] - 12s - loss: 301.3794 - val_loss: 2179428858833403904.0000\n",
      "Epoch 369/500\n",
      "311/311 [==============================] - 12s - loss: 301.2854 - val_loss: 1976008487456473088.0000\n",
      "Epoch 370/500\n",
      "311/311 [==============================] - 12s - loss: 301.5060 - val_loss: 1865319414937681920.0000\n",
      "Epoch 371/500\n",
      "311/311 [==============================] - 12s - loss: 301.2664 - val_loss: 1673112550335578112.0000\n",
      "Epoch 372/500\n",
      "311/311 [==============================] - 12s - loss: 301.4382 - val_loss: 1654566812831973376.0000\n",
      "Epoch 373/500\n",
      "311/311 [==============================] - 12s - loss: 301.1460 - val_loss: 1674174403690102784.0000\n",
      "Epoch 374/500\n",
      "311/311 [==============================] - 12s - loss: 301.5172 - val_loss: 1704453854407426048.0000\n",
      "Epoch 375/500\n",
      "311/311 [==============================] - 12s - loss: 301.1017 - val_loss: 1881587514104348672.0000\n",
      "Epoch 376/500\n",
      "311/311 [==============================] - 12s - loss: 301.0065 - val_loss: 1876746364407250944.0000\n",
      "Epoch 377/500\n",
      "311/311 [==============================] - 12s - loss: 301.1783 - val_loss: 1838283386083344384.0000\n",
      "Epoch 378/500\n",
      "311/311 [==============================] - 12s - loss: 301.0492 - val_loss: 1990252248277450752.0000\n",
      "Epoch 379/500\n",
      "311/311 [==============================] - 12s - loss: 301.0619 - val_loss: 1895312992631783424.0000\n",
      "Epoch 380/500\n",
      "311/311 [==============================] - 12s - loss: 300.8687 - val_loss: 1805011751909982208.0000\n",
      "Epoch 381/500\n",
      "311/311 [==============================] - 12s - loss: 301.0456 - val_loss: 1610775876037771264.0000\n",
      "Epoch 382/500\n",
      "311/311 [==============================] - 12s - loss: 300.8195 - val_loss: 1384312764599631872.0000\n",
      "Epoch 383/500\n",
      "311/311 [==============================] - 12s - loss: 300.8827 - val_loss: 1282462666056531968.0000\n",
      "Epoch 384/500\n",
      "311/311 [==============================] - 12s - loss: 300.8979 - val_loss: 1022103672718360576.0000\n",
      "Epoch 385/500\n",
      "311/311 [==============================] - 12s - loss: 300.7909 - val_loss: 581873098291150848.0000\n",
      "Epoch 386/500\n",
      "311/311 [==============================] - 12s - loss: 300.7558 - val_loss: 390131533266026496.0000\n",
      "Epoch 387/500\n",
      "311/311 [==============================] - 12s - loss: 300.8462 - val_loss: 280888627775406080.0000\n",
      "Epoch 388/500\n",
      "311/311 [==============================] - 12s - loss: 300.7217 - val_loss: 239185594842873856.0000\n",
      "Epoch 389/500\n",
      "311/311 [==============================] - 12s - loss: 300.6712 - val_loss: 203511596482297856.0000\n",
      "Epoch 390/500\n",
      "311/311 [==============================] - 12s - loss: 300.8098 - val_loss: 106703085170065408.0000\n",
      "Epoch 391/500\n",
      "311/311 [==============================] - 12s - loss: 300.6166 - val_loss: 45987610702643200.0000\n",
      "Epoch 392/500\n",
      "311/311 [==============================] - 12s - loss: 300.6167 - val_loss: 35530404718968832.0000\n",
      "Epoch 393/500\n",
      "311/311 [==============================] - 12s - loss: 300.6369 - val_loss: 35819305694134272.0000\n",
      "Epoch 394/500\n",
      "311/311 [==============================] - 12s - loss: 300.5058 - val_loss: 35437730062139392.0000\n",
      "Epoch 395/500\n",
      "311/311 [==============================] - 12s - loss: 300.5567 - val_loss: 33447702062694400.0000\n",
      "Epoch 396/500\n",
      "311/311 [==============================] - 12s - loss: 300.4364 - val_loss: 35411970995781632.0000\n",
      "Epoch 397/500\n",
      "311/311 [==============================] - 12s - loss: 300.4589 - val_loss: 36951201375322112.0000\n",
      "Epoch 398/500\n",
      "311/311 [==============================] - 12s - loss: 300.5281 - val_loss: 39409803864309760.0000\n",
      "Epoch 399/500\n",
      "311/311 [==============================] - 12s - loss: 300.5039 - val_loss: 43419374878457856.0000\n",
      "Epoch 400/500\n",
      "311/311 [==============================] - 12s - loss: 300.4521 - val_loss: 67842955515265024.0000\n",
      "Epoch 401/500\n",
      "311/311 [==============================] - 12s - loss: 300.2886 - val_loss: 128226729658417152.0000\n",
      "Epoch 402/500\n",
      "311/311 [==============================] - 12s - loss: 300.2943 - val_loss: 183511926649651200.0000\n",
      "Epoch 403/500\n",
      "311/311 [==============================] - 12s - loss: 300.3311 - val_loss: 187973607396212736.0000\n",
      "Epoch 404/500\n",
      "311/311 [==============================] - 12s - loss: 300.2682 - val_loss: 192718257768103936.0000\n",
      "Epoch 405/500\n",
      "311/311 [==============================] - 12s - loss: 300.3052 - val_loss: 285819559468859392.0000\n",
      "Epoch 406/500\n",
      "311/311 [==============================] - 12s - loss: 300.2925 - val_loss: 408088482292957184.0000\n",
      "Epoch 407/500\n",
      "311/311 [==============================] - 12s - loss: 300.1546 - val_loss: 555648818255757312.0000\n",
      "Epoch 408/500\n",
      "311/311 [==============================] - 12s - loss: 300.1315 - val_loss: 591231591510966272.0000\n",
      "Epoch 409/500\n",
      "311/311 [==============================] - 12s - loss: 300.2506 - val_loss: 556427959682990080.0000\n",
      "Epoch 410/500\n",
      "311/311 [==============================] - 12s - loss: 300.2261 - val_loss: 524126197844541440.0000\n",
      "Epoch 411/500\n",
      "311/311 [==============================] - 12s - loss: 300.0544 - val_loss: 611697900950388736.0000\n",
      "Epoch 412/500\n",
      "311/311 [==============================] - 12s - loss: 300.1128 - val_loss: 623036683331305472.0000\n",
      "Epoch 413/500\n",
      "311/311 [==============================] - 12s - loss: 300.1398 - val_loss: 615301825188331520.0000\n",
      "Epoch 414/500\n",
      "311/311 [==============================] - 12s - loss: 300.0306 - val_loss: 660522470696026112.0000\n",
      "Epoch 415/500\n",
      "311/311 [==============================] - 12s - loss: 299.9971 - val_loss: 756481523376455680.0000\n",
      "Epoch 416/500\n",
      "311/311 [==============================] - 12s - loss: 299.9613 - val_loss: 644993586940608512.0000\n",
      "Epoch 417/500\n",
      "311/311 [==============================] - 12s - loss: 300.1006 - val_loss: 486714558795218944.0000\n",
      "Epoch 418/500\n",
      "311/311 [==============================] - 12s - loss: 299.9440 - val_loss: 372469493873508352.0000\n",
      "Epoch 419/500\n",
      "311/311 [==============================] - 12s - loss: 299.9203 - val_loss: 165780463405760512.0000\n",
      "Epoch 420/500\n",
      "311/311 [==============================] - 13s - loss: 299.9990 - val_loss: 6873577076817920.0000\n",
      "Epoch 421/500\n",
      "311/311 [==============================] - 14s - loss: 299.9367 - val_loss: 3097964742443008.0000\n",
      "Epoch 422/500\n",
      "311/311 [==============================] - 14s - loss: 299.9875 - val_loss: 1873218042331136.0000\n",
      "Epoch 423/500\n",
      "311/311 [==============================] - 12s - loss: 299.9360 - val_loss: 1719834828079104.0000\n",
      "Epoch 424/500\n",
      "311/311 [==============================] - 12s - loss: 299.8518 - val_loss: 1731659141480448.0000\n",
      "Epoch 425/500\n",
      "311/311 [==============================] - 13s - loss: 299.8723 - val_loss: 1754235502854144.0000\n",
      "Epoch 426/500\n",
      "311/311 [==============================] - 12s - loss: 299.9951 - val_loss: 1783568653090816.0000\n",
      "Epoch 427/500\n",
      "311/311 [==============================] - 13s - loss: 299.8816 - val_loss: 1807038099226624.0000\n",
      "Epoch 428/500\n",
      "311/311 [==============================] - 12s - loss: 299.7386 - val_loss: 1824010602020864.0000\n",
      "Epoch 429/500\n",
      "311/311 [==============================] - 12s - loss: 299.7862 - val_loss: 1808840374878208.0000\n",
      "Epoch 430/500\n",
      "311/311 [==============================] - 13s - loss: 299.8457 - val_loss: 1840467574521856.0000\n",
      "Epoch 431/500\n",
      "311/311 [==============================] - 12s - loss: 299.7014 - val_loss: 1869295663448064.0000\n",
      "Epoch 432/500\n",
      "311/311 [==============================] - 12s - loss: 299.7559 - val_loss: 1817543991885824.0000\n",
      "Epoch 433/500\n",
      "311/311 [==============================] - 12s - loss: 299.6126 - val_loss: 1838291636715520.0000\n",
      "Epoch 434/500\n",
      "311/311 [==============================] - 12s - loss: 299.7924 - val_loss: 1838303045222400.0000\n",
      "Epoch 435/500\n",
      "311/311 [==============================] - 12s - loss: 299.6450 - val_loss: 1906435856269312.0000\n",
      "Epoch 436/500\n",
      "311/311 [==============================] - 12s - loss: 299.5288 - val_loss: 2153294604533760.0000\n",
      "Epoch 437/500\n",
      "311/311 [==============================] - 12s - loss: 299.7201 - val_loss: 2988793116229632.0000\n",
      "Epoch 438/500\n",
      "311/311 [==============================] - 12s - loss: 299.6052 - val_loss: 3455941139759104.0000\n",
      "Epoch 439/500\n",
      "311/311 [==============================] - 12s - loss: 299.6596 - val_loss: 3946018919940096.0000\n",
      "Epoch 440/500\n",
      "311/311 [==============================] - 12s - loss: 299.8310 - val_loss: 3861768036155392.0000\n",
      "Epoch 441/500\n",
      "311/311 [==============================] - 12s - loss: 299.4715 - val_loss: 4371114381803520.0000\n",
      "Epoch 442/500\n",
      "311/311 [==============================] - 12s - loss: 299.5673 - val_loss: 4251050718527488.0000\n",
      "Epoch 443/500\n",
      "311/311 [==============================] - 12s - loss: 299.6302 - val_loss: 5740083667795968.0000\n",
      "Epoch 444/500\n",
      "311/311 [==============================] - 12s - loss: 299.4029 - val_loss: 5093045234040832.0000\n",
      "Epoch 445/500\n",
      "311/311 [==============================] - 13s - loss: 299.4508 - val_loss: 2945081086574592.0000\n",
      "Epoch 446/500\n",
      "311/311 [==============================] - 13s - loss: 299.5060 - val_loss: 1918622289100800.0000\n",
      "Epoch 447/500\n",
      "311/311 [==============================] - 13s - loss: 299.4951 - val_loss: 1875512091738112.0000\n",
      "Epoch 448/500\n",
      "311/311 [==============================] - 12s - loss: 299.3310 - val_loss: 1903930011287552.0000\n",
      "Epoch 449/500\n",
      "311/311 [==============================] - 12s - loss: 299.3265 - val_loss: 3601866680172544.0000\n",
      "Epoch 450/500\n",
      "311/311 [==============================] - 12s - loss: 299.2993 - val_loss: 6993073267539968.0000\n",
      "Epoch 451/500\n",
      "311/311 [==============================] - 12s - loss: 299.2845 - val_loss: 11168005891293184.0000\n",
      "Epoch 452/500\n",
      "311/311 [==============================] - 12s - loss: 299.2668 - val_loss: 12898569547677696.0000\n",
      "Epoch 453/500\n",
      "311/311 [==============================] - 12s - loss: 299.4983 - val_loss: 12246009396592640.0000\n",
      "Epoch 454/500\n",
      "311/311 [==============================] - 12s - loss: 299.2503 - val_loss: 11068116763148288.0000\n",
      "Epoch 455/500\n",
      "311/311 [==============================] - 12s - loss: 299.1868 - val_loss: 14108220243050496.0000\n",
      "Epoch 456/500\n",
      "311/311 [==============================] - 12s - loss: 299.1163 - val_loss: 13873388611174400.0000\n",
      "Epoch 457/500\n",
      "311/311 [==============================] - 12s - loss: 299.2265 - val_loss: 13365366994501632.0000\n",
      "Epoch 458/500\n",
      "311/311 [==============================] - 12s - loss: 299.1765 - val_loss: 10066784866533376.0000\n",
      "Epoch 459/500\n",
      "311/311 [==============================] - 12s - loss: 299.0980 - val_loss: 8532966145785856.0000\n",
      "Epoch 460/500\n",
      "311/311 [==============================] - 12s - loss: 299.1576 - val_loss: 5856005371985920.0000\n",
      "Epoch 461/500\n",
      "311/311 [==============================] - 12s - loss: 299.1436 - val_loss: 4426504159100928.0000\n",
      "Epoch 462/500\n",
      "311/311 [==============================] - 12s - loss: 299.0600 - val_loss: 3694578112659456.0000\n",
      "Epoch 463/500\n",
      "311/311 [==============================] - 12s - loss: 299.2154 - val_loss: 3782006466936832.0000\n",
      "Epoch 464/500\n",
      "311/311 [==============================] - 12s - loss: 299.1419 - val_loss: 5106470228066304.0000\n",
      "Epoch 465/500\n",
      "311/311 [==============================] - 12s - loss: 299.0688 - val_loss: 7097146767572992.0000\n",
      "Epoch 466/500\n",
      "311/311 [==============================] - 12s - loss: 299.0470 - val_loss: 10758659000762368.0000\n",
      "Epoch 467/500\n",
      "311/311 [==============================] - 12s - loss: 299.0397 - val_loss: 13162114109669376.0000\n",
      "Epoch 468/500\n",
      "311/311 [==============================] - 12s - loss: 299.0514 - val_loss: 11724942890500096.0000\n",
      "Epoch 469/500\n",
      "311/311 [==============================] - 12s - loss: 298.9713 - val_loss: 8889371121942528.0000\n",
      "Epoch 470/500\n",
      "311/311 [==============================] - 12s - loss: 298.9727 - val_loss: 7761787051048960.0000\n",
      "Epoch 471/500\n",
      "311/311 [==============================] - 12s - loss: 298.8955 - val_loss: 3462286417068032.0000\n",
      "Epoch 472/500\n",
      "311/311 [==============================] - 12s - loss: 299.0143 - val_loss: 1614040790990848.0000\n",
      "Epoch 473/500\n",
      "311/311 [==============================] - 12s - loss: 298.9084 - val_loss: 1110688206422016.0000\n",
      "Epoch 474/500\n",
      "311/311 [==============================] - 12s - loss: 298.9279 - val_loss: 1046331007172608.0000\n",
      "Epoch 475/500\n",
      "311/311 [==============================] - 12s - loss: 299.0130 - val_loss: 457445121982464.0000\n",
      "Epoch 476/500\n",
      "311/311 [==============================] - 12s - loss: 298.8894 - val_loss: 11430239414517760.0000\n",
      "Epoch 477/500\n",
      "311/311 [==============================] - 12s - loss: 298.8811 - val_loss: 32169442485993472.0000\n",
      "Epoch 478/500\n",
      "311/311 [==============================] - 12s - loss: 298.8175 - val_loss: 51079753993551872.0000\n",
      "Epoch 479/500\n",
      "311/311 [==============================] - 12s - loss: 298.8454 - val_loss: 90767571090931712.0000\n",
      "Epoch 480/500\n",
      "311/311 [==============================] - 12s - loss: 298.8786 - val_loss: 159090742604595200.0000\n",
      "Epoch 481/500\n",
      "311/311 [==============================] - 12s - loss: 298.8359 - val_loss: 138577008136290304.0000\n",
      "Epoch 482/500\n",
      "311/311 [==============================] - 12s - loss: 298.7936 - val_loss: 102238346406789120.0000\n",
      "Epoch 483/500\n",
      "311/311 [==============================] - 12s - loss: 298.7434 - val_loss: 54319520839368704.0000\n",
      "Epoch 484/500\n",
      "311/311 [==============================] - 13s - loss: 298.7821 - val_loss: 10425627236630528.0000\n",
      "Epoch 485/500\n",
      "311/311 [==============================] - 13s - loss: 298.7684 - val_loss: 622484575485952.0000\n",
      "Epoch 486/500\n",
      "311/311 [==============================] - 12s - loss: 298.7586 - val_loss: 619705261883392.0000\n",
      "Epoch 487/500\n",
      "311/311 [==============================] - 12s - loss: 298.7046 - val_loss: 623793936531456.0000\n",
      "Epoch 488/500\n",
      "311/311 [==============================] - 12s - loss: 298.7552 - val_loss: 633335743250432.0000\n",
      "Epoch 489/500\n",
      "311/311 [==============================] - 12s - loss: 298.7144 - val_loss: 649799627964416.0000\n",
      "Epoch 490/500\n",
      "311/311 [==============================] - 12s - loss: 298.6538 - val_loss: 668502667034624.0000\n",
      "Epoch 491/500\n",
      "311/311 [==============================] - 12s - loss: 298.6812 - val_loss: 691468528254976.0000\n",
      "Epoch 492/500\n",
      "311/311 [==============================] - 12s - loss: 298.6289 - val_loss: 716295184056320.0000\n",
      "Epoch 493/500\n",
      "311/311 [==============================] - 12s - loss: 298.6334 - val_loss: 742612864598016.0000\n",
      "Epoch 494/500\n",
      "311/311 [==============================] - 12s - loss: 298.7835 - val_loss: 774288651059200.0000\n",
      "Epoch 495/500\n",
      "311/311 [==============================] - 12s - loss: 298.6510 - val_loss: 811628895404032.0000\n",
      "Epoch 496/500\n",
      "311/311 [==============================] - 12s - loss: 298.5622 - val_loss: 857266613911552.0000\n",
      "Epoch 497/500\n",
      "311/311 [==============================] - 12s - loss: 298.6779 - val_loss: 911192344231936.0000\n",
      "Epoch 498/500\n",
      "311/311 [==============================] - 12s - loss: 298.5238 - val_loss: 973737805479936.0000\n",
      "Epoch 499/500\n",
      "311/311 [==============================] - 12s - loss: 298.5743 - val_loss: 1046784797310976.0000\n",
      "Epoch 500/500\n",
      "311/311 [==============================] - 12s - loss: 298.6637 - val_loss: 1124203059216384.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train, batch_size=128, nb_epoch=500, validation_split=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check model predictions\n",
    "\n",
    "randnumber = np.random.randint(len(data))\n",
    "print(data['X'][randnumber])\n",
    "sample_raw = X_train[randnumber,:,:,:]\n",
    "sample = sample_raw.reshape((1,)+sample_raw.shape)\n",
    "\n",
    "speed_prediction = model.predict(sample)\n",
    "speed_prediction = speed_prediction[0,:,:,0]\n",
    "speed_true = y_train[randnumber,:,:,0]\n",
    "\n",
    "from pylab import *\n",
    "from matplotlib import gridspec\n",
    "cdict = {'red': ((0.0, 0.0, 0.0),\n",
    "                 (0.125, 165/255, 165/255),\n",
    "                 (0.25, 1.0, 1.0),\n",
    "                 (0.5625, 1.0, 1.0),\n",
    "                 (1.0, 0.0, 0.0)),\n",
    "         'green': ((0.0, 0.0, 0.0),\n",
    "                   (0.25, 0.0, 0.0),\n",
    "                   (0.5625, 1.0, 1.0),\n",
    "                   (1.0, 1.0, 1.0)),\n",
    "         'blue': ((0.0, 0.0, 0.0),\n",
    "                  (0.5, 0.0, 0.0),\n",
    "                  (1.0, 0.0, 0.0))}\n",
    "my_cmap = matplotlib.colors.LinearSegmentedColormap('my_colormap',cdict,256)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "gs = gridspec.GridSpec(3, 3,hspace=0,wspace=0) \n",
    "for i in range(9):\n",
    "    plt.subplot(gs[i])\n",
    "    plt.pcolor(sample_raw[:,:,i],cmap=plt.cm.Blues)\n",
    "plt.figure(figsize=(12,4))\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[5,6]) \n",
    "gs.update(left=0,right=1,hspace=0,wspace=0)\n",
    "plt.subplot(gs[0])\n",
    "plt.pcolor(speed_true,cmap=my_cmap)\n",
    "plt.subplot(gs[1])\n",
    "plt.pcolor(speed_prediction,cmap=my_cmap)\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "from keras.models import model_from_json\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"structure1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"structure1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "\n",
    "json_file = open('structure1.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(\"structure1.h5\")\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# later...\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print \"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:CarND]",
   "language": "python",
   "name": "conda-env-CarND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
