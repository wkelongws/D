{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import concatenate, merge, Dense, LSTM, Input, Reshape, Convolution2D, Deconvolution2D, Flatten, Dropout, MaxPooling2D, Activation\n",
    "from keras.activations import relu, softmax, linear\n",
    "from keras.layers.advanced_activations import PReLU, ELU\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "# import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.utils import shuffle\n",
    "from pylab import *\n",
    "from matplotlib import gridspec\n",
    "cdict = {'red': ((0.0, 1.0, 1.0),\n",
    "                 (0.125, 1.0, 1.0),\n",
    "                 (0.25, 1.0, 1.0),\n",
    "                 (0.5625, 1.0, 1.0),\n",
    "                 (1.0, 0.0, 0.0)),\n",
    "         'green': ((0.0, 0.0, 0.0),\n",
    "                   (0.25, 0.0, 0.0),\n",
    "                   (0.5625, 1.0, 1.0),\n",
    "                   (1.0, 1.0, 1.0)),\n",
    "         'blue': ((0.0, 0.0, 0.0),\n",
    "                  (0.5, 0.0, 0.0),\n",
    "                  (1.0, 0.0, 0.0))}\n",
    "my_cmap = matplotlib.colors.LinearSegmentedColormap('my_colormap',cdict,256)\n",
    "\n",
    "%matplotlib inline\n",
    "%autoreload 2\n",
    "#datapath = '/home/microway/Shuo/CarND/CarND-BehaviorCloning-Project/data-given/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "(Traffic,Speed,data) = pickle.load( open( \"speed_short_term.p\", \"rb\" ) )\n",
    "Count = Traffic[:,:,:,1]\n",
    "Occup = Traffic[:,:,:,2]\n",
    "print(Traffic.shape)\n",
    "print(Speed.shape)\n",
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "from lib.Function_DOW_Normalizer import get_certain_dayofweek,MinMax_Normalization,transfer_scale\n",
    "from lib.Function_CreateInput import shapeback,create_dataset,create_dataset_historyAsFeature,create_dataset_historyAsSecondInput\n",
    "from lib.Function_VisualizeResult import history_plot,history_plot_historyAsFeature,history_plot_historyAsSecondInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_speed, _, _, _, _ = get_certain_dayofweek(data,Speed[:334],dayofweek = 0)\n",
    "test_speed = train_speed[-1:]\n",
    "train_speed = train_speed[:-1]\n",
    "\n",
    "print('train_speed.shape = ',train_speed.shape)\n",
    "print('test_speed.shape = ',test_speed.shape)\n",
    "look_back = 15\n",
    "mode = 'uni'\n",
    "train_speed_x,train_speed_y = create_dataset(train_speed,train_speed, look_back, mode)\n",
    "test_speed_x,test_speed_y = create_dataset(test_speed,test_speed, look_back, mode)\n",
    "print('look_back = ',look_back)\n",
    "print('mode = ',mode)\n",
    "print('train_speed_x.shape = ',train_speed_x.shape)\n",
    "print('train_speed_y.shape = ',train_speed_y.shape)\n",
    "print('test_speed_x.shape = ',test_speed_x.shape)\n",
    "print('test_speed_y.shape = ',test_speed_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment1: input: univariate speed; output: univariate speed; lookback = 15; same day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib.Experiment1 import Experiment1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = Experiment1(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plot(history,'images/history_exp1.png','images/test_exp1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment1.1: input: univariate speed; output: univariate speed; lookback = 15; all year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib.Experiment1_1 import Experiment1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = Experiment1_1(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_plot(history,'images/history_exp11.png','images/test_exp11.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment2: input: univariate speed; output: univariate speed; lookback = 15; lookback weeks = 15 (as feature); consecutive previous days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib.Experiment2 import Experiment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = Experiment2(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_plot_historyAsFeature(history,'images/history_exp2.png','images/test_exp2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment2.1: input: univariate speed; output: univariate speed; lookback = 15; lookback weeks = 15 (as feature); previous same day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib.Experiment2_1 import Experiment2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = Experiment2_1(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_plot_historyAsFeature(history,'images/history_exp21.png','images/test_exp21.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_speed = Speed[333:334,:,:]\n",
    "# train_speed = Speed[:334,:,:]\n",
    "# dayofweek = data['dayofweek'][333]\n",
    "# train_speed = Speed[data.index[data['dayofweek'] == dayofweek],:,:]\n",
    "# train_speed = train_speed[0:48,:,:]\n",
    "# print('train_speed.shape = ',train_speed.shape)\n",
    "# # print('test_speed.shape = ',test_speed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look_back = 15\n",
    "# mode = 'uni'\n",
    "# train_speed_x,train_speed_y = create_dataset_historyAsFeature(train_speed,train_speed, look_back, mode)\n",
    "# # test_speed_x,test_speed_y = create_dataset_historyAsFeature(test_speed, look_back, mode)\n",
    "# test_speed_x = train_speed_x[-1:,:,:,:]\n",
    "# test_speed_y = train_speed_y[-1:,:,:]\n",
    "# train_speed_x = train_speed_x[:-1,:,:,:]\n",
    "# train_speed_y = train_speed_y[:-1,:,:]\n",
    "# print('look_back = ',look_back)\n",
    "# print('mode = ',mode)\n",
    "# print('train_speed_x.shape = ',train_speed_x.shape)\n",
    "# print('train_speed_y.shape = ',train_speed_y.shape)\n",
    "# print('test_speed_x.shape = ',test_speed_x.shape)\n",
    "# print('test_speed_y.shape = ',test_speed_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(test_speed_y[0,390:510,:])  #12-19-2016 Monday 6:30AM - 8:30AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = train_speed_x.shape[1]\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(32, input_shape=(look_back, train_speed_x.shape[3]), stateful=False, return_sequences=True))\n",
    "# # model.add(Dropout(0.3))\n",
    "# model.add(LSTM(32, input_shape=(look_back, train_speed_x.shape[3]), stateful=False))\n",
    "# # model.add(Dropout(0.3))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# train_x = np.reshape(train_speed_x,(train_speed_x.shape[0]*train_speed_x.shape[1],train_speed_x.shape[2],train_speed_x.shape[3]))\n",
    "# train_y = np.reshape(train_speed_y,(train_speed_y.shape[0]*train_speed_y.shape[1],train_speed_y.shape[2]))\n",
    "# history = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "# # history_plot_historyAsFeature(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_plot_historyAsFeature(history,'images/history_exp21.png','images/test_exp21.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment3: input: univariate speed; output: univariate speed; lookback = 15; lookback weeks = 6 (parallel structure); Monday only for training, Monday for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_speed, _, _, _, _ = get_certain_dayofweek(Speed[:334],dayofweek = 0)\n",
    "# # test_speed = train_speed[-1:]\n",
    "# # train_speed = train_speed[:-1]\n",
    "\n",
    "# print('train_speed.shape = ',train_speed.shape)\n",
    "# # print('test_speed.shape = ',test_speed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look_back = 15\n",
    "# look_back_days = 6\n",
    "# mode = 'uni'\n",
    "# train_speed_x1,train_speed_x2,train_speed_y = create_dataset_historyAsSecondInput(train_speed,train_speed, look_back, look_back_days, mode)\n",
    "\n",
    "# test_speed_x1 = train_speed_x1[-1:,:,:,:]\n",
    "# test_speed_x2 = train_speed_x2[-1:,:,:,:]\n",
    "# test_speed_y = train_speed_y[-1:,:,:]\n",
    "# train_speed_x1 = train_speed_x1[:-1,:,:,:]\n",
    "# train_speed_x2 = train_speed_x2[:-1,:,:,:]\n",
    "# train_speed_y = train_speed_y[:-1,:,:]\n",
    "\n",
    "# print('look_back = ',look_back)\n",
    "# print('look_back_days = ',look_back_days)\n",
    "# print('mode = ',mode)\n",
    "# print('train_speed_x1.shape = ',train_speed_x1.shape)\n",
    "# print('train_speed_x2.shape = ',train_speed_x2.shape)\n",
    "# print('train_speed_y.shape = ',train_speed_y.shape)\n",
    "# print('test_speed_x1.shape = ',test_speed_x1.shape)\n",
    "# print('test_speed_x2.shape = ',test_speed_x2.shape)\n",
    "# print('test_speed_y.shape = ',test_speed_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(test_speed_y[0,390:510,:])  #12-19-2016 Monday 6:30AM - 8:30AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = train_speed_x.shape[1]\n",
    "\n",
    "\n",
    "# todaySequence = Input(shape=(look_back, train_speed_x1.shape[3]),name='todaySequence')\n",
    "# h1=LSTM(32, input_shape=(look_back, train_speed_x1.shape[3]), stateful=False, return_sequences=True)(todaySequence)\n",
    "# h1=LSTM(32, input_shape=(look_back, train_speed_x1.shape[3]), stateful=False)(h1)\n",
    "\n",
    "# historySequence = Input(shape=(look_back_days, train_speed_x2.shape[3]),name='historySequence')\n",
    "# h2=LSTM(32, input_shape=(look_back, train_speed_x2.shape[3]), stateful=False, return_sequences=True)(historySequence)\n",
    "# h2=LSTM(32, input_shape=(look_back, train_speed_x2.shape[3]), stateful=False)(h2)\n",
    "\n",
    "# h3 = keras.layers.concatenate([h1, h2])\n",
    "# predictedSpeed = Dense(1,name='predictedSpeed')(h3)\n",
    "\n",
    "# model = Model(inputs=[todaySequence, historySequence], outputs=[predictedSpeed])\n",
    "\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# # model.compile(optimizer='rmsprop',\n",
    "# #               loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'},\n",
    "# #               loss_weights={'main_output': 1., 'aux_output': 0.2})\n",
    "\n",
    "# train_x1 = np.reshape(train_speed_x1,(train_speed_x1.shape[0]*train_speed_x1.shape[1],train_speed_x1.shape[2],train_speed_x1.shape[3]))\n",
    "# train_x2 = np.reshape(train_speed_x2,(train_speed_x2.shape[0]*train_speed_x2.shape[1],train_speed_x2.shape[2],train_speed_x2.shape[3]))\n",
    "# train_y = np.reshape(train_speed_y,(train_speed_y.shape[0]*train_speed_y.shape[1],train_speed_y.shape[2]))\n",
    "\n",
    "# history = model.fit({'todaySequence': train_x1, 'historySequence': train_x2},\n",
    "#           {'predictedSpeed': train_y},\n",
    "#           epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "\n",
    "# # history_plot_historyAsSecondInput(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_plot_historyAsSecondInput(history,'images/history_exp3.png','images/test_exp3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment3.1: input: univariate speed; output: univariate speed; lookback = 15; lookback weeks = 6 (parallel structure); all weekdays for training, monday for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_speed = Speed[333:334,:,:]\n",
    "# # train_speed = Speed[:334,:,:]\n",
    "# # dayofweek = data['dayofweek'][333]\n",
    "# train_speed0,_,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 0)\n",
    "# train_speed1,_,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 1)\n",
    "# train_speed2,_,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 2)\n",
    "# train_speed3,_,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 3)\n",
    "# train_speed4,_,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 4)\n",
    "# train_speed5,_,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 5)\n",
    "# train_speed6,_,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 6)\n",
    "# # train_speed0 = train_speed0[0:48,:,:]\n",
    "# print('train_speed0.shape = ',train_speed.shape)\n",
    "# # print('test_speed.shape = ',test_speed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look_back = 15\n",
    "# look_back_days = 6\n",
    "# mode = 'uni'\n",
    "# train_speed_x1,train_speed_x2,train_speed_y = create_dataset_historyAsSecondInput(train_speed0,train_speed0, look_back, look_back_days, mode)\n",
    "\n",
    "# test_speed_x1 = train_speed_x1[-1:,:,:,:]\n",
    "# test_speed_x2 = train_speed_x2[-1:,:,:,:]\n",
    "# test_speed_y = train_speed_y[-1:,:,:]\n",
    "# train_speed_x1 = train_speed_x1[:-1,:,:,:]\n",
    "# train_speed_x2 = train_speed_x2[:-1,:,:,:]\n",
    "# train_speed_y = train_speed_y[:-1,:,:]\n",
    "\n",
    "\n",
    "# train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed1,train_speed1, look_back, look_back_days, mode)\n",
    "# train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "# train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "# train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "# train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed2,train_speed2, look_back, look_back_days, mode)\n",
    "# train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "# train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "# train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "# train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed3,train_speed3, look_back, look_back_days, mode)\n",
    "# train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "# train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "# train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "# train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed4,train_speed4, look_back, look_back_days, mode)\n",
    "# train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "# train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "# train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "# train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed5,train_speed5, look_back, look_back_days, mode)\n",
    "# train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "# train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "# train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "# train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed6,train_speed6, look_back, look_back_days, mode)\n",
    "# train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "# train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "# train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "\n",
    "# print('look_back = ',look_back)\n",
    "# print('look_back_days = ',look_back_days)\n",
    "# print('mode = ',mode)\n",
    "# print('train_speed_x1.shape = ',train_speed_x1.shape)\n",
    "# print('train_speed_x2.shape = ',train_speed_x2.shape)\n",
    "# print('train_speed_y.shape = ',train_speed_y.shape)\n",
    "# print('test_speed_x1.shape = ',test_speed_x1.shape)\n",
    "# print('test_speed_x2.shape = ',test_speed_x2.shape)\n",
    "# print('test_speed_y.shape = ',test_speed_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(test_speed_y[0,390:510,:])  #12-19-2016 Monday 6:30AM - 8:30AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = train_speed_x.shape[1]\n",
    "\n",
    "# todaySequence = Input(shape=(look_back, train_speed_x1.shape[3]),name='todaySequence')\n",
    "# h1=LSTM(32, input_shape=(look_back, train_speed_x1.shape[3]), stateful=False, return_sequences=True)(todaySequence)\n",
    "# h1=LSTM(32, input_shape=(look_back, train_speed_x1.shape[3]), stateful=False)(h1)\n",
    "\n",
    "# historySequence = Input(shape=(look_back_days, train_speed_x2.shape[3]),name='historySequence')\n",
    "# h2=LSTM(32, input_shape=(look_back, train_speed_x2.shape[3]), stateful=False, return_sequences=True)(historySequence)\n",
    "# h2=LSTM(32, input_shape=(look_back, train_speed_x2.shape[3]), stateful=False)(h2)\n",
    "\n",
    "# h3 = keras.layers.concatenate([h1, h2])\n",
    "# predictedSpeed = Dense(1,name='predictedSpeed')(h3)\n",
    "\n",
    "# model = Model(inputs=[todaySequence, historySequence], outputs=[predictedSpeed])\n",
    "\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# # model.compile(optimizer='rmsprop',\n",
    "# #               loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'},\n",
    "# #               loss_weights={'main_output': 1., 'aux_output': 0.2})\n",
    "\n",
    "# train_x1 = np.reshape(train_speed_x1,(train_speed_x1.shape[0]*train_speed_x1.shape[1],train_speed_x1.shape[2],train_speed_x1.shape[3]))\n",
    "# train_x2 = np.reshape(train_speed_x2,(train_speed_x2.shape[0]*train_speed_x2.shape[1],train_speed_x2.shape[2],train_speed_x2.shape[3]))\n",
    "# train_y = np.reshape(train_speed_y,(train_speed_y.shape[0]*train_speed_y.shape[1],train_speed_y.shape[2]))\n",
    "\n",
    "# history = model.fit({'todaySequence': train_x1, 'historySequence': train_x2},\n",
    "#           {'predictedSpeed': train_y},\n",
    "#           epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "\n",
    "# # history_plot_historyAsSecondInput(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_plot_historyAsSecondInput(history,'images/history_exp31.png','images/test_exp31.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment4: input: univariate speed; output: univariate delta speed; lookback = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mon, Mon_delta, Mon_Z, mon_mean, mon_std = get_certain_dayofweek(Speed,dayofweek = 0)\n",
    "# train_speed, train_speed_y, _, mean0, _ = get_certain_dayofweek(Speed[:334],dayofweek = 0)\n",
    "# test_speed = train_speed[-1:]\n",
    "# train_speed = train_speed[:-1]\n",
    "# test_speed_y = train_speed_y[-1:]\n",
    "# train_speed_y = train_speed_y[:-1]\n",
    "\n",
    "\n",
    "# print('train_speed.shape = ',train_speed.shape)\n",
    "# print('test_speed.shape = ',test_speed.shape)\n",
    "\n",
    "# test_speed = Speed[333:334,:,:]\n",
    "# train_speed = Speed[:334,:,:]\n",
    "train_speed0,train_speed_y0,_,mean0,_ = get_certain_dayofweek(Speed[:334],dayofweek = 0)\n",
    "train_speed1,train_speed_y1,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 1)\n",
    "train_speed2,train_speed_y2,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 2)\n",
    "train_speed3,train_speed_y3,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 3)\n",
    "train_speed4,train_speed_y4,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 4)\n",
    "train_speed5,train_speed_y5,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 5)\n",
    "train_speed6,train_speed_y6,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 6)\n",
    "# train_speed0 = train_speed0[0:48,:,:]\n",
    "print('train_speed0.shape = ',train_speed.shape)\n",
    "# print('test_speed.shape = ',test_speed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look_back = 15\n",
    "# mode = 'uni'\n",
    "# train_speed_x,train_speed_y = create_dataset(train_speed,train_speed_y, look_back, mode)\n",
    "# test_speed_x,test_speed_y = create_dataset(test_speed,test_speed_y, look_back, mode)\n",
    "# print('look_back = ',look_back)\n",
    "# print('mode = ',mode)\n",
    "# print('train_speed_x.shape = ',train_speed_x.shape)\n",
    "# print('train_speed_y.shape = ',train_speed_y.shape)\n",
    "# print('test_speed_x.shape = ',test_speed_x.shape)\n",
    "# print('test_speed_y.shape = ',test_speed_y.shape)\n",
    "\n",
    "look_back = 15\n",
    "mode = 'uni'\n",
    "train_speed_x,train_speed_y = create_dataset(train_speed0,train_speed_y0, look_back, mode)\n",
    "\n",
    "test_speed_x = train_speed_x[-1:,:,:,:]\n",
    "test_speed_y = train_speed_y[-1:,:,:]\n",
    "train_speed_x = train_speed_x[:-1,:,:,:]\n",
    "train_speed_y = train_speed_y[:-1,:,:]\n",
    "\n",
    "train_speed_x10,train_speed_y0 = create_dataset(train_speed1,train_speed_y1, look_back,mode)\n",
    "train_speed_x = np.concatenate((train_speed_x,train_speed_x10),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_y0 = create_dataset(train_speed2,train_speed_y2, look_back,mode)\n",
    "train_speed_x = np.concatenate((train_speed_x,train_speed_x10),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_y0 = create_dataset(train_speed3,train_speed_y3, look_back,mode)\n",
    "train_speed_x = np.concatenate((train_speed_x,train_speed_x10),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_y0 = create_dataset(train_speed4,train_speed_y4, look_back,mode)\n",
    "train_speed_x = np.concatenate((train_speed_x,train_speed_x10),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_y0 = create_dataset(train_speed5,train_speed_y5, look_back,mode)\n",
    "train_speed_x = np.concatenate((train_speed_x,train_speed_x10),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_y0 = create_dataset(train_speed6,train_speed_y6, look_back,mode)\n",
    "train_speed_x = np.concatenate((train_speed_x,train_speed_x10),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "\n",
    "print('look_back = ',look_back)\n",
    "print('look_back_days = ',look_back_days)\n",
    "print('mode = ',mode)\n",
    "print('train_speed_x.shape = ',train_speed_x.shape)\n",
    "print('train_speed_y.shape = ',train_speed_y.shape)\n",
    "print('test_speed_x.shape = ',test_speed_x.shape)\n",
    "print('test_speed_y.shape = ',test_speed_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(test_speed_y[0,390:510,:]+mean0[390:510,0:1])  #12-19-2016 Monday 6:30AM - 8:30AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = train_speed_x.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(look_back, train_speed_x.shape[3]), stateful=False, return_sequences=True))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(LSTM(32, input_shape=(look_back, train_speed_x.shape[3]), stateful=False))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "train_x = np.reshape(train_speed_x,(train_speed_x.shape[0]*train_speed_x.shape[1],train_speed_x.shape[2],train_speed_x.shape[3]))\n",
    "train_y = np.reshape(train_speed_y,(train_speed_y.shape[0]*train_speed_y.shape[1],train_speed_y.shape[2]))\n",
    "history = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "# history_plot(history,mean0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plot(history,'images/history_exp4.png','images/test_exp4.png',a=mean0,b=mean0)\n",
    "history_plot(history,'images/history_exp4_delta.png','images/test_exp4_delta.png',b=mean0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment5: input: univariate speed; output: univariate delta speed; lookback = 15; lookback weeks = 15 (as feature);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment6: input: univariate speed; output: univariate delta speed; lookback = 15; lookback weeks = 6 (parallel structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_speed = Speed[333:334,:,:]\n",
    "# train_speed = Speed[:334,:,:]\n",
    "# dayofweek = data['dayofweek'][333]\n",
    "train_speed0,train_speed_y0,_,mean0,_ = get_certain_dayofweek(Speed[:334],dayofweek = 0)\n",
    "train_speed1,train_speed_y1,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 1)\n",
    "train_speed2,train_speed_y2,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 2)\n",
    "train_speed3,train_speed_y3,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 3)\n",
    "train_speed4,train_speed_y4,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 4)\n",
    "train_speed5,train_speed_y5,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 5)\n",
    "train_speed6,train_speed_y6,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 6)\n",
    "# train_speed0 = train_speed0[0:48,:,:]\n",
    "print('train_speed0.shape = ',train_speed.shape)\n",
    "# print('test_speed.shape = ',test_speed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 15\n",
    "look_back_days = 6\n",
    "mode = 'uni'\n",
    "train_speed_x1,train_speed_x2,train_speed_y = create_dataset_historyAsSecondInput(train_speed0,train_speed_y0, look_back, look_back_days, mode)\n",
    "\n",
    "test_speed_x1 = train_speed_x1[-1:,:,:,:]\n",
    "test_speed_x2 = train_speed_x2[-1:,:,:,:]\n",
    "test_speed_y = train_speed_y[-1:,:,:]\n",
    "train_speed_x1 = train_speed_x1[:-1,:,:,:]\n",
    "train_speed_x2 = train_speed_x2[:-1,:,:,:]\n",
    "train_speed_y = train_speed_y[:-1,:,:]\n",
    "\n",
    "\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed1,train_speed_y1, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed2,train_speed_y2, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed3,train_speed_y3, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed4,train_speed_y4, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed5,train_speed_y5, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed6,train_speed_y6, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "\n",
    "print('look_back = ',look_back)\n",
    "print('look_back_days = ',look_back_days)\n",
    "print('mode = ',mode)\n",
    "print('train_speed_x1.shape = ',train_speed_x1.shape)\n",
    "print('train_speed_x2.shape = ',train_speed_x2.shape)\n",
    "print('train_speed_y.shape = ',train_speed_y.shape)\n",
    "print('test_speed_x1.shape = ',test_speed_x1.shape)\n",
    "print('test_speed_x2.shape = ',test_speed_x2.shape)\n",
    "print('test_speed_y.shape = ',test_speed_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(test_speed_y[0,390:510,:]+mean0[390:510,0:1])  #12-19-2016 Monday 6:30AM - 8:30AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = train_speed_x.shape[1]\n",
    "\n",
    "todaySequence = Input(shape=(look_back, train_speed_x1.shape[3]),name='todaySequence')\n",
    "h1=LSTM(32, input_shape=(look_back, train_speed_x1.shape[3]), stateful=False, return_sequences=True)(todaySequence)\n",
    "\n",
    "h1=LSTM(32, input_shape=(look_back, train_speed_x1.shape[3]), stateful=False,name='h1')(todaySequence)\n",
    "h1= BatchNormalization()(h1)\n",
    "\n",
    "historySequence = Input(shape=(look_back_days, train_speed_x2.shape[3]),name='historySequence')\n",
    "h2=LSTM(32, input_shape=(look_back, train_speed_x2.shape[3]), stateful=False, return_sequences=True)(historySequence)\n",
    "h2=LSTM(32, input_shape=(look_back, train_speed_x2.shape[3]), stateful=False,name='h2')(h2)\n",
    "\n",
    "h3 = keras.layers.concatenate([h1, h2],name='h3')\n",
    "# h3 = keras.layers.concatenate([h1, h2],name='h3')\n",
    "\n",
    "predictedSpeed = Dense(1,name='predictedSpeed')(h3)\n",
    "\n",
    "model = Model(inputs=[todaySequence, historySequence], outputs=[predictedSpeed])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# model.compile(optimizer='rmsprop',\n",
    "#               loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'},\n",
    "#               loss_weights={'main_output': 1., 'aux_output': 0.2})\n",
    "\n",
    "train_x1 = np.reshape(train_speed_x1,(train_speed_x1.shape[0]*train_speed_x1.shape[1],train_speed_x1.shape[2],train_speed_x1.shape[3]))\n",
    "train_x2 = np.reshape(train_speed_x2,(train_speed_x2.shape[0]*train_speed_x2.shape[1],train_speed_x2.shape[2],train_speed_x2.shape[3]))\n",
    "train_y = np.reshape(train_speed_y,(train_speed_y.shape[0]*train_speed_y.shape[1],train_speed_y.shape[2]))\n",
    "\n",
    "history = model.fit({'todaySequence': train_x1, 'historySequence': train_x2},\n",
    "          {'predictedSpeed': train_y},\n",
    "          epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "\n",
    "# history_plot_historyAsSecondInput(history,mean0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intermediate_layer_model_h1 = Model(inputs=model.input,\n",
    "#                                  outputs=model.get_layer('h1').output)\n",
    "# intermediate_output_h1 = intermediate_layer_model_h1.predict([train_x1[:1],train_x2[:1]])\n",
    "# intermediate_layer_model_h2 = Model(inputs=model.input,\n",
    "#                                  outputs=model.get_layer('h2').output)\n",
    "# intermediate_output_h2 = intermediate_layer_model_h2.predict([train_x1[:1],train_x2[:1]])\n",
    "# intermediate_layer_model_h3 = Model(inputs=model.input,\n",
    "#                                  outputs=model.get_layer('h3').output)\n",
    "# intermediate_output_h3 = intermediate_layer_model_h3.predict([train_x1[:1],train_x2[:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plot_historyAsSecondInput(history,'images/history_exp6.png','images/test_exp6.png',a=mean0,b=mean0)\n",
    "history_plot_historyAsSecondInput(history,'images/history_exp6_delta.png','images/test_exp6_delta.png',b=mean0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def history_plot_multi(history_object,image1='image1',image2='image2',image3='image3',a=np.zeros((test_speed_y.shape[1],1)),b=np.zeros((test_speed_y.shape[1],1))):\n",
    "    \n",
    "    trainScore = [];\n",
    "    for i in range(len(train_speed_x)):\n",
    "        trainScore.append(model.evaluate(train_speed_x[i,:,:,:], train_speed_y[i,:,:], batch_size=batch_size, verbose=0))\n",
    "    trainScore = np.mean(trainScore)\n",
    "    print('Train Score: ', trainScore)\n",
    "    testScore = [];\n",
    "    for i in range(len(test_speed_x)):\n",
    "        testScore.append(model.evaluate(test_speed_x[i,:,:,:], test_speed_y[i,:,:], batch_size=batch_size, verbose=0))\n",
    "    testScore = np.mean(testScore)\n",
    "    print('Test Score: ', testScore)\n",
    "\n",
    "    fig2 = plt.figure(figsize=(15,5))\n",
    "    plt.plot(history_object.history['loss'])\n",
    "    plt.title('model mean squared error loss (Train Score:' + str(trainScore) + ' Test Score:' + str(testScore))\n",
    "    plt.ylabel('mean squared error loss')\n",
    "    plt.xlabel('epoch')\n",
    "    fig2.savefig(image1, bbox_inches='tight')\n",
    "    \n",
    "    look_ahead = 120\n",
    "    start = 390\n",
    "    trainPredict = test_speed_x[0,start,:,:]\n",
    "    predictions = np.zeros((look_ahead,15))\n",
    "\n",
    "    for i in range(look_ahead):\n",
    "        prediction = model.predict(np.array([trainPredict]), batch_size=batch_size)\n",
    "        predictions[i] = prediction\n",
    "        trainPredict = np.vstack([trainPredict[1:],prediction+b[(start+i):(start+i+1),:1]])\n",
    "\n",
    "    fig1 = plt.figure(figsize=(12,10))\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    ax1.set_title('prediction at the start of day', fontsize=20)\n",
    "    \n",
    "    plt.plot(np.arange(look_ahead),predictions[:,:1]+a[start:(start+look_ahead),:1],'r',label=\"prediction\")\n",
    "    plt.plot(np.arange(look_ahead),test_speed_y[0,start:(start+look_ahead),:1]+a[start:(start+look_ahead),:1],label=\"test function\")\n",
    "    plt.legend()\n",
    "\n",
    "    predictions_1 = np.zeros((look_ahead,15))\n",
    "\n",
    "    for i in range(look_ahead):\n",
    "        trainPredict = test_speed_x[0,start+i,:,:]\n",
    "        prediction = model.predict(np.array([trainPredict]), batch_size=batch_size)\n",
    "        predictions_1[i] = prediction\n",
    "\n",
    "\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "    ax2.set_title('prediction using real-time data', fontsize=20)\n",
    "    plt.plot(np.arange(look_ahead),predictions_1[:,:1]+a[start:(start+look_ahead),:1],'r',label=\"prediction\")\n",
    "    plt.plot(np.arange(look_ahead),test_speed_y[0,start:(start+look_ahead),:1]+a[start:(start+look_ahead),:1],label=\"test function\")\n",
    "    plt.legend()\n",
    "\n",
    "    fig1.savefig(image2, bbox_inches='tight')\n",
    "\n",
    "    fig3 = plt.figure(figsize=(12,10))\n",
    "    ax1 = plt.subplot(3,1,1)\n",
    "    ax1.set_title('test data', fontsize=20)\n",
    "    plt.pcolor(test_speed_y[0,start:(start+look_ahead),:].transpose()+a[start:(start+look_ahead),:].transpose(),cmap=my_cmap, vmin=20, vmax=70)\n",
    "    \n",
    "    ax2 = plt.subplot(3,1,2)\n",
    "    ax2.set_title('prediction at the start', fontsize=20)\n",
    "    plt.pcolor(predictions.transpose()+a[start:(start+look_ahead),:].transpose(),cmap=my_cmap, vmin=20, vmax=70)\n",
    "    \n",
    "    ax3 = plt.subplot(3,1,3)\n",
    "    ax3.set_title('prediction using real-time data', fontsize=20)\n",
    "    plt.pcolor(predictions_1.transpose()+a[start:(start+look_ahead),:].transpose(),cmap=my_cmap, vmin=20, vmax=70)\n",
    "    \n",
    "    fig3.savefig(image3, bbox_inches='tight')\n",
    "\n",
    "def history_plot_multi_historyAsSecondInput(history_object,image1='image1',image2='image2',image3='image3',a=np.zeros((test_speed_y.shape[1],1)),b=np.zeros((test_speed_y.shape[1],1))):\n",
    "  \n",
    "    trainScore = [];\n",
    "    for i in range(len(train_speed_x1)):\n",
    "        trainScore.append(model.evaluate([train_speed_x1[i,:,:,:],train_speed_x2[i,:,:,:]], train_speed_y[i,:,:], batch_size=batch_size, verbose=0))\n",
    "    trainScore = np.mean(trainScore)\n",
    "    print('Train Score: ', trainScore)\n",
    "    testScore = [];\n",
    "    for i in range(len(test_speed_x1)):\n",
    "        testScore.append(model.evaluate([test_speed_x1[i,:,:,:],test_speed_x2[i,:,:,:]], test_speed_y[i,:,:], batch_size=batch_size, verbose=0))\n",
    "    testScore = np.mean(testScore)\n",
    "    print('Test Score: ', testScore)\n",
    "\n",
    "    fig2 = plt.figure(figsize=(15,5))\n",
    "    plt.plot(history_object.history['loss'])\n",
    "    plt.title('model mean squared error loss (Train Score:' + str(trainScore) + ' Test Score:' + str(testScore))\n",
    "    plt.ylabel('mean squared error loss')\n",
    "    plt.xlabel('epoch')\n",
    "    fig2.savefig(image1, bbox_inches='tight')\n",
    "    \n",
    "    look_ahead = 120\n",
    "    start = 390\n",
    "    trainPredict = test_speed_x1[0,start,:,:]  \n",
    "    predictions = np.zeros((look_ahead,15))\n",
    "\n",
    "    for i in range(look_ahead):\n",
    "        input2 = test_speed_x2[0,start+i,:,:]\n",
    "        prediction = model.predict([np.array([trainPredict]),np.array([input2])], batch_size=batch_size)\n",
    "        predictions[i] = prediction\n",
    "        trainPredict = np.vstack([trainPredict[1:],prediction+b[(start+i):(start+i+1),:1]])\n",
    "\n",
    "    fig1 = plt.figure(figsize=(12,10))\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    ax1.set_title('prediction at the start of day', fontsize=20)\n",
    "    plt.plot(np.arange(look_ahead),predictions[:,:1]+a[start:(start+look_ahead),:1],'r',label=\"prediction\")\n",
    "    plt.plot(np.arange(look_ahead),test_speed_y[0,start:(start+look_ahead),:1]+a[start:(start+look_ahead),:1],label=\"test function\")\n",
    "    plt.legend()\n",
    "\n",
    "    predictions_1 = np.zeros((look_ahead,15))\n",
    "\n",
    "    for i in range(look_ahead):\n",
    "        trainPredict = test_speed_x1[0,start+i,:,:]\n",
    "        input2 = test_speed_x2[0,start+i,:,:]\n",
    "        prediction = model.predict([np.array([trainPredict]),np.array([input2])], batch_size=batch_size)\n",
    "        predictions_1[i] = prediction\n",
    "\n",
    "\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "    ax2.set_title('prediction using real-time data', fontsize=20)\n",
    "    plt.plot(np.arange(look_ahead),predictions_1[:,:1]+a[start:(start+look_ahead),:1],'r',label=\"prediction\")\n",
    "    plt.plot(np.arange(look_ahead),test_speed_y[0,start:(start+look_ahead),:1]+a[start:(start+look_ahead),:1],label=\"test function\")\n",
    "    plt.legend()\n",
    "\n",
    "    fig1.savefig(image2, bbox_inches='tight')\n",
    "\n",
    "    fig3 = plt.figure(figsize=(12,10))\n",
    "    ax1 = plt.subplot(3,1,1)\n",
    "    ax1.set_title('test data', fontsize=20)\n",
    "    plt.pcolor(test_speed_y[0,start:(start+look_ahead),:].transpose()+a[start:(start+look_ahead),:].transpose(),cmap=my_cmap, vmin=20, vmax=70)\n",
    "    \n",
    "    ax2 = plt.subplot(3,1,2)\n",
    "    ax2.set_title('prediction at the start', fontsize=20)\n",
    "    plt.pcolor(predictions.transpose()+a[start:(start+look_ahead),:].transpose(),cmap=my_cmap, vmin=20, vmax=70)\n",
    "    \n",
    "    ax3 = plt.subplot(3,1,3)\n",
    "    ax3.set_title('prediction using real-time data', fontsize=20)\n",
    "    plt.pcolor(predictions_1.transpose()+a[start:(start+look_ahead),:].transpose(),cmap=my_cmap, vmin=20, vmax=70)\n",
    "    \n",
    "    fig3.savefig(image3, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment7: input: multivariate speed; output: multivariate speed; lookback = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_speed = Speed[333:334,:,:]\n",
    "train_speed = Speed[:333,:,:]\n",
    "print('train_speed.shape = ',train_speed.shape)\n",
    "print('test_speed.shape = ',test_speed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 15\n",
    "mode = 'multi'\n",
    "train_speed_x,train_speed_y = create_dataset(train_speed,train_speed, look_back, mode)\n",
    "test_speed_x,test_speed_y = create_dataset(test_speed,test_speed, look_back, mode)\n",
    "print('look_back = ',look_back)\n",
    "print('mode = ',mode)\n",
    "print('train_speed_x.shape = ',train_speed_x.shape)\n",
    "print('train_speed_y.shape = ',train_speed_y.shape)\n",
    "print('test_speed_x.shape = ',test_speed_x.shape)\n",
    "print('test_speed_y.shape = ',test_speed_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plt.plot(test_speed_y[0,390:510,:1])  #12-19-2016 Monday 6:30AM - 8:30AM\n",
    "# plt.pcolor(test_speed_y[0,390:510,:].transpose(),cmap=my_cmap, vmin=20, vmax=70)  #12-19-2016 Monday 6:30AM - 8:30AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = train_speed_x.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(look_back, train_speed_x.shape[3]), stateful=False, return_sequences=True))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(LSTM(32, input_shape=(look_back, train_speed_x.shape[3]), stateful=False))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(train_speed_y.shape[2]))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "train_x = np.reshape(train_speed_x,(train_speed_x.shape[0]*train_speed_x.shape[1],train_speed_x.shape[2],train_speed_x.shape[3]))\n",
    "train_y = np.reshape(train_speed_y,(train_speed_y.shape[0]*train_speed_y.shape[1],train_speed_y.shape[2]))\n",
    "history = model.fit(train_x, train_y,epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "# history_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plot_multi(history,'images/history_exp7.png','images/test_exp7.png','images/heatmap_exp7.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment8: input: multivariate speed; output: multivariate speed; lookback = 15; lookback weeks = 15 (as feature);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment9: input: multivariate speed; output: multivariate speed; lookback = 15; lookback weeks = 6 (parallel structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_speed = Speed[333:334,:,:]\n",
    "# train_speed = Speed[:334,:,:]\n",
    "# dayofweek = data['dayofweek'][333]\n",
    "train_speed0,_,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 0)\n",
    "train_speed1,_,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 1)\n",
    "train_speed2,_,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 2)\n",
    "train_speed3,_,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 3)\n",
    "train_speed4,_,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 4)\n",
    "train_speed5,_,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 5)\n",
    "train_speed6,_,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 6)\n",
    "# train_speed0 = train_speed0[0:48,:,:]\n",
    "print('train_speed0.shape = ',train_speed.shape)\n",
    "# print('test_speed.shape = ',test_speed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 15\n",
    "look_back_days = 6\n",
    "mode = 'multi'\n",
    "train_speed_x1,train_speed_x2,train_speed_y = create_dataset_historyAsSecondInput(train_speed0,train_speed0, look_back, look_back_days, mode)\n",
    "\n",
    "test_speed_x1 = train_speed_x1[-1:,:,:,:]\n",
    "test_speed_x2 = train_speed_x2[-1:,:,:,:]\n",
    "test_speed_y = train_speed_y[-1:,:,:]\n",
    "train_speed_x1 = train_speed_x1[:-1,:,:,:]\n",
    "train_speed_x2 = train_speed_x2[:-1,:,:,:]\n",
    "train_speed_y = train_speed_y[:-1,:,:]\n",
    "\n",
    "\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed1,train_speed1, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed2,train_speed2, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed3,train_speed3, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed4,train_speed4, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed5,train_speed5, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed6,train_speed6, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "\n",
    "print('look_back = ',look_back)\n",
    "print('look_back_days = ',look_back_days)\n",
    "print('mode = ',mode)\n",
    "print('train_speed_x1.shape = ',train_speed_x1.shape)\n",
    "print('train_speed_x2.shape = ',train_speed_x2.shape)\n",
    "print('train_speed_y.shape = ',train_speed_y.shape)\n",
    "print('test_speed_x1.shape = ',test_speed_x1.shape)\n",
    "print('test_speed_x2.shape = ',test_speed_x2.shape)\n",
    "print('test_speed_y.shape = ',test_speed_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(test_speed_y[0,390:510,:1])  #12-19-2016 Monday 6:30AM - 8:30AM\n",
    "# plt.pcolor(test_speed_y[0,390:510,:].transpose(),cmap=my_cmap, vmin=20, vmax=70)  #12-19-2016 Monday 6:30AM - 8:30AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = train_speed_x.shape[1]\n",
    "\n",
    "todaySequence = Input(shape=(look_back, train_speed_x1.shape[3]),name='todaySequence')\n",
    "h1=LSTM(32, input_shape=(look_back, train_speed_x1.shape[3]), stateful=False, return_sequences=True)(todaySequence)\n",
    "h1=LSTM(32, input_shape=(look_back, train_speed_x1.shape[3]), stateful=False)(h1)\n",
    "\n",
    "historySequence = Input(shape=(look_back_days, train_speed_x2.shape[3]),name='historySequence')\n",
    "h2=LSTM(32, input_shape=(look_back, train_speed_x2.shape[3]), stateful=False, return_sequences=True)(historySequence)\n",
    "h2=LSTM(32, input_shape=(look_back, train_speed_x2.shape[3]), stateful=False)(h2)\n",
    "\n",
    "h3 = keras.layers.concatenate([h1, h2])\n",
    "predictedSpeed = Dense(train_speed_y.shape[2],name='predictedSpeed')(h3)\n",
    "\n",
    "model = Model(inputs=[todaySequence, historySequence], outputs=[predictedSpeed])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# model.compile(optimizer='rmsprop',\n",
    "#               loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'},\n",
    "#               loss_weights={'main_output': 1., 'aux_output': 0.2})\n",
    "\n",
    "train_x1 = np.reshape(train_speed_x1,(train_speed_x1.shape[0]*train_speed_x1.shape[1],train_speed_x1.shape[2],train_speed_x1.shape[3]))\n",
    "train_x2 = np.reshape(train_speed_x2,(train_speed_x2.shape[0]*train_speed_x2.shape[1],train_speed_x2.shape[2],train_speed_x2.shape[3]))\n",
    "train_y = np.reshape(train_speed_y,(train_speed_y.shape[0]*train_speed_y.shape[1],train_speed_y.shape[2]))\n",
    "\n",
    "history = model.fit({'todaySequence': train_x1, 'historySequence': train_x2},\n",
    "          {'predictedSpeed': train_y},\n",
    "          epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "\n",
    "# history_plot_historyAsSecondInput(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plot_multi_historyAsSecondInput(history,'images/history_exp9.png','images/test_exp9.png','images/heatmap_exp9.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment10: input: multivariate speed; output: multivariate delta speed; lookback = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mon, Mon_delta, Mon_Z, mon_mean, mon_std = get_certain_dayofweek(Speed,dayofweek = 0)\n",
    "# train_speed, train_speed_y, _, mean0, _ = get_certain_dayofweek(Speed[:334],dayofweek = 0)\n",
    "# test_speed = train_speed[-1:]\n",
    "# train_speed = train_speed[:-1]\n",
    "# test_speed_y = train_speed_y[-1:]\n",
    "# train_speed_y = train_speed_y[:-1]\n",
    "\n",
    "\n",
    "# print('train_speed.shape = ',train_speed.shape)\n",
    "# print('test_speed.shape = ',test_speed.shape)\n",
    "\n",
    "# test_speed = Speed[333:334,:,:]\n",
    "# train_speed = Speed[:334,:,:]\n",
    "train_speed0,train_speed_y0,_,mean0,_ = get_certain_dayofweek(Speed[:334],dayofweek = 0)\n",
    "train_speed1,train_speed_y1,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 1)\n",
    "train_speed2,train_speed_y2,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 2)\n",
    "train_speed3,train_speed_y3,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 3)\n",
    "train_speed4,train_speed_y4,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 4)\n",
    "train_speed5,train_speed_y5,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 5)\n",
    "train_speed6,train_speed_y6,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 6)\n",
    "# train_speed0 = train_speed0[0:48,:,:]\n",
    "print('train_speed0.shape = ',train_speed.shape)\n",
    "# print('test_speed.shape = ',test_speed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look_back = 15\n",
    "# mode = 'uni'\n",
    "# train_speed_x,train_speed_y = create_dataset(train_speed,train_speed_y, look_back, mode)\n",
    "# test_speed_x,test_speed_y = create_dataset(test_speed,test_speed_y, look_back, mode)\n",
    "# print('look_back = ',look_back)\n",
    "# print('mode = ',mode)\n",
    "# print('train_speed_x.shape = ',train_speed_x.shape)\n",
    "# print('train_speed_y.shape = ',train_speed_y.shape)\n",
    "# print('test_speed_x.shape = ',test_speed_x.shape)\n",
    "# print('test_speed_y.shape = ',test_speed_y.shape)\n",
    "\n",
    "look_back = 15\n",
    "mode = 'multi'\n",
    "train_speed_x,train_speed_y = create_dataset(train_speed0,train_speed_y0, look_back, mode)\n",
    "\n",
    "test_speed_x = train_speed_x[-1:,:,:,:]\n",
    "test_speed_y = train_speed_y[-1:,:,:]\n",
    "train_speed_x = train_speed_x[:-1,:,:,:]\n",
    "train_speed_y = train_speed_y[:-1,:,:]\n",
    "\n",
    "train_speed_x10,train_speed_y0 = create_dataset(train_speed1,train_speed_y1, look_back,mode)\n",
    "train_speed_x = np.concatenate((train_speed_x,train_speed_x10),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_y0 = create_dataset(train_speed2,train_speed_y2, look_back,mode)\n",
    "train_speed_x = np.concatenate((train_speed_x,train_speed_x10),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_y0 = create_dataset(train_speed3,train_speed_y3, look_back,mode)\n",
    "train_speed_x = np.concatenate((train_speed_x,train_speed_x10),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_y0 = create_dataset(train_speed4,train_speed_y4, look_back,mode)\n",
    "train_speed_x = np.concatenate((train_speed_x,train_speed_x10),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_y0 = create_dataset(train_speed5,train_speed_y5, look_back,mode)\n",
    "train_speed_x = np.concatenate((train_speed_x,train_speed_x10),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_y0 = create_dataset(train_speed6,train_speed_y6, look_back,mode)\n",
    "train_speed_x = np.concatenate((train_speed_x,train_speed_x10),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "\n",
    "print('look_back = ',look_back)\n",
    "print('look_back_days = ',look_back_days)\n",
    "print('mode = ',mode)\n",
    "print('train_speed_x.shape = ',train_speed_x.shape)\n",
    "print('train_speed_y.shape = ',train_speed_y.shape)\n",
    "print('test_speed_x.shape = ',test_speed_x.shape)\n",
    "print('test_speed_y.shape = ',test_speed_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(test_speed_y[0,390:510,:1]+mean0[390:510,:1])  #12-19-2016 Monday 6:30AM - 8:30AM\n",
    "# plt.pcolor(mean0[390:510,:].transpose(),cmap=my_cmap, vmin=20, vmax=70)  #12-19-2016 Monday 6:30AM - 8:30AM\n",
    "# plt.pcolor(test_speed_y[0,390:510,:].transpose()+mean0[390:510,:].transpose(),cmap=my_cmap, vmin=20, vmax=70)  #12-19-2016 Monday 6:30AM - 8:30AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = train_speed_x.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(look_back, train_speed_x.shape[3]), stateful=False, return_sequences=True))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(LSTM(32, input_shape=(look_back, train_speed_x.shape[3]), stateful=False))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(train_speed_y.shape[2]))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "train_x = np.reshape(train_speed_x,(train_speed_x.shape[0]*train_speed_x.shape[1],train_speed_x.shape[2],train_speed_x.shape[3]))\n",
    "train_y = np.reshape(train_speed_y,(train_speed_y.shape[0]*train_speed_y.shape[1],train_speed_y.shape[2]))\n",
    "history = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "# history_plot(history,mean0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plot_multi(history,'images/history_exp10.png','images/test_exp10.png','images/heatmap_exp10.png',a=mean0,b=mean0)\n",
    "history_plot_multi(history,'images/history_exp10_delta.png','images/test_exp10_delta.png','images/heatmap_exp10_delta.png',b=mean0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment11: input: multivariate speed; output: multivariate delta speed; lookback = 15; lookback weeks = 15 (as feature);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment12: input: multivariate speed; output: multivariate delta speed; lookback = 15; lookback weeks = 6 (parallel structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_speed = Speed[333:334,:,:]\n",
    "# train_speed = Speed[:334,:,:]\n",
    "# dayofweek = data['dayofweek'][333]\n",
    "train_speed0,train_speed_y0,_,mean0,_ = get_certain_dayofweek(Speed[:334],dayofweek = 0)\n",
    "train_speed1,train_speed_y1,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 1)\n",
    "train_speed2,train_speed_y2,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 2)\n",
    "train_speed3,train_speed_y3,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 3)\n",
    "train_speed4,train_speed_y4,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 4)\n",
    "train_speed5,train_speed_y5,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 5)\n",
    "train_speed6,train_speed_y6,_,_,_ = get_certain_dayofweek(Speed[:334],dayofweek = 6)\n",
    "# train_speed0 = train_speed0[0:48,:,:]\n",
    "print('train_speed0.shape = ',train_speed.shape)\n",
    "# print('test_speed.shape = ',test_speed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 15\n",
    "look_back_days = 6\n",
    "mode = 'multi'\n",
    "train_speed_x1,train_speed_x2,train_speed_y = create_dataset_historyAsSecondInput(train_speed0,train_speed_y0, look_back, look_back_days, mode)\n",
    "\n",
    "test_speed_x1 = train_speed_x1[-1:,:,:,:]\n",
    "test_speed_x2 = train_speed_x2[-1:,:,:,:]\n",
    "test_speed_y = train_speed_y[-1:,:,:]\n",
    "train_speed_x1 = train_speed_x1[:-1,:,:,:]\n",
    "train_speed_x2 = train_speed_x2[:-1,:,:,:]\n",
    "train_speed_y = train_speed_y[:-1,:,:]\n",
    "\n",
    "\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed1,train_speed_y1, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed2,train_speed_y2, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed3,train_speed_y3, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed4,train_speed_y4, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed5,train_speed_y5, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "train_speed_x10,train_speed_x20,train_speed_y0 = create_dataset_historyAsSecondInput(train_speed6,train_speed_y6, look_back, look_back_days, mode)\n",
    "train_speed_x1 = np.concatenate((train_speed_x1,train_speed_x10),axis=0)\n",
    "train_speed_x2 = np.concatenate((train_speed_x2,train_speed_x20),axis=0)\n",
    "train_speed_y = np.concatenate((train_speed_y,train_speed_y0),axis=0)\n",
    "\n",
    "print('look_back = ',look_back)\n",
    "print('look_back_days = ',look_back_days)\n",
    "print('mode = ',mode)\n",
    "print('train_speed_x1.shape = ',train_speed_x1.shape)\n",
    "print('train_speed_x2.shape = ',train_speed_x2.shape)\n",
    "print('train_speed_y.shape = ',train_speed_y.shape)\n",
    "print('test_speed_x1.shape = ',test_speed_x1.shape)\n",
    "print('test_speed_x2.shape = ',test_speed_x2.shape)\n",
    "print('test_speed_y.shape = ',test_speed_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(test_speed_y[0,390:510,:1]+mean0[390:510,:1])  #12-19-2016 Monday 6:30AM - 8:30AM\n",
    "# plt.pcolor(mean0[390:510,:].transpose(),cmap=my_cmap, vmin=20, vmax=70)  #12-19-2016 Monday 6:30AM - 8:30AM\n",
    "# plt.pcolor(test_speed_y[0,390:510,:].transpose()+mean0[390:510,:].transpose(),cmap=my_cmap, vmin=20, vmax=70)  #12-19-2016 Monday 6:30AM - 8:30AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = train_speed_x.shape[1]\n",
    "\n",
    "todaySequence = Input(shape=(look_back, train_speed_x1.shape[3]),name='todaySequence')\n",
    "h1=LSTM(32, input_shape=(look_back, train_speed_x1.shape[3]), stateful=False, return_sequences=True)(todaySequence)\n",
    "\n",
    "h1=LSTM(32, input_shape=(look_back, train_speed_x1.shape[3]), stateful=False,name='h1')(todaySequence)\n",
    "\n",
    "historySequence = Input(shape=(look_back_days, train_speed_x2.shape[3]),name='historySequence')\n",
    "h2=LSTM(32, input_shape=(look_back, train_speed_x2.shape[3]), stateful=False, return_sequences=True)(historySequence)\n",
    "h2=LSTM(32, input_shape=(look_back, train_speed_x2.shape[3]), stateful=False,name='h2')(h2)\n",
    "\n",
    "h3 = keras.layers.concatenate([h1, h2],name='h3')\n",
    "# h3 = keras.layers.concatenate([h1, h2],name='h3')\n",
    "\n",
    "predictedSpeed = Dense(train_speed_y.shape[2],name='predictedSpeed')(h3)\n",
    "\n",
    "model = Model(inputs=[todaySequence, historySequence], outputs=[predictedSpeed])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# model.compile(optimizer='rmsprop',\n",
    "#               loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'},\n",
    "#               loss_weights={'main_output': 1., 'aux_output': 0.2})\n",
    "\n",
    "train_x1 = np.reshape(train_speed_x1,(train_speed_x1.shape[0]*train_speed_x1.shape[1],train_speed_x1.shape[2],train_speed_x1.shape[3]))\n",
    "train_x2 = np.reshape(train_speed_x2,(train_speed_x2.shape[0]*train_speed_x2.shape[1],train_speed_x2.shape[2],train_speed_x2.shape[3]))\n",
    "train_y = np.reshape(train_speed_y,(train_speed_y.shape[0]*train_speed_y.shape[1],train_speed_y.shape[2]))\n",
    "\n",
    "history = model.fit({'todaySequence': train_x1, 'historySequence': train_x2},\n",
    "          {'predictedSpeed': train_y},\n",
    "          epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "\n",
    "# history_plot_historyAsSecondInput(history,mean0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plot_multi_historyAsSecondInput(history,'images/history_exp12.png','images/test_exp12.png','images/heatmap_exp12.png',a=mean0,b=mean0)\n",
    "history_plot_multi_historyAsSecondInput(history,'images/history_exp12_delta.png','images/test_exp12_delta.png','images/heatmap_exp12_delta.png',b=mean0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def history_plot_multi_co(history_object,image1='image1',image2='image2',image3='image3',a=np.zeros((test_speed_y.shape[1],1)),b=np.zeros((test_speed_y.shape[1],1))):\n",
    "    \n",
    "    trainScore = [];\n",
    "    for i in range(len(train_speed_x)):\n",
    "        trainScore.append(model.evaluate(train_speed_x[i,:,:,:], train_speed_y[i,:,:], batch_size=batch_size, verbose=0))\n",
    "    trainScore = np.mean(trainScore)\n",
    "    print('Train Score: ', trainScore)\n",
    "    testScore = [];\n",
    "    for i in range(len(test_speed_x)):\n",
    "        testScore.append(model.evaluate(test_speed_x[i,:,:,:], test_speed_y[i,:,:], batch_size=batch_size, verbose=0))\n",
    "    testScore = np.mean(testScore)\n",
    "    print('Test Score: ', testScore)\n",
    "\n",
    "    fig2 = plt.figure(figsize=(15,5))\n",
    "    plt.plot(history_object.history['loss'])\n",
    "    plt.title('model mean squared error loss (Train Score:' + str(trainScore) + ' Test Score:' + str(testScore))\n",
    "    plt.ylabel('mean squared error loss')\n",
    "    plt.xlabel('epoch')\n",
    "#     fig2.savefig(image1, bbox_inches='tight')\n",
    "    \n",
    "    look_ahead = 120\n",
    "    start = 390\n",
    "    trainPredict = test_speed_x[0,start,:,:]\n",
    "    predictions = np.zeros((look_ahead,15))\n",
    "\n",
    "    for i in range(look_ahead):\n",
    "        prediction = model.predict(np.array([trainPredict]), batch_size=batch_size)\n",
    "        predictions[i] = prediction\n",
    "        trainPredict = np.vstack([trainPredict[1:],prediction+b[(start+i):(start+i+1),:1]])\n",
    "\n",
    "    fig1 = plt.figure(figsize=(12,10))\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    ax1.set_title('prediction at the start of day', fontsize=20)\n",
    "    \n",
    "    plt.plot(np.arange(look_ahead),predictions[:,:1]+a[start:(start+look_ahead),:1],'r',label=\"prediction\")\n",
    "    plt.plot(np.arange(look_ahead),test_speed_y[0,start:(start+look_ahead),:1]+a[start:(start+look_ahead),:1],label=\"test function\")\n",
    "    plt.legend()\n",
    "\n",
    "    predictions_1 = np.zeros((look_ahead,15))\n",
    "\n",
    "    for i in range(look_ahead):\n",
    "        trainPredict = test_speed_x[0,start+i,:,:]\n",
    "        prediction = model.predict(np.array([trainPredict]), batch_size=batch_size)\n",
    "        predictions_1[i] = prediction\n",
    "\n",
    "\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "    ax2.set_title('prediction using real-time data', fontsize=20)\n",
    "    plt.plot(np.arange(look_ahead),predictions_1[:,:1]+a[start:(start+look_ahead),:1],'r',label=\"prediction\")\n",
    "    plt.plot(np.arange(look_ahead),test_speed_y[0,start:(start+look_ahead),:1]+a[start:(start+look_ahead),:1],label=\"test function\")\n",
    "    plt.legend()\n",
    "\n",
    "#     fig1.savefig(image2, bbox_inches='tight')\n",
    "\n",
    "    fig3 = plt.figure(figsize=(12,10))\n",
    "    ax1 = plt.subplot(3,1,1)\n",
    "    ax1.set_title('test data', fontsize=20)\n",
    "    plt.pcolor(test_speed_y[0,start:(start+look_ahead),:].transpose()+a[start:(start+look_ahead),:].transpose(),cmap=my_cmap, vmin=20, vmax=70)\n",
    "    \n",
    "    ax2 = plt.subplot(3,1,2)\n",
    "    ax2.set_title('prediction at the start', fontsize=20)\n",
    "    plt.pcolor(predictions.transpose()+a[start:(start+look_ahead),:].transpose(),cmap=my_cmap, vmin=20, vmax=70)\n",
    "    \n",
    "    ax3 = plt.subplot(3,1,3)\n",
    "    ax3.set_title('prediction using real-time data', fontsize=20)\n",
    "    plt.pcolor(predictions_1.transpose()+a[start:(start+look_ahead),:].transpose(),cmap=my_cmap, vmin=20, vmax=70)\n",
    "    \n",
    "#     fig3.savefig(image3, bbox_inches='tight')\n",
    "\n",
    "def history_plot_multi_co_historyAsSecondInput(history_object,image1='image1',image2='image2',image3='image3',a=np.zeros((test_speed_y.shape[1],1)),b=np.zeros((test_speed_y.shape[1],1))):\n",
    "  \n",
    "    trainScore = [];\n",
    "    for i in range(len(train_speed_x1)):\n",
    "        trainScore.append(model.evaluate([train_speed_x1[i,:,:,:],train_speed_x2[i,:,:,:]], train_speed_y[i,:,:], batch_size=batch_size, verbose=0))\n",
    "    trainScore = np.mean(trainScore)\n",
    "    print('Train Score: ', trainScore)\n",
    "    testScore = [];\n",
    "    for i in range(len(test_speed_x1)):\n",
    "        testScore.append(model.evaluate([test_speed_x1[i,:,:,:],test_speed_x2[i,:,:,:]], test_speed_y[i,:,:], batch_size=batch_size, verbose=0))\n",
    "    testScore = np.mean(testScore)\n",
    "    print('Test Score: ', testScore)\n",
    "\n",
    "    fig2 = plt.figure(figsize=(15,5))\n",
    "    plt.plot(history_object.history['loss'])\n",
    "    plt.title('model mean squared error loss (Train Score:' + str(trainScore) + ' Test Score:' + str(testScore))\n",
    "    plt.ylabel('mean squared error loss')\n",
    "    plt.xlabel('epoch')\n",
    "#     fig2.savefig(image1, bbox_inches='tight')\n",
    "    \n",
    "    look_ahead = 120\n",
    "    start = 390\n",
    "    trainPredict = test_speed_x1[0,start,:,:]  \n",
    "    predictions = np.zeros((look_ahead,15))\n",
    "\n",
    "    for i in range(look_ahead):\n",
    "        input2 = test_speed_x2[0,start+i,:,:]\n",
    "        prediction = model.predict([np.array([trainPredict]),np.array([input2])], batch_size=batch_size)\n",
    "        predictions[i] = prediction\n",
    "        trainPredict = np.vstack([trainPredict[1:],prediction+b[(start+i):(start+i+1),:1]])\n",
    "\n",
    "    fig1 = plt.figure(figsize=(12,10))\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    ax1.set_title('prediction at the start of day', fontsize=20)\n",
    "    plt.plot(np.arange(look_ahead),predictions[:,:1]+a[start:(start+look_ahead),:1],'r',label=\"prediction\")\n",
    "    plt.plot(np.arange(look_ahead),test_speed_y[0,start:(start+look_ahead),:1]+a[start:(start+look_ahead),:1],label=\"test function\")\n",
    "    plt.legend()\n",
    "\n",
    "    predictions_1 = np.zeros((look_ahead,15))\n",
    "\n",
    "    for i in range(look_ahead):\n",
    "        trainPredict = test_speed_x1[0,start+i,:,:]\n",
    "        input2 = test_speed_x2[0,start+i,:,:]\n",
    "        prediction = model.predict([np.array([trainPredict]),np.array([input2])], batch_size=batch_size)\n",
    "        predictions_1[i] = prediction\n",
    "\n",
    "\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "    ax2.set_title('prediction using real-time data', fontsize=20)\n",
    "    plt.plot(np.arange(look_ahead),predictions_1[:,:1]+a[start:(start+look_ahead),:1],'r',label=\"prediction\")\n",
    "    plt.plot(np.arange(look_ahead),test_speed_y[0,start:(start+look_ahead),:1]+a[start:(start+look_ahead),:1],label=\"test function\")\n",
    "    plt.legend()\n",
    "\n",
    "#     fig1.savefig(image2, bbox_inches='tight')\n",
    "\n",
    "    fig3 = plt.figure(figsize=(12,10))\n",
    "    ax1 = plt.subplot(3,1,1)\n",
    "    ax1.set_title('test data', fontsize=20)\n",
    "    plt.pcolor(test_speed_y[0,start:(start+look_ahead),:].transpose()+a[start:(start+look_ahead),:].transpose(),cmap=my_cmap, vmin=20, vmax=70)\n",
    "    \n",
    "    ax2 = plt.subplot(3,1,2)\n",
    "    ax2.set_title('prediction at the start', fontsize=20)\n",
    "    plt.pcolor(predictions.transpose()+a[start:(start+look_ahead),:].transpose(),cmap=my_cmap, vmin=20, vmax=70)\n",
    "    \n",
    "    ax3 = plt.subplot(3,1,3)\n",
    "    ax3.set_title('prediction using real-time data', fontsize=20)\n",
    "    plt.pcolor(predictions_1.transpose()+a[start:(start+look_ahead),:].transpose(),cmap=my_cmap, vmin=20, vmax=70)\n",
    "    \n",
    "#     fig3.savefig(image3, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment13: input: multivariate speed, count, occup; output: multivariate speed; lookback = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_speed,_ = MinMax_Normalization(Speed[333:334,:,:])\n",
    "test_speed_y = Speed[333:334,:,:]\n",
    "test_count,_ = MinMax_Normalization(Count[333:334,:,:])\n",
    "test_occup,_ = MinMax_Normalization(Occup[333:334,:,:])\n",
    "train_speed,scaler = MinMax_Normalization(Speed[:333,:,:])\n",
    "train_speed_y = Speed[:333,:,:]\n",
    "train_count,_ = MinMax_Normalization(Count[:333,:,:])\n",
    "train_occup,_ = MinMax_Normalization(Occup[:333,:,:])\n",
    "print('train_speed.shape = ',train_speed.shape)\n",
    "print('test_speed.shape = ',test_speed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 15\n",
    "mode = 'multi'\n",
    "train_speed_x,train_speed_y = create_dataset(train_speed,train_speed_y, look_back, mode)\n",
    "train_speed_c,_ = create_dataset(train_count,train_count, look_back, mode)\n",
    "train_speed_o,_ = create_dataset(train_occup,train_occup, look_back, mode)\n",
    "train_speed_x = np.concatenate((train_speed_x,train_speed_c,train_speed_o),axis=-1)\n",
    "\n",
    "test_speed_x,test_speed_y = create_dataset(test_speed,test_speed_y, look_back, mode)\n",
    "test_speed_c,_ = create_dataset(test_count,test_count, look_back, mode)\n",
    "test_speed_o,_ = create_dataset(test_occup,test_occup, look_back, mode)\n",
    "test_speed_x = np.concatenate((test_speed_x,test_speed_c,test_speed_o),axis=-1)\n",
    "\n",
    "print('look_back = ',look_back)\n",
    "print('mode = ',mode)\n",
    "print('train_speed_x.shape = ',train_speed_x.shape)\n",
    "print('train_speed_y.shape = ',train_speed_y.shape)\n",
    "print('test_speed_x.shape = ',test_speed_x.shape)\n",
    "print('test_speed_y.shape = ',test_speed_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plt.plot(test_speed_y[0,390:510,:1])  #12-19-2016 Monday 6:30AM - 8:30AM\n",
    "# plt.pcolor(test_speed_y[0,390:510,:].transpose(),cmap=my_cmap, vmin=20, vmax=70)  #12-19-2016 Monday 6:30AM - 8:30AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = train_speed_x.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(look_back, train_speed_x.shape[3]), stateful=False, return_sequences=True))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(LSTM(32, input_shape=(look_back, train_speed_x.shape[3]), stateful=False))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(train_speed_y.shape[2]))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "train_x = np.reshape(train_speed_x,(train_speed_x.shape[0]*train_speed_x.shape[1],train_speed_x.shape[2],train_speed_x.shape[3]))\n",
    "train_y = np.reshape(train_speed_y,(train_speed_y.shape[0]*train_speed_y.shape[1],train_speed_y.shape[2]))\n",
    "history = model.fit(train_x, train_y,epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "# history_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    look_ahead = 120\n",
    "    start = 390\n",
    "    trainPredict = test_speed_x[0,start,:,:]\n",
    "    predictions = np.zeros((look_ahead,15))\n",
    "\n",
    "#     for i in range(look_ahead):\n",
    "#         prediction = model.predict(np.array([trainPredict]), batch_size=batch_size)\n",
    "#         predictions[i] = prediction\n",
    "#         trainPredict = np.vstack([trainPredict[1:],prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples_normalized = scaler.transform(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_plot_multi_co(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment14: input: multivariate speed, count, occup; output: multivariate speed; lookback = 15; lookback weeks = 15 (as feature);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment15: input: multivariate speed, count, occup; output: multivariate speed; lookback = 15; lookback weeks = 6 (parallel structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment16: input: multivariate speed, count, occup; output: multivariate delta speed; lookback = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment17: input: multivariate speed, count, occup; output: multivariate delta speed; lookback = 15; lookback weeks = 15 (as feature);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment18: input: multivariate speed, count, occup; output: multivariate delta speed; lookback = 15; lookback weeks = 6 (parallel structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
