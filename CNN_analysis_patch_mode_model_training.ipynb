{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import xml.etree.ElementTree as ET\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "from moviepy.editor import VideoFileClip,ImageSequenceClip\n",
    "from IPython.display import HTML\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import pickle\n",
    "from pylab import *\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "cdict = {'red': ((0.0, 1.0, 1.0),\n",
    "                 (0.125, 1.0, 1.0),\n",
    "                 (0.25, 1.0, 1.0),\n",
    "                 (0.5625, 1.0, 1.0),\n",
    "                 (1.0, 0.0, 0.0)),\n",
    "         'green': ((0.0, 0.0, 0.0),\n",
    "                   (0.25, 0.0, 0.0),\n",
    "                   (0.5625, 1.0, 1.0),\n",
    "                   (1.0, 1.0, 1.0)),\n",
    "         'blue': ((0.0, 0.0, 0.0),\n",
    "                  (0.5, 0.0, 0.0),\n",
    "                  (1.0, 0.0, 0.0))}\n",
    "my_cmap = matplotlib.colors.LinearSegmentedColormap('my_colormap',cdict,256)\n",
    "\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_history = True\n",
    "weights_file_name = 'CNN_patch_weather_and_history'\n",
    "batch_size = 1000\n",
    "epochs = 10000\n",
    "# use_history = False\n",
    "# weights_file_name = 'CNN_weather_only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015 data loaded\n",
      "2016 data loaded\n"
     ]
    }
   ],
   "source": [
    "which_data = 'Data_2015_DES_I235E'\n",
    "(Traffic_2015,Weather_2015,data_2015) = pickle.load( open(which_data+\"_filter_smooth.p\", \"rb\" ) )\n",
    "year =  data_2015['y'][0][:4]\n",
    "print('{} data loaded'.format(year))\n",
    "\n",
    "which_data = 'Data_2016_DES_I235E'\n",
    "(Traffic_2016,Weather_2016,data_2016) = pickle.load( open(which_data+\"_filter_smooth.p\", \"rb\" ) )\n",
    "year =  data_2016['y'][0][:4]\n",
    "print('{} data loaded'.format(year))\n",
    "\n",
    "data = pd.concat([data_2015,data_2016],ignore_index=True)\n",
    "Traffic = np.concatenate([Traffic_2015, Traffic_2016],axis = 0)\n",
    "Weather_5min = np.concatenate([Weather_2015, Weather_2016],axis = 0)\n",
    "Weather = np.zeros([Weather_5min.shape[0],Weather_5min.shape[1],Weather_5min.shape[2]*5,Weather_5min.shape[3]])\n",
    "for i in range(Weather.shape[2]):\n",
    "    Weather[:,:,i,:] = Weather_5min[:,:,int(i/5),:]\n",
    "Weather = np.delete(Weather,1,axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_SpeedPrediction_patch_database(Dataset):\n",
    "    def __init__(self, Traffic, Weather, data, transform=None, look_back = 6, patch_length = 120, stride = 10):\n",
    "        '''\n",
    "        patch_length = 120 minutes =2 hrs\n",
    "        stride = 10 minutes \n",
    "        '''\n",
    "\n",
    "        self.Traffic = Traffic\n",
    "        self.Weather = Weather\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.look_back = look_back\n",
    "        self.patch_length = patch_length\n",
    "        self.stride = stride\n",
    "        self.rate = (1440-patch_length)/stride+1\n",
    "#         printdb_trans_1 = Dataset_NVIDIA_1(annotation_list,frame_list,transform = PerspectiveTransform(MAP_FILE, world_origin, pixel_ratio, PMAT_FILE))(self.__len__())\n",
    "    def __len__(self):\n",
    "        return int(len(self.data)*self.rate)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        assert idx < self.__len__(),'idx out of dataset index boundary'\n",
    "        \n",
    "        day_idx = int(idx/self.rate)\n",
    "        hr_idx = int(idx%self.rate)\n",
    "        Traffic_today = self.Traffic[day_idx,:,hr_idx*self.stride:hr_idx*self.stride+self.patch_length,:]\n",
    "        Weather_today = self.Weather[day_idx,:,hr_idx*self.stride:hr_idx*self.stride+self.patch_length,:]\n",
    "        Traffic_history = 0 \n",
    "        Traffic_output = self.Traffic[day_idx,:,hr_idx*self.stride:hr_idx*self.stride+self.patch_length,0]\n",
    "        \n",
    "        dayofweek = self.data.loc[day_idx]['dayofweek']\n",
    "        data_sub = self.data[:day_idx]\n",
    "        sameday_in_history = data_sub.index[data_sub['dayofweek'] == dayofweek].tolist()\n",
    "        \n",
    "#         Traffic_history = np.full((self.look_back,)+self.Traffic.shape[1:], np.nan)\n",
    "        \n",
    "        Traffic_history = [self.Traffic[day_idx,:,hr_idx*self.stride:(hr_idx*self.stride+self.patch_length),:]+np.random.randn(15,self.patch_length,3) for _ in range(self.look_back)]\n",
    "        Traffic_history = np.stack(Traffic_history,0)\n",
    "#         print(len(sameday_in_history))\n",
    "        sameday_in_near_history = sameday_in_history[-self.look_back:]\n",
    "#         print(len(sameday_in_near_history))\n",
    "        \n",
    "        for i in range(len(sameday_in_near_history)):\n",
    "            Traffic_history[self.look_back-len(sameday_in_near_history)+i] = self.Traffic[sameday_in_near_history[i],:,hr_idx*self.stride:hr_idx*self.stride+self.patch_length,:]\n",
    "        \n",
    "        sample = {'weather': torch.Tensor(Weather_today), 'history': torch.Tensor(Traffic_history), 'label': torch.Tensor(Traffic_output)} # \n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = CNN_SpeedPrediction_patch_database(Traffic, Weather, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X                      20161216Dir1.csv\n",
      "y             20161216_Traffic_Dir1.csv\n",
      "day                            20161216\n",
      "date                2016-12-16 00:00:00\n",
      "dayofweek                             4\n",
      "weekofyear                           50\n",
      "month                                12\n",
      "dayofyear                           351\n",
      "Name: 431, dtype: object\n",
      "dict_keys(['weather', 'history', 'label'])\n",
      "torch.Size([6, 15, 120, 3])\n",
      "torch.Size([15, 120, 9])\n",
      "torch.Size([15, 120])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rate = (1440-120)/10+1\n",
    "idx = 431  # test: [417,420,431]\n",
    "print(data.loc[idx])\n",
    "\n",
    "def vis_one_day_traffic_speed(speed):\n",
    "    plt.pcolor(speed,cmap=my_cmap, vmin=20, vmax=70)\n",
    "idx = idx*rate + 90\n",
    "# vis_one_day_traffic_speed(db[257]['label'])\n",
    "print(db[idx].keys())\n",
    "print(db[idx]['history'].shape)\n",
    "print(db[idx]['weather'].shape)\n",
    "print(db[idx]['label'].shape)\n",
    "vis_one_day_traffic_speed(db[idx]['label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[:-30]\n",
    "data_train = data_train.reset_index()\n",
    "\n",
    "data_val = data[-61:]\n",
    "data_val = data_val.reset_index()\n",
    "\n",
    "dataset = {}\n",
    "dataset['train'] = CNN_SpeedPrediction_patch_database(Traffic[:-30], Weather[:-30], data_train)\n",
    "dataset['val'] = CNN_SpeedPrediction_patch_database(Traffic[-61:], Weather[-61:], data_val)\n",
    "\n",
    "dataset_sizes = {x: len(dataset[x]) for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(dataset[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dataloaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 15, 120, 9])\n"
     ]
    }
   ],
   "source": [
    "# for sample in dataloaders['train']:\n",
    "#     print(sample['weather'].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''https://github.com/wkelongws/iemgrid'''\n",
    "'''Weather: 0:tmpc 1:dwpc 2:smps 3:drct 4:vsby 5:roadtmpc 6:srad 7:snwd 8:pcpn '''\n",
    "\n",
    "Traffic_max = []\n",
    "Traffic_min = []\n",
    "Weather_max = []\n",
    "Weather_min = []\n",
    "\n",
    "for i in range(Traffic.shape[-1]):\n",
    "#     print(i,'max: ',np.max(Traffic[:,:,:,i]))\n",
    "    Traffic_max.append(np.max(Traffic[:,:,:,i]))\n",
    "#     print(i,'mean: ',np.mean(Traffic[:,:,:,i]))\n",
    "#     print(i,'min: ',np.min(Traffic[:,:,:,i]))\n",
    "    Traffic_min.append(np.min(Traffic[:,:,:,i]))\n",
    "for i in range(Weather.shape[-1]):\n",
    "#     print(i,'max: ',np.max(Weather[:,:,:,i]))\n",
    "    Weather_max.append(np.max(Weather[:,:,:,i]))\n",
    "#     print(i,'mean: ',np.mean(Weather[:,:,:,i]))\n",
    "#     print(i,'min: ',np.min(Weather[:,:,:,i]))\n",
    "    Weather_min.append(np.min(Weather[:,:,:,i]))\n",
    "    \n",
    "Min_Max = (Traffic_max,Traffic_min,Weather_max,Weather_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Long_Term_Speed_Pred_Net(nn.Module):\n",
    "    def __init__(self, use_gpu = True, use_history = True, Min_Max = Min_Max):\n",
    "        super(CNN_Long_Term_Speed_Pred_Net, self).__init__()\n",
    "        \n",
    "        self.use_gpu = use_gpu\n",
    "        self.use_history = use_history\n",
    "\n",
    "        '''for on-fly normalization'''\n",
    "        self.Traffic_max = Min_Max[0]\n",
    "        self.Traffic_min = Min_Max[1]\n",
    "        self.Weather_max = Min_Max[2]\n",
    "        self.Weather_min = Min_Max[3]\n",
    "        \n",
    "        self.weather_layer1_conv2d = nn.Conv2d(in_channels=9, out_channels=2, kernel_size=(1,1))\n",
    "        self.weather_layer2_conv2d = nn.Conv2d(in_channels=2, out_channels=2, kernel_size=(3,3))\n",
    "        self.weather_layer3_conv2d = nn.Conv2d(in_channels=2, out_channels=3, kernel_size=(3,3))\n",
    "        \n",
    "        self.history_layer1_conv3d = nn.Conv3d(in_channels=1, out_channels=2, kernel_size=(3,3,3))\n",
    "        self.history_layer2_conv2d = nn.Conv2d(in_channels=8, out_channels=2, kernel_size=(1,1))\n",
    "        self.history_layer3_conv2d = nn.Conv2d(in_channels=2, out_channels=3, kernel_size=(3,3))\n",
    "        \n",
    "        self.decoder_layer1_conv2d = nn.ConvTranspose2d(in_channels=3, out_channels=1, kernel_size=(3,3))\n",
    "        self.decoder_layer2_conv2d = nn.ConvTranspose2d(in_channels=1, out_channels=1, kernel_size=(3,3))\n",
    "\n",
    "    def forward(self, input_sample, future = 0, use_gpu = True):\n",
    "        \n",
    "        '''reconstruct data from sample'''\n",
    "        weather = input_sample['weather']\n",
    "        history = input_sample['history']\n",
    "        label = input_sample['label']\n",
    "        \n",
    "        '''normalize'''\n",
    "#         label = (label - self.Traffic_min[0])/(self.Traffic_max[0]-self.Traffic_min[0])\n",
    "        for i in range(history.shape[-1]):\n",
    "            history[:,:,:,:,i] = (history[:,:,:,:,i]-self.Traffic_min[i])/(self.Traffic_max[i]-self.Traffic_min[i])\n",
    "        for i in range(weather.shape[-1]):\n",
    "            weather[:,:,:,i] = (weather[:,:,:,i]-self.Weather_min[i])/(self.Weather_max[i]-self.Weather_min[i])\n",
    "        \n",
    "        '''re-arrange inputs'''\n",
    "        input_history = history[:,:,:,:,0].unsqueeze(1)\n",
    "        input_weather = weather.permute(0,3,1,2)\n",
    "            \n",
    "        if use_gpu:\n",
    "            input_history = Variable(input_history.cuda())\n",
    "            input_weather = Variable(input_weather.cuda())\n",
    "            label = Variable(label.cuda())\n",
    "        else:\n",
    "            input_history = Variable(input_history)\n",
    "            input_weather = Variable(input_weather)\n",
    "            label = Variable(label)\n",
    "        \n",
    "        '''feedforward'''\n",
    "        weather_feature_map_1 = self.weather_layer1_conv2d(input_weather)\n",
    "        weather_feature_map_2 = self.weather_layer2_conv2d(weather_feature_map_1)\n",
    "        weather_feature_map_3 = self.weather_layer3_conv2d(weather_feature_map_2)\n",
    "        encoded_feature_map = weather_feature_map_3\n",
    "        \n",
    "        if self.use_history:\n",
    "            history_feature_map_1 = self.history_layer1_conv3d(input_history)\n",
    "            history_feature_map_1 = torch.cat([history_feature_map_1[:,i,:,:,:] for i in range(history_feature_map_1.shape[1])],1)\n",
    "            history_feature_map_2 = self.history_layer2_conv2d(history_feature_map_1)\n",
    "            history_feature_map_3 = self.history_layer3_conv2d(history_feature_map_2)\n",
    "            encoded_feature_map += history_feature_map_3\n",
    "        \n",
    "        upsampled_feature_map = self.decoder_layer1_conv2d(encoded_feature_map)\n",
    "        output = self.decoder_layer2_conv2d(upsampled_feature_map).squeeze(1)\n",
    "        output = output*(self.Traffic_max[0]-self.Traffic_min[0])+self.Traffic_min[0] \n",
    "        \n",
    "        return output, label\n",
    "\n",
    "    \n",
    "class CNN_deeper_Long_Term_Speed_Pred_Net(nn.Module):\n",
    "    def __init__(self, use_gpu = True, use_history = True, Min_Max = Min_Max):\n",
    "        super(CNN_Long_Term_Speed_Pred_Net, self).__init__()\n",
    "        \n",
    "        self.use_gpu = use_gpu\n",
    "        self.use_history = use_history\n",
    "\n",
    "        '''for on-fly normalization'''\n",
    "        self.Traffic_max = Min_Max[0]\n",
    "        self.Traffic_min = Min_Max[1]\n",
    "        self.Weather_max = Min_Max[2]\n",
    "        self.Weather_min = Min_Max[3]\n",
    "        \n",
    "        self.weather_layer1_conv2d = nn.Conv2d(in_channels=9, out_channels=2, kernel_size=(1,1))\n",
    "        self.weather_layer2_conv2d = nn.Conv2d(in_channels=2, out_channels=8, kernel_size=(3,3))\n",
    "        self.weather_layer3_conv2d = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3))\n",
    "        \n",
    "        self.history_layer1_conv3d = nn.Conv3d(in_channels=1, out_channels=2, kernel_size=(3,3,3))\n",
    "        self.history_layer2_conv2d = nn.Conv2d(in_channels=8, out_channels=2, kernel_size=(1,1))\n",
    "        self.history_layer3_conv2d = nn.Conv2d(in_channels=2, out_channels=16, kernel_size=(3,3))\n",
    "        \n",
    "        self.decoder_layer1_conv2d = nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=(3,3))\n",
    "        self.decoder_layer2_conv2d = nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=(3,3))\n",
    "\n",
    "    def forward(self, input_sample, future = 0, use_gpu = True):\n",
    "        \n",
    "        '''reconstruct data from sample'''\n",
    "        weather = input_sample['weather']\n",
    "        history = input_sample['history']\n",
    "        label = input_sample['label']\n",
    "        \n",
    "        '''normalize'''\n",
    "#         label = (label - self.Traffic_min[0])/(self.Traffic_max[0]-self.Traffic_min[0])\n",
    "        for i in range(history.shape[-1]):\n",
    "            history[:,:,:,:,i] = (history[:,:,:,:,i]-self.Traffic_min[i])/(self.Traffic_max[i]-self.Traffic_min[i])\n",
    "        for i in range(weather.shape[-1]):\n",
    "            weather[:,:,:,i] = (weather[:,:,:,i]-self.Weather_min[i])/(self.Weather_max[i]-self.Weather_min[i])\n",
    "        \n",
    "        '''re-arrange inputs'''\n",
    "        input_history = history[:,:,:,:,0].unsqueeze(1)\n",
    "        input_weather = weather.permute(0,3,1,2)\n",
    "            \n",
    "        if use_gpu:\n",
    "            input_history = Variable(input_history.cuda())\n",
    "            input_weather = Variable(input_weather.cuda())\n",
    "            label = Variable(label.cuda())\n",
    "        else:\n",
    "            input_history = Variable(input_history)\n",
    "            input_weather = Variable(input_weather)\n",
    "            label = Variable(label)\n",
    "        \n",
    "        '''feedforward'''\n",
    "        weather_feature_map_1 = self.weather_layer1_conv2d(input_weather)\n",
    "        weather_feature_map_2 = self.weather_layer2_conv2d(weather_feature_map_1)\n",
    "        weather_feature_map_3 = self.weather_layer3_conv2d(weather_feature_map_2)\n",
    "        encoded_feature_map = weather_feature_map_3\n",
    "        \n",
    "        if self.use_history:\n",
    "            history_feature_map_1 = self.history_layer1_conv3d(input_history)\n",
    "            history_feature_map_1 = torch.cat([history_feature_map_1[:,i,:,:,:] for i in range(history_feature_map_1.shape[1])],1)\n",
    "            history_feature_map_2 = self.history_layer2_conv2d(history_feature_map_1)\n",
    "            history_feature_map_3 = self.history_layer3_conv2d(history_feature_map_2)\n",
    "            encoded_feature_map += history_feature_map_3\n",
    "        \n",
    "        upsampled_feature_map = self.decoder_layer1_conv2d(encoded_feature_map)\n",
    "        output = self.decoder_layer2_conv2d(upsampled_feature_map).squeeze(1)\n",
    "        output = output*(self.Traffic_max[0]-self.Traffic_min[0])+self.Traffic_min[0] \n",
    "        \n",
    "        return output, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "\n",
    "model = CNN_Long_Term_Speed_Pred_Net(use_gpu = use_gpu, use_history = use_history, Min_Max = Min_Max)\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CNN_LongTerm_SP_Net(model,dataloaders, criterion, optimizer, dataset_sizes, num_epochs=100, weights_file_name = weights_file_name):\n",
    "    since = time.time()\n",
    "\n",
    "#     timeSince(since)\n",
    "#     model.load_state_dict(torch.load('Best_LSTM_Weights_1st'))\n",
    "#     print()\n",
    "#     print('keep training from previous \"Best_LSTM_Weights_1st\"')\n",
    "#     print()\n",
    "\n",
    "#     vanillaPlus_compromised_dict = torch.load('Best_LSTM_Weights_vanillaPlus')\n",
    "#     vanillaPlus_compromised_dict['linear_out.weight'] = torch.randn(model.state_dict()['linear_out.weight'].shape).cuda()\n",
    "#     vanillaPlus_compromised_dict['linear_out.bias'] = torch.randn(model.state_dict()['linear_out.bias'].shape).cuda()\n",
    "#     model.load_state_dict(vanillaPlus_compromised_dict)\n",
    "#     print()\n",
    "#     print('weights in the output layer are initialized from normal distribution')\n",
    "#     print('and other model weights are loaded from \"Best_LSTM_Weights_vanillaPlus_compromised')\n",
    "#     print('keep training from previous \"Best_LSTM_Weights_vanillaPlus_compromised\"')\n",
    "#     print()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_loss = 100000\n",
    "    losses = {'train':[],'val':[]}\n",
    "    \n",
    "#     losses = pickle.load( open( 'loss_log_'+weights_file_name+'_.p', \"rb\" ) )\n",
    "#     best_loss = losses['val'][-1]\n",
    "#     print('best val loss: {}'.format(best_loss))\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for sample in dataloaders[phase]:\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                model.zero_grad()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Also, we need to clear out the hidden state of the LSTM,\n",
    "                # detaching it from its history on the last instance.\n",
    "#                 model.hidden = model.init_hidden()\n",
    "                \n",
    "                # forward\n",
    "                pred,label = model(sample)\n",
    "                \n",
    "                # loss function\n",
    "#                 loss = customized_loss(pred,label)\n",
    "                loss = criterion(pred,label)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            losses[phase].append(epoch_loss)\n",
    "            print('{} Loss: {:.4f} total elapsed time: {}'.format(phase, epoch_loss, timeSince(since)))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = model.state_dict()\n",
    "                torch.save(best_model_wts, weights_file_name)\n",
    "                print('Weights saved to {}'.format(weights_file_name))\n",
    "                print()\n",
    "                pickle.dump( losses, open( 'loss_log_'+weights_file_name+'_.p', \"wb\" ) )\n",
    "\n",
    "        print()\n",
    "\n",
    "    print('Training complete in {}'.format(timeSince(since)))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "    \n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "#     torch.save(model, 'Model_with_Best_CNN_Weights')\n",
    "#     print('Model saved to \"Model_with_Best_CNN_Weights\"')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = train_CNN_LongTerm_SP_Net(model,dataloaders, criterion, optimizer, dataset_sizes, num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
