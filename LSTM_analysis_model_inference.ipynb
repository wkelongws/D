{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import xml.etree.ElementTree as ET\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "from moviepy.editor import VideoFileClip,ImageSequenceClip\n",
    "from IPython.display import HTML\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import pickle\n",
    "from pylab import *\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "cdict = {'red': ((0.0, 1.0, 1.0),\n",
    "                 (0.125, 1.0, 1.0),\n",
    "                 (0.25, 1.0, 1.0),\n",
    "                 (0.5625, 1.0, 1.0),\n",
    "                 (1.0, 0.0, 0.0)),\n",
    "         'green': ((0.0, 0.0, 0.0),\n",
    "                   (0.25, 0.0, 0.0),\n",
    "                   (0.5625, 1.0, 1.0),\n",
    "                   (1.0, 1.0, 1.0)),\n",
    "         'blue': ((0.0, 0.0, 0.0),\n",
    "                  (0.5, 0.0, 0.0),\n",
    "                  (1.0, 0.0, 0.0))}\n",
    "my_cmap = matplotlib.colors.LinearSegmentedColormap('my_colormap',cdict,256)\n",
    "\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_single_sensor = False\n",
    "use_volume_and_occup = False\n",
    "use_weather = False\n",
    "use_history = True\n",
    "input_feature = 'cnn'\n",
    "weights_file_name = 'Speedonly_with_history'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_log = pickle.load(open('loss_log_'+weights_file_name+'_.p','rb'))\n",
    "# plt.plot(loss_log['val'])\n",
    "print('MSE = {0:.4f}'.format(np.nanmin(loss_log['val'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_SpeedPrediction_database_output_single_sensor(Dataset):\n",
    "    def __init__(self, Traffic, Weather, data, transform=None, look_back = 6, target_sensor = 13):\n",
    "\n",
    "        self.Traffic = Traffic\n",
    "        self.Weather = Weather\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.look_back = look_back\n",
    "        self.target_sensor = target_sensor\n",
    "#         print(self.__len__())\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        assert idx < self.__len__(),'idx out of dataset index boundary'\n",
    "        \n",
    "        Traffic_today = self.Traffic[idx,:,:-1,:]\n",
    "        Weather_today = self.Weather[idx,:,:-1,:]\n",
    "        Traffic_history = 0\n",
    "        Traffic_output = self.Traffic[idx,self.target_sensor,1:,0]\n",
    "        \n",
    "        dayofweek = self.data.loc[idx]['dayofweek']\n",
    "        data_sub = self.data[:idx]\n",
    "        sameday_in_history = data_sub.index[data_sub['dlen(sameday_in_history)ayofweek'] == dayofweek].tolist()\n",
    "        \n",
    "        Traffic_history = np.full((self.look_back,)+self.Traffic.shape[1:], np.nan)\n",
    "#         print(len(sameday_in_history))\n",
    "        sameday_in_near_history = sameday_in_history[-self.look_back:]\n",
    "#         print(len(sameday_in_near_history))\n",
    "        \n",
    "        for i in range(len(sameday_in_near_history)):\n",
    "            Traffic_history[i] = self.Traffic[sameday_in_near_history[i]]\n",
    "        \n",
    "        sample = {'traffic': Traffic_today, 'weather': Weather_today, 'history': Traffic_history, 'label': Traffic_output}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "     \n",
    "class LSTM_SpeedPrediction_database_output_multi_sensor(Dataset):\n",
    "    def __init__(self, Traffic, Weather, data, transform=None, look_back = 6):\n",
    "\n",
    "        self.Traffic = Traffic\n",
    "        self.Weather = Weather\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.look_back = look_back\n",
    "#         printdb_trans_1 = Dataset_NVIDIA_1(annotation_list,frame_list,transform = PerspectiveTransform(MAP_FILE, world_origin, pixel_ratio, PMAT_FILE))(self.__len__())\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        assert idx < self.__len__(),'idx out of dataset index boundary'\n",
    "        Traffic_today = self.Traffic[idx,:,:-1,:]\n",
    "        Weather_today = self.Weather[idx,:,:-1,:]\n",
    "        Traffic_history = 0 \n",
    "        Traffic_output = self.Traffic[idx,:,1:,0]\n",
    "        \n",
    "        dayofweek = self.data.loc[idx]['dayofweek']\n",
    "        data_sub = self.data[:idx]\n",
    "        sameday_in_history = data_sub.index[data_sub['dayofweek'] == dayofweek].tolist()\n",
    "        \n",
    "#         Traffic_history = np.full((self.look_back,)+self.Traffic.shape[1:], np.nan)\n",
    "        \n",
    "        Traffic_history = [self.Traffic[idx,:,:,:]+np.random.randn(15,1440,3) for _ in range(self.look_back)]\n",
    "        Traffic_history = np.stack(Traffic_history,0)\n",
    "        \n",
    "#         print(len(sameday_in_history))\n",
    "        sameday_in_near_history = sameday_in_history[-self.look_back:]\n",
    "#         print(len(sameday_in_near_history))\n",
    "        \n",
    "        for i in range(len(sameday_in_near_history)):\n",
    "            Traffic_history[self.look_back-len(sameday_in_near_history)+i] = self.Traffic[sameday_in_near_history[i]]\n",
    "        \n",
    "        sample = {'traffic': torch.Tensor(Traffic_today),'weather': torch.Tensor(Weather_today), 'history': torch.Tensor(Traffic_history), 'label': torch.Tensor(Traffic_output)} # \n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''''\n",
    "which_data = 'Data_2015_DES_I235E'\n",
    "(Traffic_2015,Weather_2015,data_2015) = pickle.load( open(which_data+\"_filter_smooth.p\", \"rb\" ) )\n",
    "year =  data_2015['y'][0][:4]\n",
    "print('{} data loaded'.format(year))\n",
    "\n",
    "which_data = 'Data_2016_DES_I235E'\n",
    "(Traffic_2016,Weather_2016,data_2016) = pickle.load( open(which_data+\"_filter_smooth.p\", \"rb\" ) )\n",
    "year =  data_2016['y'][0][:4]\n",
    "print('{} data loaded'.format(year))\n",
    "\n",
    "data = pd.concat([data_2015,data_2016],ignore_index=True)\n",
    "Traffic = np.concatenate([Traffic_2015, Traffic_2016],axis = 0)\n",
    "Weather_5min = np.concatenate([Weather_2015, Weather_2016],axis = 0)\n",
    "Weather = np.zeros([Weather_5min.shape[0],Weather_5min.shape[1],Weather_5min.shape[2]*5,Weather_5min.shape[3]])\n",
    "for i in range(Weather.shape[2]):\n",
    "    Weather[:,:,i,:] = Weather_5min[:,:,int(i/5),:]\n",
    "Weather = np.delete(Weather,1,axis=3)\n",
    "\n",
    "\n",
    "db = LSTM_SpeedPrediction_database_output_multi_sensor(Traffic, Weather, data)\n",
    "print('database \"db\" built from file')\n",
    "\n",
    "Traffic_max = []\n",
    "Traffic_min = []\n",
    "Weather_max = []\n",
    "Weather_min = []\n",
    "\n",
    "for i in range(Traffic.shape[-1]):\n",
    "    Traffic_max.append(np.max(Traffic[:,:,:,i]))\n",
    "    Traffic_min.append(np.min(Traffic[:,:,:,i]))\n",
    "for i in range(Weather.shape[-1]):\n",
    "    Weather_max.append(np.max(Weather[:,:,:,i]))\n",
    "    Weather_min.append(np.min(Weather[:,:,:,i]))\n",
    "    \n",
    "Min_Max = (Traffic_max,Traffic_min,Weather_max,Weather_min)\n",
    "\n",
    "loss_log = pickle.load( open('loss_log_'+weights_file_name+'_.p', \"rb\" ) )\n",
    "print('training log loaded into loss_log')\n",
    "''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Short_Term_Speed_Pred_Net(nn.Module):\n",
    "    def __init__(self, filter_height = 5, output_single_sensor = False, \\\n",
    "                 hidden_dim = 16,use_gpu = True, use_volume_and_occup = False, \\\n",
    "                 use_weather = False, use_history = True, input_feature = 'cnn', Min_Max = Min_Max):\n",
    "        super(LSTM_Short_Term_Speed_Pred_Net, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.out_dim = 15\n",
    "        \n",
    "        self.input_dim_today = self.out_dim\n",
    "        self.input_dim_history = self.out_dim\n",
    "        if input_feature == 'cnn':\n",
    "            self.input_dim_today = self.out_dim - filter_height + 1\n",
    "            self.input_dim_history = self.out_dim - filter_height + 1\n",
    "#         else:\n",
    "#             self.input_dim_today = self.out_dim\n",
    "#             self.input_dim_history = self.out_dim\n",
    "        \n",
    "        if output_single_sensor:\n",
    "            self.out_dim = out_dim = 1\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        self.use_volume_and_occup = use_volume_and_occup\n",
    "        self.use_weather = use_weather\n",
    "        self.use_history = use_history\n",
    "#         assert input_feature in ['raw','linear','cnn'], 'wrong choice for input_feature'\n",
    "        assert input_feature == 'cnn', 'currently only allow cnn as input feature extractor'\n",
    "        self.input_feature = input_feature # ['raw','linear','CNN']\n",
    "        \n",
    "        '''for on-fly normalization'''\n",
    "        self.Traffic_max = Min_Max[0]\n",
    "        self.Traffic_min = Min_Max[1]\n",
    "        self.Weather_max = Min_Max[2]\n",
    "        self.Weather_min = Min_Max[3]\n",
    "        \n",
    "        if self.input_feature == 'cnn':\n",
    "            self.CNN_feature_extract = nn.Conv2d(1, 1, (filter_height, 1), stride=(1, 1))\n",
    "            self.CNN_for_history = self.CNN_feature_extract\n",
    "            if self.use_volume_and_occup:\n",
    "                self.CNN_feature_extract = nn.Conv2d(1, 1, (filter_height, 3), stride=(1, 1))\n",
    "            if self.use_weather:\n",
    "                self.CNN_feature_extract = nn.Conv2d(1, 1, (filter_height, 12), stride=(1, 1))\n",
    "        self.CNN_today_and_history_output_combine = nn.Conv2d(1, 1, (1, 2), stride=(1, 1))\n",
    "        self.lstm_today = nn.LSTMCell(self.input_dim_today, self.hidden_dim)\n",
    "        self.lstm_history = nn.LSTMCell(self.input_dim_history, self.hidden_dim)\n",
    "        self.linear_out = nn.Linear(self.hidden_dim, self.out_dim)\n",
    "        \n",
    "    def init_hidden(self,input_sample):\n",
    "        \n",
    "        batch_size = input_sample['traffic'].shape[0]\n",
    "        if self.use_gpu:\n",
    "            return Variable(torch.zeros(batch_size, self.hidden_dim).cuda(), requires_grad=False)\n",
    "        return Variable(torch.zeros(batch_size, self.hidden_dim), requires_grad=False)\n",
    "\n",
    "    def LSTM_update(self,input_t,hidden_state_today,cell_state_today):\n",
    "        input_t = input_t.squeeze(3).squeeze(1)\n",
    "        hidden_state_today, cell_state_today = self.lstm_today(input_t, (hidden_state_today, cell_state_today))\n",
    "        hidden_state_output = hidden_state_today\n",
    "        return hidden_state_today, cell_state_today, hidden_state_output\n",
    " \n",
    "    def LSTM_update_with_history(self,input_t,input_history,hidden_state_today,cell_state_today,hidden_state_history,cell_state_history):\n",
    "        input_t = input_t.squeeze(3).squeeze(1)\n",
    "        hidden_state_today, cell_state_today = self.lstm_today(input_t, (hidden_state_today, cell_state_today))\n",
    "        if len(input_history)>0:\n",
    "            for input_t_history in input_history:\n",
    "                input_h = input_t_history.squeeze(3).squeeze(1)\n",
    "                hidden_state_history, cell_state_history = self.lstm_history(input_h, (hidden_state_history, cell_state_history))\n",
    "\n",
    "            h_combine = torch.stack([hidden_state_today,hidden_state_history],2)\n",
    "            h_combine = h_combine.unsqueeze(1)\n",
    "            hidden_state_output = self.CNN_today_and_history_output_combine(h_combine)\n",
    "            hidden_state_output = hidden_state_output.squeeze(3).squeeze(1)\n",
    "            return hidden_state_today, cell_state_today, hidden_state_output\n",
    "        else:\n",
    "            hidden_state_output = hidden_state_today\n",
    "            return hidden_state_today, cell_state_today, hidden_state_output\n",
    "        \n",
    "\n",
    "    def forward(self, input_sample, future = 0, use_gpu = True):\n",
    "        \n",
    "        '''reconstruct data from sample'''\n",
    "        traffic = input_sample['traffic']\n",
    "        weather = input_sample['weather']\n",
    "        history = input_sample['history']\n",
    "        label = input_sample['label']\n",
    "        \n",
    "        '''normalize'''\n",
    "#         label = (label - self.Traffic_min[0])/(self.Traffic_max[0]-self.Traffic_min[0])\n",
    "        for i in range(traffic.shape[-1]):\n",
    "            traffic[:,:,:,i] = (traffic[:,:,:,i]-self.Traffic_min[i])/(self.Traffic_max[i]-self.Traffic_min[i])\n",
    "            history[:,:,:,:,i] = (history[:,:,:,:,i]-self.Traffic_min[i])/(self.Traffic_max[i]-self.Traffic_min[i])\n",
    "        for i in range(weather.shape[-1]):\n",
    "            weather[:,:,:,i] = (weather[:,:,:,i]-self.Weather_min[i])/(self.Weather_max[i]-self.Weather_min[i])\n",
    "        \n",
    "        '''re-arrange inputs'''\n",
    "        input_today = traffic[:,:,:,0:1]\n",
    "        \n",
    "        if self.use_volume_and_occup:\n",
    "            input_today = traffic\n",
    "            \n",
    "        if self.use_weather:\n",
    "            input_today = torch.cat([traffic,weather],3)\n",
    "            \n",
    "        input_history = history[:,:,:,:,0:1]\n",
    "            \n",
    "        if use_gpu:\n",
    "            input_today = Variable(input_today.cuda())\n",
    "            input_history = Variable(input_history.cuda())\n",
    "            label = Variable(label.cuda())\n",
    "        else:\n",
    "            input_today = Variable(input_today)\n",
    "            input_history = Variable(input_history)\n",
    "            label = Variable(label)\n",
    "        \n",
    "        '''feedforward'''\n",
    "        \n",
    "        outputs = []\n",
    "        hidden_state_today = self.init_hidden(input_sample)\n",
    "        cell_state_today = self.init_hidden(input_sample)\n",
    "        hidden_state_history = self.init_hidden(input_sample)\n",
    "        cell_state_history = self.init_hidden(input_sample)\n",
    "#         print(input_today.data.shape[2])\n",
    "        for i in range(input_today.data.shape[2]):\n",
    "            \n",
    "            input_t = input_today[:,:,i:i+1,:]\n",
    "            input_t = input_t.permute(0,2,1,3)\n",
    "            \n",
    "            input_t_history = []\n",
    "#             print(input_history.shape[1])\n",
    "            for k in range(input_history.shape[1]):\n",
    "                if not np.isnan(np.array(input_history[0,k,0,0,0].data))[0]:\n",
    "                    input_t_history.append(input_history[:,k,:,i+1:i+2,:].permute(0,2,1,3))\n",
    "#             print(len(input_t_history))\n",
    "\n",
    "            if self.input_feature == 'cnn':\n",
    "                input_t = self.CNN_feature_extract(input_t)\n",
    "                input_t_history = [self.CNN_for_history(x) for x in input_t_history]\n",
    "\n",
    "            if self.use_history:\n",
    "                hidden_state_today, cell_state_today, hidden_state_output = self.LSTM_update_with_history(input_t,input_t_history,hidden_state_today,cell_state_today,hidden_state_history,cell_state_history)\n",
    "            else:\n",
    "                hidden_state_today, cell_state_today, hidden_state_output = self.LSTM_update(input_t,hidden_state_today,cell_state_today)\n",
    "            \n",
    "            output = nn.functional.sigmoid(self.linear_out(hidden_state_output))\n",
    "            output = output*(self.Traffic_max[0]-self.Traffic_min[0])+self.Traffic_min[0] \n",
    "            outputs += [output]\n",
    "        outputs = torch.stack(outputs, 2)\n",
    "\n",
    "        return outputs, label\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "model = LSTM_Short_Term_Speed_Pred_Net(filter_height = 5, output_single_sensor = output_single_sensor, \\\n",
    "                 hidden_dim = 16,use_gpu = use_gpu, use_volume_and_occup = use_volume_and_occup, \\\n",
    "                 use_weather = use_weather, use_history = use_history, input_feature = input_feature)\n",
    "print('model structure built from class')\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "model.load_state_dict(torch.load(weights_file_name))\n",
    "print('model weights loaded from {}'.format(weights_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 431  # test: [417,420,431]\n",
    "print(data.loc[idx])\n",
    "\n",
    "def vis_one_day_traffic_speed(speed):\n",
    "    plt.pcolor(speed,cmap=my_cmap, vmin=20, vmax=70)\n",
    "    \n",
    "# vis_one_day_traffic_speed(db[257]['label'])\n",
    "print(type(db[idx]['traffic']))\n",
    "print(db[idx].keys())\n",
    "print('db[idx][\"traffic\"].shape: ',db[idx]['traffic'].shape)\n",
    "print('db[idx][\"weather\"].shape: ',db[idx]['weather'].shape)\n",
    "print('db[idx][\"history\"].shape: ',db[idx]['history'].shape)\n",
    "print('db[idx][\"label\"].shape: ',db[idx]['label'].shape)\n",
    "vis_one_day_traffic_speed(db[idx]['traffic'][:,:,0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_patch_dim_to_sample(sample):\n",
    "    traffic = sample['traffic'].unsqueeze(0)\n",
    "    weather = sample['weather'].unsqueeze(0)\n",
    "    label = sample['label'].unsqueeze(0)\n",
    "    history = sample['history'].unsqueeze(0)\n",
    "    sample = {'traffic':traffic,'weather':weather,'label':label,'history':history}\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out,label=model(add_patch_dim_to_sample(db[idx]))\n",
    "# label = label.squeeze(0).data.cpu().numpy()\n",
    "# out = out.squeeze(0).data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis_one_day_traffic_speed(label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis_one_day_traffic_speed(out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_hidden():\n",
    "        \n",
    "    batch_size = 1\n",
    "    hidden_dim = 16\n",
    "    if use_gpu:\n",
    "        return Variable(torch.zeros(batch_size, hidden_dim).cuda(), requires_grad=False)\n",
    "    return Variable(torch.zeros(batch_size, hidden_dim), requires_grad=False)\n",
    "    \n",
    "def inference(input_sample,model,step_ahead,Min_Max=Min_Max):\n",
    "    \n",
    "    Traffic_max = Min_Max[0]\n",
    "    Traffic_min = Min_Max[1]\n",
    "    Weather_max = Min_Max[2]\n",
    "    Weather_min = Min_Max[3]\n",
    "    \n",
    "    '''reconstruct data from sample'''\n",
    "    traffic = input_sample['traffic']\n",
    "    weather = input_sample['weather']\n",
    "    history = input_sample['history']\n",
    "    label = input_sample['label']\n",
    "        \n",
    "    '''normalize'''\n",
    "#         label = (label - self.Traffic_min[0])/(self.Traffic_max[0]-self.Traffic_min[0])\n",
    "    for i in range(traffic.shape[-1]):\n",
    "        traffic[:,:,i] = (traffic[:,:,i]-Traffic_min[i])/(Traffic_max[i]-Traffic_min[i])\n",
    "        history[:,:,:,i] = (history[:,:,:,i]-Traffic_min[i])/(Traffic_max[i]-Traffic_min[i])\n",
    "    for i in range(weather.shape[-1]):\n",
    "        weather[:,:,i] = (weather[:,:,i]-Weather_min[i])/(Weather_max[i]-Weather_min[i])\n",
    "        \n",
    "    '''re-arrange inputs'''\n",
    "    input_today = traffic[:,:,0:1]\n",
    "        \n",
    "    if use_volume_and_occup:\n",
    "        input_today = traffic\n",
    "            \n",
    "    if use_weather:\n",
    "        input_today = torch.cat([traffic,weather],2)\n",
    "            \n",
    "    input_history = history[:,:,:,0:1]\n",
    "            \n",
    "    if use_gpu:\n",
    "        input_today = Variable(input_today.cuda())\n",
    "        input_history = Variable(input_history.cuda())\n",
    "        label = Variable(label.cuda())\n",
    "    else:\n",
    "        input_today = Variable(input_today)\n",
    "        input_history = Variable(input_history)\n",
    "        label = Variable(label)\n",
    "        \n",
    "        '''feedforward'''\n",
    "        \n",
    "    outputs = []\n",
    "    hidden_state_today = init_hidden()\n",
    "    cell_state_today = init_hidden()\n",
    "    hidden_state_history = init_hidden()\n",
    "    cell_state_history = init_hidden()\n",
    "#         print(input_today.data.shape[2])\n",
    "    for i in range(input_today.data.shape[1]-step_ahead+1):\n",
    "            \n",
    "        input_t = input_today[:,i:i+1,:]\n",
    "        input_t = input_t.unsqueeze(0)\n",
    "        input_t = input_t.permute(0,2,1,3)\n",
    "            \n",
    "        input_t_history = []\n",
    "#             print(input_history.shape[1])\n",
    "        for k in range(input_history.shape[0]):\n",
    "            input_t_history.append(input_history[k,:,i+1:i+2,:].unsqueeze(0).permute(0,2,1,3))\n",
    "\n",
    "        input_t = model.CNN_feature_extract(input_t)\n",
    "        input_t_history = [model.CNN_for_history(x) for x in input_t_history]\n",
    "\n",
    "        if use_history:\n",
    "            hidden_state_today, cell_state_today, hidden_state_output = model.LSTM_update_with_history(input_t,input_t_history,hidden_state_today,cell_state_today,hidden_state_history,cell_state_history)\n",
    "        else:\n",
    "            hidden_state_today, cell_state_today, hidden_state_output = model.LSTM_update(input_t,hidden_state_today,cell_state_today)\n",
    "            \n",
    "        hidden_state_today_pred = hidden_state_today.clone() \n",
    "        cell_state_today_pred = cell_state_today.clone()\n",
    "        \n",
    "        for j in range(step_ahead-1):\n",
    "            pred_speed_as_input = nn.functional.sigmoid(model.linear_out(hidden_state_output))\n",
    "            pred_speed_as_input = pred_speed_as_input.unsqueeze(2).unsqueeze(0)\n",
    "            pred_feature_as_input = model.CNN_feature_extract(pred_speed_as_input)\n",
    "            \n",
    "            input_t_history = []\n",
    "#             print(input_history.shape[1])\n",
    "            for k in range(input_history.shape[0]):\n",
    "                input_t_history.append(input_history[k,:,i+1+j+1:i+2+j+1,:].unsqueeze(0).permute(0,2,1,3))\n",
    "\n",
    "            input_t_history = [model.CNN_for_history(x) for x in input_t_history]\n",
    "            \n",
    "            if use_history:\n",
    "                hidden_state_today_pred, cell_state_today_pred, hidden_state_output = model.LSTM_update_with_history(pred_feature_as_input,input_t_history,hidden_state_today_pred,cell_state_today_pred,hidden_state_history,cell_state_history)\n",
    "            else:\n",
    "                hidden_state_today_pred, cell_state_today_pred, hidden_state_output = model.LSTM_update(input_t,hidden_state_today_pred,cell_state_today_pred)\n",
    "            \n",
    "        output = nn.functional.sigmoid(model.linear_out(hidden_state_output))\n",
    "        output = output*(Traffic_max[0]-Traffic_min[0])+Traffic_min[0] \n",
    "        outputs += [output]\n",
    "    outputs = torch.stack(outputs, 2).squeeze(0)\n",
    "    return outputs.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 431  # test: [417,420,431]\n",
    "out=inference(db[idx],model,step_ahead=5,Min_Max=Min_Max)\n",
    "\n",
    "gs = gridspec.GridSpec(2, 1, wspace=0.1, hspace=0.1)\n",
    "fig = plt.figure(figsize=(12,14))\n",
    "ax = plt.subplot(gs[0])\n",
    "vis_one_day_traffic_speed(db[idx]['label'])\n",
    "ax = plt.subplot(gs[1])\n",
    "vis_one_day_traffic_speed(out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
