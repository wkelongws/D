{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import xml.etree.ElementTree as ET\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "from moviepy.editor import VideoFileClip,ImageSequenceClip\n",
    "from IPython.display import HTML\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import pickle\n",
    "from pylab import *\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "cdict = {'red': ((0.0, 1.0, 1.0),\n",
    "                 (0.125, 1.0, 1.0),\n",
    "                 (0.25, 1.0, 1.0),\n",
    "                 (0.5625, 1.0, 1.0),\n",
    "                 (1.0, 0.0, 0.0)),\n",
    "         'green': ((0.0, 0.0, 0.0),\n",
    "                   (0.25, 0.0, 0.0),\n",
    "                   (0.5625, 1.0, 1.0),\n",
    "                   (1.0, 1.0, 1.0)),\n",
    "         'blue': ((0.0, 0.0, 0.0),\n",
    "                  (0.5, 0.0, 0.0),\n",
    "                  (1.0, 0.0, 0.0))}\n",
    "my_cmap = matplotlib.colors.LinearSegmentedColormap('my_colormap',cdict,256)\n",
    "\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = [float('nan') , 1 , float('nan')]\n",
    "b = [0 if np.isnan(x) else x for x in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuo/anaconda2/envs/pytorch/lib/python3.5/site-packages/numpy/core/fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/shuo/anaconda2/envs/pytorch/lib/python3.5/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =[]\n",
    "b =np.mean(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import, filter and smooth raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_data = 'Data_2015_DES_I235E'\n",
    "(Traffic_2015,Weather_2015,data_2015) = pickle.load( open(which_data+\".p\", \"rb\" ) )\n",
    "year =  data_2015['y'][0][:4]\n",
    "print('load {} data'.format(year))\n",
    "\n",
    "which_data = 'Data_2016_DES_I235E'\n",
    "(Traffic_2016,Weather_2016,data_2016) = pickle.load( open(which_data+\".p\", \"rb\" ) )\n",
    "year =  data_2016['y'][0][:4]\n",
    "print('load {} data'.format(year))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_nan_with_local_mean(M_3d):\n",
    "    index = np.asarray(np.where(np.isnan(M_3d)))\n",
    "    for i in range(index.shape[1]):\n",
    "        span = 0\n",
    "        historical = M_3d[index[0,i],index[1,i],index[2,i]-span:index[2,i]+1+span]\n",
    "        historical_mean = np.nanmean(historical)\n",
    "        stage_1_flag = True\n",
    "        count = 0 \n",
    "        while (not historical_mean>0) & stage_1_flag:\n",
    "            count+=1\n",
    "            if count > 1000:\n",
    "                print('1st ',count)\n",
    "            if index[0,i]-span<0:\n",
    "                historical = M_3d[0:index[0,i]+1+span+span,index[1,i],index[2,i]]\n",
    "            elif index[0,i]+1+span>M_3d.shape[0]:\n",
    "                historical = M_3d[-1-span-span:,index[1,i],index[2,i]]\n",
    "            else:\n",
    "                historical = M_3d[index[0,i]-span:index[0,i]+1+span,index[1,i],index[2,i]]\n",
    "            historical_mean = np.nanmean(historical)\n",
    "            span+=1\n",
    "            if 2*span>M_3d.shape[0]:\n",
    "                stage_1_flag = False\n",
    "        span = 0\n",
    "        count = 0 \n",
    "        while not historical_mean>0:\n",
    "            count+=1\n",
    "            if count > 1000:\n",
    "                print('2nd ',count)\n",
    "            if index[2,i]-span<0:\n",
    "                historical = M_3d[:,index[1,i],0:index[2,i]+1+span+span]\n",
    "            elif index[2,i]+1+span>M_3d.shape[2]:\n",
    "                historical = M_3d[:,index[1,i],-1-span-span:]\n",
    "            else:\n",
    "                historical = M_3d[:,index[1,i],index[2,i]-span:index[2,i]+1+span]\n",
    "            historical_mean = np.nanmean(historical)\n",
    "            span+=1\n",
    "#         print(historical_mean)\n",
    "\n",
    "        span = 0\n",
    "        count = 0 \n",
    "        local = M_3d[index[0,i],index[1,i],index[2,i]-span:index[2,i]+1+span]\n",
    "        local_mean = np.nanmean(local)\n",
    "        stage_1_flag = True\n",
    "        while (not local_mean>0) & stage_1_flag:\n",
    "            count+=1\n",
    "            if count > 1000:\n",
    "                print('3rd ',count)\n",
    "            if index[2,i]-span<0:\n",
    "                local = M_3d[index[0,i],index[1,i],0:index[2,i]+1+span+span]\n",
    "            elif index[2,i]+1+span>M_3d.shape[2]:\n",
    "                local = M_3d[index[0,i],index[1,i],-1-span-span:]\n",
    "            else:\n",
    "                local = M_3d[index[0,i],index[1,i],index[2,i]-span:index[2,i]+1+span]\n",
    "            local_mean = np.nanmean(local)\n",
    "            span+=1\n",
    "            if 2*span>M_3d.shape[2]:\n",
    "                stage_1_flag = False\n",
    "        \n",
    "        span = 0\n",
    "        count = 0 \n",
    "        while not local_mean>0:\n",
    "            count+=1\n",
    "            if count > 1000:\n",
    "                print('4th ',count)\n",
    "            if index[1,i]-span<0:\n",
    "                local = M_3d[index[0,i],0:index[1,i]+1+span+span,:]\n",
    "            elif index[1,i]+1+span>M_3d.shape[1]:\n",
    "                local = M_3d[index[0,i],-1-span-span:,:]\n",
    "            else:\n",
    "                local = M_3d[index[0,i],index[1,i]-span:index[1,i]+1+span,:]\n",
    "            local_mean = np.nanmean(local)\n",
    "            span+=1\n",
    "        \n",
    "#         print(local_mean)\n",
    "        M_3d[index[0,i],index[1,i],index[2,i]] = 0.7*local_mean + 0.3*historical_mean\n",
    "    return M_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume_smoothing(Volume,top_threshold = 400):\n",
    "    Volume[Volume>top_threshold] = nan\n",
    "    Volume = replace_nan_with_local_mean(Volume)\n",
    "    return Volume\n",
    "\n",
    "def speed_smoothing(Speed,top_threshold = 120):\n",
    "    Speed[Speed>top_threshold] = nan\n",
    "    Speed = replace_nan_with_local_mean(Speed)\n",
    "    Speed[Speed == 0] = nan\n",
    "    Speed = replace_nan_with_local_mean(Speed)\n",
    "    return Speed\n",
    "\n",
    "print('Filter traffic data .....')\n",
    "# Traffic_2015[:,:,:,0] = speed_smoothing(Traffic_2015[:,:,:,0])\n",
    "# Traffic_2015[:,:,:,1] = volume_smoothing(Traffic_2015[:,:,:,1])\n",
    "\n",
    "# Traffic_2016[:,:,:,0] = speed_smoothing(Traffic_2016[:,:,:,0])\n",
    "# Traffic_2016[:,:,:,1] = volume_smoothing(Traffic_2016[:,:,:,1])\n",
    "print('Done')\n",
    "\n",
    "def moving_avg_batch(data,window_length=5):\n",
    "    data_new = np.zeros(data.shape)\n",
    "    for i in range(window_length):\n",
    "        data_shift = np.copy(data)\n",
    "        data_shift[:,:,i:]=data[:,:,:data.shape[2]-i]\n",
    "        data_new += data_shift\n",
    "    return data_new/window_length\n",
    "\n",
    "def data_smoothing_moving_avg(data,window_length=5):\n",
    "    data_new = np.copy(data)\n",
    "    if len(data.shape)==4:\n",
    "        for i in range(data.shape[-1]):\n",
    "            data_new[:,:,:,i] = moving_avg_batch(data[:,:,:,i],window_length=window_length)\n",
    "    if len(data.shape)==3:\n",
    "        data_new = moving_avg_batch(data,window_length=window_length)\n",
    "    return data_new\n",
    "\n",
    "print('Smooth traffic data .....')\n",
    "# Traffic_2015 = data_smoothing_moving_avg(Traffic_2015)\n",
    "# Traffic_2016 = data_smoothing_moving_avg(Traffic_2016)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle.dump( (Traffic_2015,Weather_2015,data_2015), open( 'Data_2015_DES_I235E'+'_filter_smooth.p', \"wb\" ) )\n",
    "# pickle.dump( (Traffic_2016,Weather_2016,data_2016), open( 'Data_2016_DES_I235E'+'_filter_smooth.p', \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import saved smoothed data (start from here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015 data loaded\n",
      "2016 data loaded\n"
     ]
    }
   ],
   "source": [
    "which_data = 'Data_2015_DES_I235E'\n",
    "(Traffic_2015,Weather_2015,data_2015) = pickle.load( open(which_data+\"_filter_smooth.p\", \"rb\" ) )\n",
    "year =  data_2015['y'][0][:4]\n",
    "print('{} data loaded'.format(year))\n",
    "\n",
    "which_data = 'Data_2016_DES_I235E'\n",
    "(Traffic_2016,Weather_2016,data_2016) = pickle.load( open(which_data+\"_filter_smooth.p\", \"rb\" ) )\n",
    "year =  data_2016['y'][0][:4]\n",
    "print('{} data loaded'.format(year))\n",
    "\n",
    "data = pd.concat([data_2015,data_2016],ignore_index=True)\n",
    "Traffic = np.concatenate([Traffic_2015, Traffic_2016],axis = 0)\n",
    "Weather_5min = np.concatenate([Weather_2015, Weather_2016],axis = 0)\n",
    "Weather = np.zeros([Weather_5min.shape[0],Weather_5min.shape[1],Weather_5min.shape[2]*5,Weather_5min.shape[3]])\n",
    "for i in range(Weather.shape[2]):\n",
    "    Weather[:,:,i,:] = Weather_5min[:,:,int(i/5),:]\n",
    "Weather = np.delete(Weather,1,axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Data Base\n",
    "* ### Multi-output: each sample includes {'traffic':(15,1439,3),'weather':(15,1439,10),'history':(6,15,1439,3),'label':(15,1439)}\n",
    "* ### Single-output: each sample includes {'traffic':(15,1439,3),'weather':(15,1439,10),'history':(6,15,1439,3),'label':(1439,)}\n",
    "* ### note: in 'history', non-existing days in database are represented in nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_SpeedPrediction_database_output_single_sensor(Dataset):\n",
    "    def __init__(self, Traffic, Weather, data, transform=None, look_back = 6, target_sensor = 13):\n",
    "\n",
    "        self.Traffic = Traffic\n",
    "        self.Weather = Weather\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.look_back = look_back\n",
    "        self.target_sensor = target_sensor\n",
    "#         print(self.__len__())\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        assert idx < self.__len__(),'idx out of dataset index boundary'\n",
    "        \n",
    "        Traffic_today = self.Traffic[idx,:,:-1,:]\n",
    "        Weather_today = self.Weather[idx,:,:-1,:]\n",
    "        Traffic_history = 0\n",
    "        Traffic_output = self.Traffic[idx,self.target_sensor,1:,0]\n",
    "        \n",
    "        dayofweek = self.data.loc[idx]['dayofweek']\n",
    "        data_sub = self.data[:idx]\n",
    "        sameday_in_history = data_sub.index[data_sub['dlen(sameday_in_history)ayofweek'] == dayofweek].tolist()\n",
    "        \n",
    "        Traffic_history = np.full((self.look_back,)+self.Traffic.shape[1:], np.nan)\n",
    "#         print(len(sameday_in_history))\n",
    "        sameday_in_near_history = sameday_in_history[-self.look_back:]\n",
    "#         print(len(sameday_in_near_history))\n",
    "        \n",
    "        for i in range(len(sameday_in_near_history)):\n",
    "            Traffic_history[i] = self.Traffic[sameday_in_near_history[i]]\n",
    "        \n",
    "        sample = {'traffic': Traffic_today, 'weather': Weather_today, 'history': Traffic_history, 'label': Traffic_output}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "     \n",
    "class LSTM_SpeedPrediction_database_output_multi_sensor(Dataset):\n",
    "    def __init__(self, Traffic, Weather, data, transform=None, look_back = 6):\n",
    "\n",
    "        self.Traffic = Traffic\n",
    "        self.Weather = Weather\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.look_back = look_back\n",
    "#         printdb_trans_1 = Dataset_NVIDIA_1(annotation_list,frame_list,transform = PerspectiveTransform(MAP_FILE, world_origin, pixel_ratio, PMAT_FILE))(self.__len__())\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        assert idx < self.__len__(),'idx out of dataset index boundary'\n",
    "        Traffic_today = self.Traffic[idx,:,:-1,:]\n",
    "        Weather_today = self.Weather[idx,:,:-1,:]\n",
    "        Traffic_history = 0 \n",
    "        Traffic_output = self.Traffic[idx,:,1:,0]\n",
    "        \n",
    "        dayofweek = self.data.loc[idx]['dayofweek']\n",
    "        data_sub = self.data[:idx]\n",
    "        sameday_in_history = data_sub.index[data_sub['dayofweek'] == dayofweek].tolist()\n",
    "        \n",
    "#         Traffic_history = np.full((self.look_back,)+self.Traffic.shape[1:], np.nan)\n",
    "        \n",
    "        Traffic_history = [self.Traffic[idx,:,:,:]+np.random.randn(15,1440,3) for _ in range(self.look_back)]\n",
    "        Traffic_history = np.stack(Traffic_history,0)\n",
    "        \n",
    "#         print(len(sameday_in_history))\n",
    "        sameday_in_near_history = sameday_in_history[-self.look_back:]\n",
    "#         print(len(sameday_in_near_history))\n",
    "        \n",
    "        for i in range(len(sameday_in_near_history)):\n",
    "            Traffic_history[self.look_back-len(sameday_in_near_history)+i] = self.Traffic[sameday_in_near_history[i]]\n",
    "        \n",
    "        sample = {'traffic': torch.Tensor(Traffic_today),'weather': torch.Tensor(Weather_today), 'history': torch.Tensor(Traffic_history), 'label': torch.Tensor(Traffic_output)} # \n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = LSTM_SpeedPrediction_database_output_multi_sensor(Traffic, Weather, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X                      20161216Dir1.csv\n",
      "y             20161216_Traffic_Dir1.csv\n",
      "day                            20161216\n",
      "date                2016-12-16 00:00:00\n",
      "dayofweek                             4\n",
      "weekofyear                           50\n",
      "month                                12\n",
      "dayofyear                           351\n",
      "Name: 431, dtype: object\n",
      "<class 'torch.FloatTensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 431  # test: [417,420,431]\n",
    "print(data.loc[idx])\n",
    "\n",
    "def vis_one_day_traffic_speed(speed):\n",
    "    plt.pcolor(speed,cmap=my_cmap, vmin=20, vmax=70)\n",
    "    \n",
    "# vis_one_day_traffic_speed(db[257]['label'])\n",
    "print(type(db[idx]['traffic']))\n",
    "vis_one_day_traffic_speed(db[idx]['traffic'][:,:,0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test = data.loc[[417,420,431]]\n",
    "# data_test = data_test.reset_index()\n",
    "\n",
    "# data_train = data\n",
    "# data_train = data_train.drop([417,420,431])\n",
    "# data_train = data_train.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader: load sample from database in batch\n",
    "\n",
    "## batch added one more dimension to the left\n",
    "\n",
    "## in case of multi-output and batch = 10, each sample:\n",
    "\n",
    "## {'traffic':(10,15,1439,3),'weather':(10,15,1439,10),'history':(10,6,15,1439,3),'label':(10,15,1439)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[:-30]\n",
    "data_train = data_train.reset_index()\n",
    "\n",
    "data_val = data[-61:]\n",
    "data_val = data_val.reset_index()\n",
    "\n",
    "dataset = {}\n",
    "dataset['train'] = LSTM_SpeedPrediction_database_output_multi_sensor(Traffic[:-30], Weather[:-30], data_train)\n",
    "dataset['val'] = LSTM_SpeedPrediction_database_output_multi_sensor(Traffic[-61:], Weather[-61:], data_val)\n",
    "\n",
    "dataset_sizes = {x: len(dataset[x]) for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(dataset[x], batch_size=1000,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample in dataloaders['train']:\n",
    "#     print('traffic: ',sample['traffic'].shape)\n",
    "#     print('weather: ',sample['weather'].shape)\n",
    "#     print('history: ',sample['history'].shape)\n",
    "#     print('label: ',sample['label'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''https://github.com/wkelongws/iemgrid'''\n",
    "'''Weather: 0:tmpc 1:dwpc 2:smps 3:drct 4:vsby 5:roadtmpc 6:srad 7:snwd 8:pcpn '''\n",
    "\n",
    "Traffic_max = []\n",
    "Traffic_min = []\n",
    "Weather_max = []\n",
    "Weather_min = []\n",
    "\n",
    "for i in range(Traffic.shape[-1]):\n",
    "#     print(i,'max: ',np.max(Traffic[:,:,:,i]))\n",
    "    Traffic_max.append(np.max(Traffic[:,:,:,i]))\n",
    "#     print(i,'mean: ',np.mean(Traffic[:,:,:,i]))\n",
    "#     print(i,'min: ',np.min(Traffic[:,:,:,i]))\n",
    "    Traffic_min.append(np.min(Traffic[:,:,:,i]))\n",
    "for i in range(Weather.shape[-1]):\n",
    "#     print(i,'max: ',np.max(Weather[:,:,:,i]))\n",
    "    Weather_max.append(np.max(Weather[:,:,:,i]))\n",
    "#     print(i,'mean: ',np.mean(Weather[:,:,:,i]))\n",
    "#     print(i,'min: ',np.min(Weather[:,:,:,i]))\n",
    "    Weather_min.append(np.min(Weather[:,:,:,i]))\n",
    "    \n",
    "Min_Max = (Traffic_max,Traffic_min,Weather_max,Weather_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-25.0, -29.0, 0.0, 0.0, 0.0, -20.4, 0.0, 0.0, -36.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Min_Max[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Prediction Net\n",
    "## Normalization on the fly. Normalize all numbers ~ (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Short_Term_Speed_Pred_Net(nn.Module):\n",
    "    def __init__(self, filter_height = 5, output_single_sensor = False, \\\n",
    "                 hidden_dim = 16,use_gpu = True, use_volume_and_occup = False, \\\n",
    "                 use_weather = False, use_history = True, input_feature = 'cnn', Min_Max = Min_Max):\n",
    "        super(LSTM_Short_Term_Speed_Pred_Net, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.out_dim = 15\n",
    "        \n",
    "        self.input_dim_today = self.out_dim\n",
    "        self.input_dim_history = self.out_dim\n",
    "        if input_feature == 'cnn':\n",
    "            self.input_dim_today = self.out_dim - filter_height + 1\n",
    "            self.input_dim_history = self.out_dim - filter_height + 1\n",
    "#         else:\n",
    "#             self.input_dim_today = self.out_dim\n",
    "#             self.input_dim_history = self.out_dim\n",
    "        \n",
    "        if output_single_sensor:\n",
    "            self.out_dim = out_dim = 1\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        self.use_volume_and_occup = use_volume_and_occup\n",
    "        self.use_weather = use_weather\n",
    "        self.use_history = use_history\n",
    "#         assert input_feature in ['raw','linear','cnn'], 'wrong choice for input_feature'\n",
    "        assert input_feature == 'cnn', 'currently only allow cnn as input feature extractor'\n",
    "        self.input_feature = input_feature # ['raw','linear','CNN']\n",
    "        \n",
    "        '''for on-fly normalization'''\n",
    "        self.Traffic_max = Min_Max[0]\n",
    "        self.Traffic_min = Min_Max[1]\n",
    "        self.Weather_max = Min_Max[2]\n",
    "        self.Weather_min = Min_Max[3]\n",
    "        \n",
    "        if self.input_feature == 'cnn':\n",
    "            self.CNN_for_history = nn.Conv2d(1, 1, (filter_height, 1), stride=(1, 1))\n",
    "            self.CNN_feature_extract = nn.Conv2d(1, 1, (filter_height, 1), stride=(1, 1))\n",
    "            if self.use_volume_and_occup:\n",
    "                self.CNN_feature_extract = nn.Conv2d(1, 1, (filter_height, 3), stride=(1, 1))\n",
    "            if self.use_weather:\n",
    "                self.CNN_feature_extract = nn.Conv2d(1, 1, (filter_height, 12), stride=(1, 1))\n",
    "        self.CNN_today_and_history_output_combine = nn.Conv2d(1, 1, (1, 2), stride=(1, 1))\n",
    "        self.lstm_today = nn.LSTMCell(self.input_dim_today, self.hidden_dim)\n",
    "        self.lstm_history = nn.LSTMCell(self.input_dim_history, self.hidden_dim)\n",
    "        self.linear_out = nn.Linear(self.hidden_dim, self.out_dim)\n",
    "        \n",
    "    def init_hidden(self,input_sample):\n",
    "        \n",
    "        batch_size = input_sample['traffic'].shape[0]\n",
    "        if self.use_gpu:\n",
    "            return Variable(torch.zeros(batch_size, self.hidden_dim).cuda(), requires_grad=False)\n",
    "        return Variable(torch.zeros(batch_size, self.hidden_dim), requires_grad=False)\n",
    "\n",
    "    def LSTM_update(self,input_t,hidden_state_today,cell_state_today):\n",
    "        input_t = input_t.squeeze(3).squeeze(1)\n",
    "        hidden_state_today, cell_state_today = self.lstm_today(input_t, (hidden_state_today, cell_state_today))\n",
    "        hidden_state_output = hidden_state_today\n",
    "        return hidden_state_today, cell_state_today, hidden_state_output\n",
    " \n",
    "    def LSTM_update_with_history(self,input_t,input_history,hidden_state_today,cell_state_today,hidden_state_history,cell_state_history):\n",
    "        input_t = input_t.squeeze(3).squeeze(1)\n",
    "        hidden_state_today, cell_state_today = self.lstm_today(input_t, (hidden_state_today, cell_state_today))\n",
    "        if len(input_history)>0:\n",
    "            for input_t_history in input_history:\n",
    "                input_h = input_t_history.squeeze(3).squeeze(1)\n",
    "                hidden_state_history, cell_state_history = self.lstm_history(input_h, (hidden_state_history, cell_state_history))\n",
    "\n",
    "            h_combine = torch.stack([hidden_state_today,hidden_state_history],2)\n",
    "            h_combine = h_combine.unsqueeze(1)\n",
    "            hidden_state_output = self.CNN_today_and_history_output_combine(h_combine)\n",
    "            hidden_state_output = hidden_state_output.squeeze(3).squeeze(1)\n",
    "            return hidden_state_today, cell_state_today, hidden_state_output\n",
    "        else:\n",
    "            hidden_state_output = hidden_state_today\n",
    "            return hidden_state_today, cell_state_today, hidden_state_output\n",
    "        \n",
    "\n",
    "    def forward(self, input_sample, future = 0, use_gpu = True):\n",
    "        \n",
    "        '''reconstruct data from sample'''\n",
    "        traffic = input_sample['traffic']\n",
    "        weather = input_sample['weather']\n",
    "        history = input_sample['history']\n",
    "        label = input_sample['label']\n",
    "#         print('traffic: ',traffic.shape)\n",
    "#         print('weather: ',weather.shape)\n",
    "#         print('history: ',history.shape)\n",
    "#         print('label: ',label.shape)\n",
    "#         print()\n",
    "#         print(np.sum(np.isnan(np.array(traffic))))\n",
    "#         print(np.sum(np.isnan(np.array(weather))))\n",
    "#         print(np.sum(np.isnan(np.array(history))))\n",
    "        \n",
    "        '''normalize'''\n",
    "#         label = (label - self.Traffic_min[0])/(self.Traffic_max[0]-self.Traffic_min[0])\n",
    "        for i in range(traffic.shape[-1]):\n",
    "            traffic[:,:,:,i] = (traffic[:,:,:,i]-self.Traffic_min[i])/(self.Traffic_max[i]-self.Traffic_min[i])\n",
    "            history[:,:,:,:,i] = (history[:,:,:,:,i]-self.Traffic_min[i])/(self.Traffic_max[i]-self.Traffic_min[i])\n",
    "        for i in range(weather.shape[-1]):\n",
    "            weather[:,:,:,i] = (weather[:,:,:,i]-self.Weather_min[i])/(self.Weather_max[i]-self.Weather_min[i])\n",
    "        \n",
    "#         print()\n",
    "#         print(np.sum(np.isnan(np.array(traffic))))\n",
    "#         print(np.sum(np.isnan(np.array(weather))))\n",
    "#         print(np.sum(np.isnan(np.array(history))))\n",
    "        '''re-arrange inputs'''\n",
    "        input_today = traffic[:,:,:,0:1]\n",
    "        \n",
    "        if self.use_volume_and_occup:\n",
    "            input_today = traffic\n",
    "            \n",
    "        if self.use_weather:\n",
    "            input_today = torch.cat([traffic,weather],3)\n",
    "            \n",
    "        input_history = history[:,:,:,:,0:1]\n",
    "            \n",
    "        if use_gpu:\n",
    "            input_today = Variable(input_today.cuda())\n",
    "            input_history = Variable(input_history.cuda())\n",
    "            label = Variable(label.cuda())\n",
    "        else:\n",
    "            input_today = Variable(input_today)\n",
    "            input_history = Variable(input_history)\n",
    "            label = Variable(label)\n",
    "        \n",
    "#         print()\n",
    "#         print(np.sum(np.isnan(np.array(input_today.data))))\n",
    "#         print(np.sum(np.isnan(np.array(input_history.data))))\n",
    "        \n",
    "        '''feedforward'''\n",
    "        \n",
    "        outputs = []\n",
    "        hidden_state_today = self.init_hidden(input_sample)\n",
    "        cell_state_today = self.init_hidden(input_sample)\n",
    "        hidden_state_history = self.init_hidden(input_sample)\n",
    "        cell_state_history = self.init_hidden(input_sample)\n",
    "#         print(input_today.data.shape[2])\n",
    "        for i in range(input_today.data.shape[2]):\n",
    "            \n",
    "            input_t = input_today[:,:,i:i+1,:]\n",
    "            input_t = input_t.permute(0,2,1,3)\n",
    "            \n",
    "            input_t_history = []\n",
    "#             print(input_history.shape[1])\n",
    "            for k in range(input_history.shape[1]):\n",
    "                if not np.isnan(np.array(input_history[0,k,0,0,0].data))[0]:\n",
    "                    input_t_history.append(input_history[:,k,:,i+1:i+2,:].permute(0,2,1,3))\n",
    "#             print(len(input_t_history))\n",
    "\n",
    "            if self.input_feature == 'cnn':\n",
    "                input_t = self.CNN_feature_extract(input_t)\n",
    "                input_t_history = [self.CNN_for_history(x) for x in input_t_history]\n",
    "\n",
    "            if self.use_history:\n",
    "                hidden_state_today, cell_state_today, hidden_state_output = self.LSTM_update_with_history(input_t,input_t_history,hidden_state_today,cell_state_today,hidden_state_history,cell_state_history)\n",
    "            else:\n",
    "                hidden_state_today, cell_state_today, hidden_state_output = self.LSTM_update(input_t,hidden_state_today,cell_state_today)\n",
    "            \n",
    "            output = nn.functional.sigmoid(self.linear_out(hidden_state_output))\n",
    "            output = output*(self.Traffic_max[0]-self.Traffic_min[0])+self.Traffic_min[0] \n",
    "            outputs += [output]\n",
    "        outputs = torch.stack(outputs, 2)\n",
    "\n",
    "        return outputs, label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "\n",
    "model = LSTM_Short_Term_Speed_Pred_Net(filter_height = 5, output_single_sensor = False, \\\n",
    "                 hidden_dim = 16,use_gpu = True, use_volume_and_occup = True, \\\n",
    "                 use_weather = True, use_history = True, input_feature = 'cnn')\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred,label = model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(pred),pred.shape)\n",
    "print(type(label),label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(np.isnan(np.array(label.data))))\n",
    "print(np.sum(np.isnan(np.array(pred.data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.array(pred.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "906570/(15*1439*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for sample in dataloaders['train']:\n",
    "    cnt += 1\n",
    "    if cnt == 1:\n",
    "        s = sample\n",
    "    b = sample['traffic']\n",
    "    c = sample['weather']\n",
    "    d = sample['history']\n",
    "    e = sample['label']\n",
    "    print(type(sample['traffic']))\n",
    "    print('traffic: ',sample['traffic'].shape)\n",
    "    print('weather: ',sample['weather'].shape)\n",
    "    print('history: ',sample['history'].shape)\n",
    "    print('label: ',sample['label'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def customized_loss(preds, targets):\n",
    "    \n",
    "#     preds = preds.view(preds.data.shape[0]*preds.data.shape[1],-1)\n",
    "#     targets = targets.view(targets.data.shape[0]*targets.data.shape[1],-1)\n",
    "    \n",
    "#     pdist = nn.PairwiseDistance(p=2)\n",
    "    \n",
    "#     output = pdist(preds, targets)\n",
    "\n",
    "#     loss = sum(output)/output.data.shape[0]\n",
    "    \n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "\n",
    "model = LSTM_Short_Term_Speed_Pred_Net(filter_height = 5, output_single_sensor = False, \\\n",
    "                 hidden_dim = 16,use_gpu = True, use_volume_and_occup = True, \\\n",
    "                 use_weather = True, use_history = True, input_feature = 'cnn')\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LSTM_perVehiclePrediction_Net(model,dataloaders, criterion, optimizer, dataset_sizes, num_epochs=100):\n",
    "    since = time.time()\n",
    "\n",
    "#     timeSince(since)\n",
    "#     model.load_state_dict(torch.load('Best_LSTM_Weights_1st'))\n",
    "#     print()\n",
    "#     print('keep training from previous \"Best_LSTM_Weights_1st\"')\n",
    "#     print()\n",
    "\n",
    "#     vanillaPlus_compromised_dict = torch.load('Best_LSTM_Weights_vanillaPlus')\n",
    "#     vanillaPlus_compromised_dict['linear_out.weight'] = torch.randn(model.state_dict()['linear_out.weight'].shape).cuda()\n",
    "#     vanillaPlus_compromised_dict['linear_out.bias'] = torch.randn(model.state_dict()['linear_out.bias'].shape).cuda()\n",
    "#     model.load_state_dict(vanillaPlus_compromised_dict)\n",
    "#     print()\n",
    "#     print('weights in the output layer are initialized from normal distribution')\n",
    "#     print('and other model weights are loaded from \"Best_LSTM_Weights_vanillaPlus_compromised')\n",
    "#     print('keep training from previous \"Best_LSTM_Weights_vanillaPlus_compromised\"')\n",
    "#     print()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_loss = 100000\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for sample in dataloaders[phase]:\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                model.zero_grad()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Also, we need to clear out the hidden state of the LSTM,\n",
    "                # detaching it from its history on the last instance.\n",
    "#                 model.hidden = model.init_hidden()\n",
    "                \n",
    "                # forward\n",
    "                pred,label = model(sample)\n",
    "                \n",
    "                # loss function\n",
    "#                 loss = customized_loss(pred,label)\n",
    "                loss = criterion(pred,label)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} total elapsed time: {}'.format(phase, epoch_loss, timeSince(since)))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = model.state_dict()\n",
    "#                 torch.save(best_model_wts, 'Best_LSTM_Weights')\n",
    "                print('Weights saved to \"Best_LSTM_Weights\"')\n",
    "\n",
    "        print()\n",
    "\n",
    "    print('Training complete in {}'.format(timeSince(since)))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model, 'Model_with_Best_LSTM_Weights')\n",
    "    print('Model saved to \"Model_with_Best_LSTM_Weights\"')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = train_LSTM_perVehiclePrediction_Net(model,dataloaders, criterion, optimizer, dataset_sizes, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
